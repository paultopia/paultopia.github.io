<?xml version='1.0' encoding='UTF-8'?>
<rss version='2.0' xmlns:atom='http://www.w3.org/2005/Atom'>
<channel>
<atom:link href='http://paultopia.github.io' rel='self' type='application/rss+xml'/>
<title>
Experiments in Tech Blogging (!!)
</title>
<link>
http://paultopia.github.io
</link>
<description>
let's see, eh?
</description>
<lastBuildDate>
Tue, 25 Jul 2017 15:55:08 -0400
</lastBuildDate>
<generator>
clj-rss
</generator>
<item>
<guid>
http://paultopia.github.io/posts-output/naivebayes/
</guid>
<link>
http://paultopia.github.io/posts-output/naivebayes/
</link>
<title>
Naive Bayes Speed Test, OR: Everything is a Dot Product
</title>
<description>
 &lt;p&gt;(With help from &lt;a href='http://carlosd.ghost.io/'&gt;Carlos De La Guardia&lt;/a&gt;, who was like &quot;dude, vectorize this stuff&quot; after seeing the incredibly slow implementation the first time, and then was kind enough to talk through the problem and &lt;a href='https://github.com/paultopia/haskeml/blob/master/naive-bayes-speed-test.ipynb'&gt;the notebook&lt;/a&gt; on which this post is based. All infelicities are mine (and I didn't even implement his wise suggestions for cleaning up the notebook).)&lt;/p&gt;&lt;p&gt;Naive Bayes is the simplest possible machine learning algorithm. In its Bernoulli form, calculation is just a matter of applying probability 101 techniques to calculate the (estimated) conditional probabilities of your predictors given the labels and estimated probability of the labels, then applying Bayes Rule directly to generate a posterior on a label given the data. Trivial. &lt;/p&gt;&lt;p&gt;&quot;Training&quot; the model, then, is just arithmetic. Supposing we have everything in a pandas dataframe in which the first column is our label, and in which all features and the label are encoded as 1s and 0s. Then is all the code it takes:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;python&quot;&gt;prob&amp;#95;y = df&amp;#91;&amp;quot;LABEL&amp;quot;&amp;#93;.sum&amp;#40;&amp;#41; / len&amp;#40;df&amp;#41;
spams = df&amp;#91;df&amp;#91;&amp;quot;LABEL&amp;quot;&amp;#93; == 1&amp;#93;
notspams = df&amp;#91;df&amp;#91;&amp;quot;LABEL&amp;quot;&amp;#93; == 0&amp;#93;
features = list&amp;#40;df&amp;#41;&amp;#91;1:&amp;#93;

def conditional&amp;#95;probability&amp;#95;dict&amp;#40;column&amp;#95;label, condition&amp;#95;df&amp;#41;:
    numerator = condition&amp;#95;df&amp;#91;column&amp;#95;label&amp;#93;.sum&amp;#40;&amp;#41; + 1 
    denominator = len&amp;#40;condition&amp;#95;df&amp;#41; + 2
    return {column&amp;#95;label: numerator / denominator}

x&amp;#95;probs&amp;#95;conditional&amp;#95;on&amp;#95;spam=&amp;#91;conditional&amp;#95;probability&amp;#95;dict&amp;#40;x, spams&amp;#41; for x in list&amp;#40;spams&amp;#41;&amp;#91;1:&amp;#93;&amp;#93;
x&amp;#95;spam&amp;#95;lookup = toolz.merge&amp;#40;x&amp;#95;probs&amp;#95;conditional&amp;#95;on&amp;#95;spam&amp;#41;

x&amp;#95;probs&amp;#95;conditional&amp;#95;on&amp;#95;notspam=&amp;#91;conditional&amp;#95;probability&amp;#95;dict&amp;#40;x, notspams&amp;#41; for x in list&amp;#40;notspams&amp;#41;&amp;#91;1:&amp;#93;&amp;#93;
x&amp;#95;notspam&amp;#95;lookup = toolz.merge&amp;#40;x&amp;#95;probs&amp;#95;conditional&amp;#95;on&amp;#95;notspam&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;What this produces is a dict of priors on each x for each state of y, plus a prior on y. Note that we use &lt;a href='https://stats.stackexchange.com/a/171210/69606'&gt;Laplace smoothing&lt;/a&gt; to calculate our x priors, otherwise if a feature isn't seen for one of our labels, we end up just predicting zero for it. &lt;/p&gt;&lt;p&gt;Then a &quot;prediction&quot; is simply an application of Bayes Rule to estimate the probability of y=1 and the probability of y=0 for each observation. Recall that Bayes Rule is: &lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;nohighlight&quot;&gt; $$p&amp;#40;y=\phi | x1, x2... xn&amp;#41; = \frac{p&amp;#40;x1|y&amp;#41;p&amp;#40;x2|y&amp;#41;...p&amp;#40;xn|y&amp;#41;p&amp;#40;y&amp;#41;}{p&amp;#40;x1&amp;#41;p&amp;#40;x2&amp;#41;...p&amp;#40;xn&amp;#41;}$$ 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Note that the denominator is going to be the same for the y=1 and y=0 calculations for each observation, so we can drop it, since we're just comparing those on an observation-by-observation basis. What we end up with is:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;nohighlight&quot;&gt; $$p&amp;#40;y=\phi | x&amp;#95;{1..n}&amp;#41; = p&amp;#40;y=\phi&amp;#41;\prod&amp;#95;{i=1}&amp;#94;{n}p&amp;#40;x&amp;#95;i | y=\phi&amp;#41;$$ 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So here's the bad and slow way to actually generate predictions on this model. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;def slow&amp;#95;predict&amp;#40;row&amp;#41;:
    prob&amp;#95;spam = log&amp;#40;prob&amp;#95;y&amp;#41;
    prob&amp;#95;notspam = log&amp;#40;1 - prob&amp;#95;y&amp;#41;
    for feat in features:
        if row&amp;#91;feat&amp;#93; == 1:
            prob&amp;#95;spam = prob&amp;#95;spam + log&amp;#40;x&amp;#95;spam&amp;#95;lookup&amp;#91;feat&amp;#93;&amp;#41;
            prob&amp;#95;notspam = prob&amp;#95;notspam + log&amp;#40;x&amp;#95;notspam&amp;#95;lookup&amp;#91;feat&amp;#93;&amp;#41;
    if prob&amp;#95;spam &amp;gt;= prob&amp;#95;notspam:
        return 1
    else:
        return 0
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;A few notes about this implementation.  First, it leverages the fact that &lt;code&gt;$log&amp;#40;xy&amp;#41;=log&amp;#40;x&amp;#41;+log&amp;#40;y&amp;#41;$&lt;/code&gt; to sum the logarithms of the priors rather than multiply them. This is important, because otherwise you get into &lt;em&gt;really really&lt;/em&gt; small floating point values when you multiply a bunch of already tiny probabilities together; that's a recipe for terrible floating point errors. &lt;/p&gt;&lt;p&gt;Second, what this is doing is iterating over every cell in every row of the dataset. For each cell, it looks up the value in the dataframe to make sure it's a 1, and if it is, then it goes and looks up the prior for that feature in the dict (hash, for non-Pythonistas), and then adds it to a running total. (For extra special bonus inefficiency, it also calculates the logs over and over and over again, which was dumb.)&lt;/p&gt;&lt;p&gt;For dataset of 9,663 features and 5,574 observations (a cleaned-up and binarized version of the &lt;a href='https://archive.ics.uci.edu/ml/datasets/sms+spam+collection'&gt;UCI SMS spam dataset&lt;/a&gt;), that took about fifteen minutes to generate predictions on the original data. &lt;/p&gt;&lt;p&gt;Needless to say, this is totally outrageous. A little profiling indicated that basically all the time was spent looking up values, i.e., with all that iteration. (Calculating all those unnecessary logs didn't seem to register.)&lt;/p&gt;&lt;p&gt;After some time chatting with Carlos and a whiteboard, the solution came to me: after switching from multiplying probabilities to adding log probabilities, &lt;em&gt;calculating the posterior is just a dot product of a vector of the priors for x and the binarized features&lt;/em&gt; (plus adding the log probability of y).  That means no explicit iteration is necessary, no repeated lookups, no check to see of the feature is 1 or 0 for a given observation&amp;mdash;all that stuff is unnecessary. &lt;/p&gt;&lt;p&gt;So let's implement that. For ease of prediction, we start by reshaping the data. We'll get our labels out of the dataset for ease of multiplication, and add a column of all ones at the start to facilitate including &lt;code&gt;$log&amp;#40;p&amp;#40;y=\phi&amp;#41;&amp;#41;$&lt;/code&gt; in the dot product rather than adding it later. (Let's just call this a &quot;pseudo-intercept.&quot;) We'll also change our feature priors from a lookup dict to a vector so that we can multiply it out without a bunch of lookups. For purposes of consistency and guaranteed playing-nice-with-numpy, we'll keep everything in Pandas datastructures.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;clean&amp;#95;spamdf = df.iloc&amp;#91;:,1:&amp;#93;
clean&amp;#95;spamdf.insert&amp;#40;0, &amp;quot;pseudo&amp;#95;intercept&amp;quot;, 1&amp;#41; 

true&amp;#95;vector =&amp;#91;log&amp;#40;x&amp;#95;spam&amp;#95;lookup&amp;#91;x&amp;#93;&amp;#41; for x in features&amp;#93;
true&amp;#95;vector.insert&amp;#40;0, log&amp;#40;prob&amp;#95;y&amp;#41;&amp;#41;
true&amp;#95;vector = pd.Series&amp;#40;true&amp;#95;vector&amp;#41; 

false&amp;#95;vector =&amp;#91;log&amp;#40;x&amp;#95;notspam&amp;#95;lookup&amp;#91;x&amp;#93;&amp;#41; for x in features&amp;#93;
false&amp;#95;vector.insert&amp;#40;0, log&amp;#40;1-prob&amp;#95;y&amp;#41;&amp;#41;
false&amp;#95;vector = pd.Series&amp;#40;false&amp;#95;vector&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then we'll bust out our matrix math, with the terrifying speed of numpy:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;python&quot;&gt;def fast&amp;#95;predict&amp;#40;df, true&amp;#95;priors, false&amp;#95;priors&amp;#41;:
    true&amp;#95;posterior = np.dot&amp;#40;df, true&amp;#95;priors&amp;#41;
    false&amp;#95;posterior = np.dot&amp;#40;df, false&amp;#95;priors&amp;#41;
    combined = np.column&amp;#95;stack&amp;#40;&amp;#40;false&amp;#95;posterior, true&amp;#95;posterior&amp;#41;&amp;#41;
    return np.argmax&amp;#40;combined, axis=1&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The last two lines might be a little opaque. Column_stack does what it says on the label, i.e., sets up a numpy 2d array in which the posterior on y=0 is the first column and the posterior on y=1 is the second; then argmax returns the row index that has the maximum value&amp;mdash;thus, conveniently, returns 0 when &lt;code&gt;$p&amp;#40;y=0&amp;#41; &amp;gt; p&amp;#40;y=1&amp;#41;$&lt;/code&gt; and so forth. &lt;/p&gt;&lt;p&gt;Running this took, I'm not even making this up, under 2 seconds.  Compare that to about 15 minutes for the slow version.&lt;/p&gt;&lt;p&gt;So when people say you should vectorize stuff, this is why...&lt;/p&gt;
</description>
<enclosure>

</enclosure>
<pubDate>
Tue, 25 Jul 2017 00:00:00 -0400
</pubDate>
</item>
<item>
<guid>
http://paultopia.github.io/posts-output/ng67/
</guid>
<link>
http://paultopia.github.io/posts-output/ng67/
</link>
<title>
Lectures 6-7 (part) of Andrew Ng's mathier ML course
</title>
<description>
&lt;h2&gt;&lt;a name=&quot;ng&amp;#95;lecture&amp;#95;6&amp;#95;and&amp;#95;7:&amp;#95;multinomial&amp;#95;models,&amp;#95;transition&amp;#95;to&amp;#95;svm.&quot;&gt;&lt;/a&gt;Ng lecture 6 and 7: multinomial models, transition to SVM.&lt;/h2&gt;&lt;h2&gt;&lt;a name=&quot;lecture&amp;#95;6&quot;&gt;&lt;/a&gt;Lecture 6&lt;/h2&gt;&lt;h3&gt;&lt;a name=&quot;generalizing&amp;#95;naive&amp;#95;bayes&amp;#95;to&amp;#95;multinomial&amp;#95;models&quot;&gt;&lt;/a&gt;Generalizing Naive Bayes to multinomial models&lt;/h3&gt;&lt;p&gt;What if it isn't just &quot;spam/not-spam?&quot; What if it's &quot;spam/not-spam-and-from-a-friend/not-spam-andfrom-by-boss?&quot;  The model comes out the same way: the probability of x given y is just a multinomial rather than a bernoilli. You can also discretize continuous features into buckets and then use multinomial naive bayes.&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;multinomial&amp;#95;event&amp;#95;model&amp;#95;for&amp;#95;naive&amp;#95;bayes&quot;&gt;&lt;/a&gt;Multinomial Event model for naive bayes&lt;/h3&gt;&lt;p&gt;(warning, his notation changes here.)&lt;/p&gt;&lt;p&gt;another variation on naive bayes especially for other text documents or other sequences.  Takes into account the number of times different words appears.  If some word appears a lot of times (&quot;buy&quot;), it's more likely to be spam than if it appears once, but the version of naive bayes he did before just has binaries.&lt;/p&gt;&lt;p&gt;Represents each document as a feature vector &lt;code&gt;$&amp;#40;x&amp;#94;{&amp;#40;i&amp;#41;}&amp;#95;1, x&amp;#94;{&amp;#40;i&amp;#41;}&amp;#95;2... x&amp;#94;{&amp;#40;i&amp;#41;}&amp;#95;n&amp;#41;$&lt;/code&gt; where n is the number of words in that document, and maps to the dictionary.  So if the dictionary has 1000 words, then the components of the feature vector for each document is an index into our dictionary for the word that appears in that picture. &lt;/p&gt;&lt;p&gt;So then we're calculating p(x|y) as the product of the probability of seeing the word we see in each position of the document.  See page 13 of &lt;a href='https://see.stanford.edu/materials/aimlcs229/cs229-notes2.pdf'&gt;notes 2&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;Skipping the gnarly sums, the maximum likelihood estimator for a given word p(xi|y=1) is another simple proportion, namely: the numerator is &quot;count the total number of appearances of word k in documents with classlabel 1.  The denominator is &quot;sum the lengths of all the e-mails in classlabel 1&quot;.  This is a translation of the maximum likelihood estimates on pg. 14 of the notes.  In those estimates, remember that j...n indexes positions in a document and m indexes documents.&lt;/p&gt;&lt;p&gt;So essentially instead of fitting naive bayes over &lt;em&gt;documents&lt;/em&gt;, we're fitting naive bayes over &lt;em&gt;positions in documents&lt;/em&gt;.&lt;br /&gt;&lt;/p&gt;&lt;p&gt;And for laplace smoothing, we add 1 to the numerator and k to the denominator, where k is the number of unique words. (also in the notes as |V|).&lt;br /&gt;&lt;/p&gt;&lt;p&gt;(Interlude: Ng actually stopped in the middle to lay out maximum likelihood estimation in response to a student question (at minute 20 of the video).  The short version id that the likelihood function is a function of the parameters, and is the product of the probability of each x and y, paramaterized by the aforementioned parameters; then maximize the log.)&lt;/p&gt;&lt;p&gt;Multinomial event model almost always does better than the first version of naive bayes for text classification. &lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;nonlinear&amp;#95;classifiers&quot;&gt;&lt;/a&gt;Nonlinear classifiers&lt;/h3&gt;&lt;p&gt;Let's think of taking a simple algorithm like logistic regression and go out to more complex classifiers. &lt;/p&gt;&lt;p&gt;How would we get a nonlinear decision boundary out of our logistic regression. Suppose we have a function with a bunch of parameters and weights on them, then applies a sigmoid function to generate a hypothesis.&lt;br /&gt;&lt;/p&gt;&lt;p&gt;To get a nonlinear decision boundary, one thing we could do would be to create intermediate results&amp;mdash;create multiple hypotheses from the combinations of our features and weights, and then has a second (etc.) set of weights on those hypotheses, which get combined by another sigmoid function.  Then you've turned your logistic regression into a neutral net.&lt;/p&gt;&lt;p&gt;As before, we do gradient descent to minimize the squared error, our labels - hypothesis.  And backpropogation is the name of the algorithm that carries out that gradient descent.&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;support&amp;#95;vector&amp;#95;machines&quot;&gt;&lt;/a&gt;Support vector machines&lt;/h3&gt;&lt;p&gt;We're actually going to start off with a linear version before going to the nonlinear bit. &lt;/p&gt;&lt;p&gt;&quot;Two intuitions about classification&quot;:&lt;/p&gt;&lt;p&gt;First intuition.  Logistic regression is an algorithm that computes &lt;code&gt;$\theta&amp;#94;Tx$&lt;/code&gt; and predicts 1 if that product greater than zero, or - if it's less than zero.  If the distance away from zero is large, that's a very confident prediction, you're on the tails of the sigmoid function. &lt;/p&gt;&lt;p&gt;&quot;Wouldn't it be nice,&quot; he says, if for our training set, if y=1 we'd have high confidence in it, i.e., we'd have &lt;code&gt;$\theta&amp;#94;Tx$&lt;/code&gt; much higher than zero, and vice versa.  So that's the first intuition, and it leads to the idea of &quot;functional margins,&quot; discussed below.&lt;/p&gt;&lt;p&gt;Second intuition: assuming the training set is linearly separable (there's a straight line separating the training set... this is an assumption that will go away later).  A better line is one that is further away from the training data (more centralized in the boundary).  Formalizations here will use the term &quot;geometric margins.&quot;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;warning: another notation change here as we get into SVM&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;labels (y), instead of being 0 or 1, they'll be -1 or +1.  And the hypothesis will output values that are either +1 or -1. Also, for our hypothesis, we're dropping our convention that &lt;code&gt;$x&amp;#95;0 = 1$&lt;/code&gt; (adding the intercept).  Instead, we'll just separate out an intercept term b.  Also our parameters become w rather than theta.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Definition: functional margin&lt;/strong&gt;: the functional margin of a hyperplane with respect to a specific training example &lt;code&gt;$&amp;#40;x&amp;#94;{&amp;#40;i&amp;#41;}, y&amp;#94;{&amp;#40;i&amp;#41;}&amp;#41;$&lt;/code&gt; is &lt;code&gt;$\hat{\gamma}&amp;#94;{&amp;#40;i&amp;#41;}=y&amp;#94;{&amp;#40;i&amp;#41;}&amp;#40;w&amp;#94;Tx&amp;#94;{&amp;#40;i&amp;#41;}+b&amp;#41;$&lt;/code&gt;  What that means is that if &lt;code&gt;$y&amp;#94;{&amp;#40;i&amp;#41;} = 1$&lt;/code&gt; then you want the functional margin to be large which means you make the hypothesis (that term with w and b) to be big, and small if it's -1. Also, if &lt;code&gt;$\hat{\gamma}&amp;#94;{&amp;#40;i&amp;#41;} &amp;gt; 0$&lt;/code&gt; then we've classified correctly.&lt;/p&gt;&lt;p&gt;So if the functional margin is high, we've both classified correctly and confidently.  Module one problem, namely that we could make the funcional margin large just by multiplying our parameters by constants. So that's bad. We need to add a normalization constraint later. (e.g. that the l2 norm ||w|| of w is 1.) &lt;/p&gt;&lt;p&gt;&lt;strong&gt;Definition: geometric margin&lt;/strong&gt;: the geometric distance at a given training example is between a training example and the separating hyperplane. &lt;/p&gt;&lt;p&gt;Note that all points on the decision boundary satisfy &lt;code&gt;$w&amp;#94;Tx+b=0$&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;There's a bunch of linear algebra/geometry that I let slide here.  But what it amounts to is that the geometric margin is just equal to the functional margin divided by the (l2?) norm of w. So it doesn't have the problem that the functional margin has of being subject to scaling by a constant.  Intuitively, what we're doing is finding a vector orthogonal to the plane at the training example.  (More intuitively still, a perpendicular line from the plane to the data.)&lt;/p&gt;&lt;p&gt;The geometric margin of a whole training set is just the minimum of the margins of all the examples. &lt;/p&gt;&lt;p&gt;Maximum margin classifier is a precursor to SVMs. See &lt;a href='https://see.stanford.edu/materials/aimlcs229/cs229-notes3.pdf'&gt;notes 3, pg. 5-6&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Maximum margin idea: maximize the minimum of the margins of all the examples.&lt;/p&gt;&lt;p&gt;Unfortunately, maximizing the geometric margin directly us pretty uggo: it's not convex. &lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;lecture&amp;#95;7&quot;&gt;&lt;/a&gt;Lecture 7&lt;/h2&gt;&lt;p&gt;So there's a trick to solve that optimization problem. Since the geometric margin is invariant to scaling, you can find some constants to scale w such that the functional margin &lt;code&gt;$min&amp;#40;y&amp;#94;{&amp;#40;i&amp;#41;}&amp;#41;&amp;#40;w&amp;#94;Tx&amp;#94;{&amp;#40;i&amp;#41;}+b&amp;#41; = 1$&lt;/code&gt;. Plugged into the optimization problem we had before, we get a convex function that can be optimized. &lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;kernels&quot;&gt;&lt;/a&gt;Kernels&lt;/h3&gt;&lt;p&gt;Essentially, the idea of a kernel is: &quot;sometimes you want to have a really ugly transformation on your feature vector.  And sometimes, you can find some other function and other matrix, such that dot-producting the two matrices together with the function is equivalent, but it's much easier to calculate.&quot;&lt;/p&gt;
</description>
<enclosure>

</enclosure>
<pubDate>
Mon, 24 Jul 2017 00:00:00 -0400
</pubDate>
</item>
<item>
<guid>
http://paultopia.github.io/posts-output/mathjax/
</guid>
<link>
http://paultopia.github.io/posts-output/mathjax/
</link>
<title>
Getting Mathjax to Play Nicely with Markdown and Highlight.js
</title>
<description>
&lt;p&gt;Mathjax and markdown tend to fight with one another a bit.  When I started blogging math notes on here, the combination of Mathjax and Cryogen's markdown parser and Highlight.js fought with one another a lot.  So here's a quick tutorial on fixing it.&lt;/p&gt;&lt;p&gt;The assumption here is that you want to write in normal markdown, i.e., the kind of thing that you could convert to a PDF with pandoc.  And you want to write latex math.  But you observe that doing so blows up when you convert to html and use mathjax.&lt;br /&gt;&lt;/p&gt;&lt;p&gt;My fix definitely works for me, using &lt;a href='http://cryogenweb.org/'&gt;Cryogen&lt;/a&gt;, but YMMV if you use some other markdown parser/static site generator. &lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;step&amp;#95;1:&amp;#95;basic&amp;#95;setup&quot;&gt;&lt;/a&gt;Step 1: Basic Setup&lt;/h3&gt;&lt;p&gt;Mathjax isn't set up out of the box to recognize the delimiters typically used in Markdown for latex blocks.  So you need to tweak the Mathjax config. &lt;a href='https://github.com/paultopia/experimental-cryogen/blob/master/resources/templates/themes/nucleus/html/base.html#L105'&gt;Here's how I did it&lt;/a&gt;:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;javascript&quot;&gt;&amp;lt;script type=&amp;quot;text/x-mathjax-config&amp;quot;&amp;gt;
 MathJax.Hub.Config&amp;#40;{tex2jax: {inlineMath: &amp;#91;&amp;#91;'$','$'&amp;#93;&amp;#93;,
                               displayMath: &amp;#91;&amp;#91;'$$','$$'&amp;#93;&amp;#93;,
                               processEscapes: true,
                               skipTags: &amp;#91;&amp;quot;script&amp;quot;,&amp;quot;noscript&amp;quot;,&amp;quot;style&amp;quot;,&amp;quot;textarea&amp;quot;&amp;#93;
 }}&amp;#41;;
&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Important parts: pass it the $ delimiters for both inline and display (block) math.  Also, change the skipTags setting, because the &lt;a href='http://docs.mathjax.org/en/latest/options/tex2jax.html'&gt;default&lt;/a&gt; skips pre and code blocks, which you don't want &amp;mdash; the next step will have you putting latex in a code block, and if you don't change this setting, then Mathjax will decline to process those blocks.&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;first&amp;#95;problem:&amp;#95;superscript&amp;#95;and&amp;#95;such.&amp;#95;&amp;#95;stick&amp;#95;it&amp;#95;in&amp;#95;a&amp;#95;code&amp;#95;block.&quot;&gt;&lt;/a&gt;First Problem: Superscript and Such.  Stick it in a code block.&lt;/h3&gt;&lt;p&gt;A number of the characters used in LaTeX (look, I gave it the silly capitalization! No more.) have their own meaning in Markdown; I have particular problems with superscript and subscript. One possible solution is to just escape them all, but that gets really ugly really quick.  An easier fix is just to stick everything in a code block. &lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;second&amp;#95;problem:&amp;#95;syntax&amp;#95;highlighting.&quot;&gt;&lt;/a&gt;Second problem: syntax highlighting.&lt;/h3&gt;&lt;p&gt;So if you also use Highlight.js, then it turns out that putting latex in codeblocks means that it'll try to identify the language (incorrectly) and add a bunch of highlighter classes for the css.  Which, naturally, again blows up mathjax rendering.&lt;br /&gt;&lt;/p&gt;&lt;p&gt;The solution there is to slap a nohighlight class on the block-level code blocks (blessedly, highlight.js doesn't seem to tamper with inline code blocks). &lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;third&amp;#95;problem:&amp;#95;what&amp;#95;if&amp;#95;you&amp;#95;want&amp;#95;to&amp;#95;mangle&amp;#95;your&amp;#95;markdown&amp;#95;by&amp;#95;hand?&quot;&gt;&lt;/a&gt;Third problem: what if you want to mangle your markdown by hand?&lt;/h3&gt;&lt;p&gt;All this stuff seems like extra typing.  I don't like extra typing.  So ultimately, what I did was write &lt;a href='https://github.com/paultopia/experimental-cryogen/blob/master/preprocess-math.cljs'&gt;a preprocessor&lt;/a&gt; that takes a normal markdown file (plus the cryogen header information). It's really quite simple, it just loads the file, looks for a &quot;mathy&quot; header, and, if it finds one, sticks all the latex into appropriate code blocks.&lt;/p&gt;&lt;p&gt;Here are the guts:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;defn fix-inline-math &amp;#91;post&amp;#93;
  {:text &amp;#40;replace &amp;#40;:text post&amp;#41; #&amp;quot;&amp;#91;&amp;#94;$&amp;#93;&amp;#40;\$&amp;#91;&amp;#94;$&amp;#93;+?\$&amp;#41;&amp;#91;&amp;#94;$&amp;#93;&amp;quot; &amp;quot; `$1` &amp;quot;&amp;#41; :filename &amp;#40;:filename post&amp;#41;}&amp;#41;

&amp;#40;defn fix-block-math &amp;#91;post&amp;#93;
  {:text 
   &amp;#40;replace &amp;#40;:text post&amp;#41; #&amp;quot;&amp;#91;&amp;#94;$&amp;#93;&amp;#40;\$\$&amp;#91;&amp;#94;$&amp;#93;+?\$\$&amp;#41;&amp;#91;&amp;#94;$&amp;#93;&amp;quot; &amp;quot;\n\n```nohighlight \n $1 \n```\n\n&amp;quot;&amp;#41;
   :filename &amp;#40;:filename post&amp;#41;}&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Easy.&lt;/p&gt;
</description>
<enclosure>

</enclosure>
<pubDate>
Mon, 24 Jul 2017 00:00:00 -0400
</pubDate>
</item>
<item>
<guid>
http://paultopia.github.io/posts-output/unidiomaticpython/
</guid>
<link>
http://paultopia.github.io/posts-output/unidiomaticpython/
</link>
<title>
Avoiding Inheritance Through Really Unidiomatic Python
</title>
<description>
 &lt;p&gt;So, confession: my brain works in a functional way, and really doesn't work in an object-oriented way. This can be a bit of an issue when you're using an object-oriented language and trying to avoid excessive code duplication.&lt;br /&gt;&lt;/p&gt;&lt;p&gt;So here's some really unnatural stuff I just did. The problem: I'm writing a Python library to wrap a bunch of legal and political APIs with a simpler interface. (&lt;a href='https://github.com/paultopia/lawpy'&gt;Extreme work in progress.&lt;/a&gt;)  I had a bunch of code that looked very similar. For example, this was what two of my session objects (interfaces to different APIs) looked like, in relevant part:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;python&quot;&gt;class courtlistener&amp;#40;object&amp;#41;:
    def &amp;#95;&amp;#95;init&amp;#95;&amp;#95;&amp;#40;self, api&amp;#95;key=&amp;quot;ENV&amp;quot;&amp;#41;:
        if api&amp;#95;key == &amp;quot;ENV&amp;quot;:
            try:
                self.api&amp;#95;key = os.environ&amp;#91;'COURTLISTENER'&amp;#93;
            except KeyError as e:
                raise Exception&amp;#40;&amp;quot;API key is missing. Please set the COURTLISTENER environment variable or pass the key to the session constructor.&amp;quot;&amp;#41; from e
        else:
            self.api&amp;#95;key = api&amp;#95;key
        self.auth&amp;#95;header = {'Authorization': 'Token ' + self.api&amp;#95;key}
        self.total&amp;#95;requests&amp;#95;this&amp;#95;session = 0

    def request&amp;#40;self, endpoint=&amp;quot;&amp;quot;, headers={}, parameters=None&amp;#41;:
        if endpoint.startswith&amp;#40;&amp;quot;https://&amp;quot;&amp;#41;:
            ep = endpoint
        else:
            ep = &amp;quot;https://www.courtlistener.com/api/rest/v3/&amp;quot; + endpoint
        h = {}
        h = safe&amp;#95;merge&amp;#40;h, headers&amp;#41;
        h = safe&amp;#95;merge&amp;#40;h, self.auth&amp;#95;header&amp;#41;
        result = requests.get&amp;#40;ep, headers=h, params=parameters&amp;#41;
        self.total&amp;#95;requests&amp;#95;this&amp;#95;session += 1
        result.raise&amp;#95;for&amp;#95;status&amp;#40;&amp;#41;
        return result.json&amp;#40;&amp;#41;

class propublica&amp;#40;object&amp;#41;:
    def &amp;#95;&amp;#95;init&amp;#95;&amp;#95;&amp;#40;self, api&amp;#95;key=&amp;quot;ENV&amp;quot;&amp;#41;:
        if api&amp;#95;key == &amp;quot;ENV&amp;quot;:
            try:
                self.api&amp;#95;key = os.environ&amp;#91;'PROPUBLICA'&amp;#93;
            except KeyError as e:
                raise Exception&amp;#40;&amp;quot;API key is missing. Please set the COURTLISTENER environment variable or pass the key to the session constructor. You can get an API key directly from courtlistner.com by registering on their website.&amp;quot;&amp;#41; from e
        else:
            self.api&amp;#95;key = api&amp;#95;key
        self.auth&amp;#95;header = {'X-API-Key': self.api&amp;#95;key}
        self.total&amp;#95;requests&amp;#95;this&amp;#95;session = 0

    def request&amp;#40;self, endpoint=&amp;quot;&amp;quot;, headers={}, parameters=None&amp;#41;:
        if endpoint.startswith&amp;#40;&amp;quot;https://&amp;quot;&amp;#41;:
            ep = endpoint
        else:
            ep = &amp;quot;https://api.propublica.org/congress/v1/&amp;quot; + endpoint
        h = {}
        h = safe&amp;#95;merge&amp;#40;h, headers&amp;#41;
        h = safe&amp;#95;merge&amp;#40;h, self.auth&amp;#95;header&amp;#41;
        result = requests.get&amp;#40;ep, headers=h, params=parameters&amp;#41;
        self.total&amp;#95;requests&amp;#95;this&amp;#95;session += 1
        result.raise&amp;#95;for&amp;#95;status&amp;#40;&amp;#41;
        return result.json&amp;#40;&amp;#41;

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Ugh, horrible, right?  The only difference between those two chunks of code is a URL and the name of an environment variable. Each class, of course, has other stuff too&amp;mdash;methods specific to the API that the class wraps, natch&amp;mdash;but that stuff is just pure fat that needs to be trimmed.  (FYI, for those who are checking, &lt;code&gt;safe&amp;#95;merge&lt;/code&gt; is just a utility function I have in there to merge two dicts without overwriting data with empty stuff, mutating the originals, etc.)&lt;/p&gt;&lt;p&gt;So how do we fix this?  I imagine that the standard OOP solution would involve either creating some kind of higher-level class, maybe call it baserequest or something, and give that most of the architecture, and subclass it for courtlistener and propublica. Or, I guess, use some kind of explicit object composition. &lt;/p&gt;&lt;p&gt;But I'm really only using classes here at all because I want other people to use this library, and I think people kinda expect the surface area of a library like this to be &quot;initialize an object then call methods on it to get and manipulate your data.&quot; But for the internal implementation details, I'm a lot more comfortable with functional idioms, even if they're unidiomatic in python. So here's the solution I came up with: &lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;python&quot;&gt;def session&amp;#95;builder&amp;#40;selfvar, keyenv&amp;#41;:
    def class&amp;#95;init&amp;#40;selfvar, api&amp;#95;key=&amp;quot;ENV&amp;quot;&amp;#41;:
        if api&amp;#95;key == &amp;quot;ENV&amp;quot;:
            try:
                selfvar.api&amp;#95;key = os.environ&amp;#91;keyenv&amp;#93;
            except KeyError as e:
                raise Exception&amp;#40;&amp;quot;API token is missing. Please set the {} environment variable or pass the token to the session constructor.&amp;quot;.format&amp;#40;keyenv&amp;#41;&amp;#41; from e
        else:
            selfvar.api&amp;#95;key = api&amp;#95;key
        selfvar.auth&amp;#95;header = {'X-API-Key': selfvar.api&amp;#95;key}
        selfvar.total&amp;#95;requests&amp;#95;this&amp;#95;session = 0
    return class&amp;#95;init

def request&amp;#95;builder&amp;#40;selfvar, baseurl&amp;#41;:
    def request&amp;#40;selfvar, endpoint=&amp;quot;&amp;quot;, headers={}, parameters=None&amp;#41;:
        if endpoint.startswith&amp;#40;&amp;quot;https://&amp;quot;&amp;#41;:
            ep = endpoint
        else:
            ep = baseurl + endpoint
        h = {}
        h = safe&amp;#95;merge&amp;#40;h, headers&amp;#41;
        h = safe&amp;#95;merge&amp;#40;h, selfvar.auth&amp;#95;header&amp;#41;
        result = requests.get&amp;#40;ep, headers=h, params=parameters&amp;#41;
        selfvar.total&amp;#95;requests&amp;#95;this&amp;#95;session += 1
        result.raise&amp;#95;for&amp;#95;status&amp;#40;&amp;#41;
        return result.json&amp;#40;&amp;#41;
    return request

class propublica&amp;#40;object&amp;#41;:

    def &amp;#95;&amp;#95;init&amp;#95;&amp;#95;&amp;#40;self&amp;#41;:
        session&amp;#95;builder&amp;#40;self, &amp;quot;PROPUBLICA&amp;quot;&amp;#41;&amp;#40;self&amp;#41;

    def request&amp;#40;self, endpoint=&amp;quot;&amp;quot;, headers={}, parameters=None&amp;#41;:
        return request&amp;#95;builder&amp;#40;self, &amp;quot;https://api.propublica.org/congress/v1/&amp;quot;&amp;#41;&amp;#40;self, endpoint, headers, parameters&amp;#41;

class courtlistener&amp;#40;object&amp;#41;:
    def &amp;#95;&amp;#95;init&amp;#95;&amp;#95;&amp;#40;self&amp;#41;:
        session&amp;#95;builder&amp;#40;self, &amp;quot;COURTLISTENER&amp;quot;&amp;#41;&amp;#40;self&amp;#41;

    def request&amp;#40;self, endpoint=&amp;quot;&amp;quot;, headers={}, parameters=None&amp;#41;:
        return request&amp;#95;builder&amp;#40;self, &amp;quot;https://www.courtlistener.com/api/rest/v3/&amp;quot;&amp;#41;&amp;#40;self, endpoint, headers, parameters&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;(Please ignore the bug for now in that I forgot that the details of the auth header also change across APIs, that gets fixed below and isn't germane to the key point.)&lt;/p&gt;&lt;p&gt;Can we have a hearty &lt;em&gt;BWAHAHAHAHAAHAHA!!!!!&lt;/em&gt;?  Look at all that code I get to delete, and I get to leave off lots more code as I add more APIs! &lt;/p&gt;&lt;p&gt;So what this is doing is that for each of these methods, it's taking an externally defined function and closing over the class-specific data (the URLs, environment variables for API keys, etc.), then immediately invoking them (javascript-style, I suppose). &lt;/p&gt;&lt;p&gt;However, this solution isn't perfect either.  First of all, it's adding some overhead, since it actually creates a new function every time the request method is called, and immediately invokes it. Apparently there's a version that &lt;a href='https://stackoverflow.com/a/38549072/4386239'&gt;leverages more of Python's internals&lt;/a&gt;, but that seems, to me, less readable?  (Probably more readable to more pythonic people.)&lt;/p&gt;&lt;p&gt;This is more difficult because python does some kind of magic with passing the instance in with self.  I tried to go around the problem by defining request within the constructor, i.e.: &lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;python&quot;&gt;def session&amp;#95;builder&amp;#40;selfvar, keyenv, baseurl&amp;#41;:
    def class&amp;#95;init&amp;#40;selfvar, api&amp;#95;key=&amp;quot;ENV&amp;quot;&amp;#41;:
        if api&amp;#95;key == &amp;quot;ENV&amp;quot;:
            try:
                selfvar.api&amp;#95;key = os.environ&amp;#91;keyenv&amp;#93;
            except KeyError as e:
                raise Exception&amp;#40;&amp;quot;API token is missing. Please set the {} environment variable or pass the token to the session constructor.&amp;quot;.format&amp;#40;keyenv&amp;#41;&amp;#41; from e
        else:
            selfvar.api&amp;#95;key = api&amp;#95;key
        selfvar.auth&amp;#95;header = {'X-API-Key': selfvar.api&amp;#95;key}
        selfvar.total&amp;#95;requests&amp;#95;this&amp;#95;session = 0
        selfvar.request = request&amp;#95;builder&amp;#40;selfvar, baseurl&amp;#41;
    return class&amp;#95;init
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;but apparently the python magic didn't go far enough to pass the self variable to a method defined that way: &lt;code&gt;TypeError: request&amp;#40;&amp;#41; missing 1 required positional argument: 'selfvar'&lt;/code&gt;.  Alas.&lt;/p&gt;&lt;p&gt;However, it occurred to me that I don't &lt;em&gt;really&lt;/em&gt; need the request method to mess with any internal state in the object it belongs to. I was tracking request counts only in order to squash a bug several iterations of the method ago, and that's the only thing that really requires getting at any state. So, why not rewrite to be completely free of internal state, and just close over the authentication information as well?&lt;/p&gt;&lt;p&gt;Thus, the final code! &lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;python&quot;&gt;def request&amp;#95;builder&amp;#40;auth&amp;#95;header, baseurl&amp;#41;:
    def request&amp;#40;endpoint=&amp;quot;&amp;quot;, headers={}, parameters=None&amp;#41;:
        if endpoint.startswith&amp;#40;&amp;quot;https://&amp;quot;&amp;#41;:
            ep = endpoint
        else:
            ep = baseurl + endpoint
        h = {}
        h = safe&amp;#95;merge&amp;#40;h, headers&amp;#41;
        h = safe&amp;#95;merge&amp;#40;h, auth&amp;#95;header&amp;#41;
        result = requests.get&amp;#40;ep, headers=h, params=parameters&amp;#41;
        result.raise&amp;#95;for&amp;#95;status&amp;#40;&amp;#41;
        return result.json&amp;#40;&amp;#41;
    return request

def session&amp;#95;builder&amp;#40;selfvar, keyenv, baseurl, keyheader, key&amp;#95;prefix=&amp;quot;&amp;quot;&amp;#41;:
    def class&amp;#95;init&amp;#40;selfvar, api&amp;#95;key=&amp;quot;ENV&amp;quot;&amp;#41;:
        if api&amp;#95;key == &amp;quot;ENV&amp;quot;:
            try:
                selfvar.api&amp;#95;key = os.environ&amp;#91;keyenv&amp;#93;
            except KeyError as e:
                raise Exception&amp;#40;&amp;quot;API token is missing. Please set the {} environment variable or pass the token to the session constructor.&amp;quot;.format&amp;#40;keyenv&amp;#41;&amp;#41; from e
        else:
            selfvar.api&amp;#95;key = api&amp;#95;key
        auth&amp;#95;header = {keyheader: key&amp;#95;prefix + selfvar.api&amp;#95;key}
        selfvar.request = request&amp;#95;builder&amp;#40;auth&amp;#95;header, baseurl&amp;#41;
    return class&amp;#95;init
    
class courtlistener&amp;#40;object&amp;#41;:

    def &amp;#95;&amp;#95;init&amp;#95;&amp;#95;&amp;#40;self&amp;#41;:
        session&amp;#95;builder&amp;#40;self, &amp;quot;COURTLISTENER&amp;quot;, &amp;quot;https://www.courtlistener.com/api/rest/v3/&amp;quot;, 'Authorization', 'Token '&amp;#41;&amp;#40;self&amp;#41;

class propublica&amp;#40;object&amp;#41;:

    def &amp;#95;&amp;#95;init&amp;#95;&amp;#95;&amp;#40;self&amp;#41;:
        session&amp;#95;builder&amp;#40;self, &amp;quot;PROPUBLICA&amp;quot;, &amp;quot;https://api.propublica.org/congress/v1/&amp;quot;, 'X-API-Key'&amp;#41;&amp;#40;self&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now it's even more stateless and functional, has even fewer lines of code, and allows the effortless creation of wrappers for authentication and basic requests for the other APIs I want to wrap. Plus if I want to add more error handling or whatnot to the requests, I can do it all in one place.  With no subclassing. &lt;/p&gt;&lt;p&gt;Unidiomatic functional programming in Python! &lt;/p&gt;
</description>
<enclosure>

</enclosure>
<pubDate>
Mon, 17 Jul 2017 00:00:00 -0400
</pubDate>
</item>
<item>
<guid>
http://paultopia.github.io/posts-output/ng5/
</guid>
<link>
http://paultopia.github.io/posts-output/ng5/
</link>
<title>
Mathy Ng Lecture 5: generative learning algorithms, naive bayes
</title>
<description>
&lt;h2&gt;&lt;a name=&quot;ng&amp;#95;lecture&amp;#95;5:&amp;#95;generative&amp;#95;learning&amp;#95;algorithms&quot;&gt;&lt;/a&gt;Ng lecture 5: generative learning algorithms&lt;/h2&gt;&lt;h3&gt;&lt;a name=&quot;the&amp;#95;idea&amp;#95;of&amp;#95;generative&amp;#95;algorithms&quot;&gt;&lt;/a&gt;The idea of generative algorithms&lt;/h3&gt;&lt;p&gt;Algorithms like logistic regression are like &quot;try to find a straight line that separate the classes best.&quot; Those are discriminative learning algorithms.&lt;/p&gt;&lt;p&gt;By contrast, imagine an algorithm that finds all the examples of class x and builds a model of what those look, then finds all the examples of class y and builds a model of what those look like; classification then becomes &quot;let's see what our new observation looks like.&quot;&lt;/p&gt;&lt;p&gt;So that's a generative learning algorithm.&lt;/p&gt;&lt;p&gt;More formally: &lt;/p&gt;&lt;p&gt;Discriminative algorithm learns p(y|x) directly by learning a hypothesis function &lt;code&gt;$h&amp;#40;\theta&amp;#41;$&lt;/code&gt; that outputs a label in the range of 0 to 1. &lt;/p&gt;&lt;p&gt;By contrast, a generative algorithm models p(x|y) and p(y).  It builds a model of what the features look like conditioned on the class label.&lt;/p&gt;&lt;p&gt;Then Bayes rule steps in, because of course it does. &lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;gaussian&amp;#95;discriminant&amp;#95;analysis:&quot;&gt;&lt;/a&gt;Gaussian discriminant analysis:&lt;/h3&gt;&lt;p&gt;Assumes input features are continuous-values random variables and p(x|y) is multivariate gaussian. &lt;/p&gt;&lt;p&gt;Models the response as a bernoulli. &lt;/p&gt;&lt;p&gt;Features are modeled as a separate distribution for each value of y, i.e., p(x|y=0) is one distribution with mean &lt;code&gt;$\mu&amp;#95;0$&lt;/code&gt;  p(x|y=1) is another distribution with mean &lt;code&gt;$\mu&amp;#95;1$&lt;/code&gt;  Leaving off the likelihood derivations.  The practical implication is that GDA is like logistic regression, but has the stronger assumptions, and if those assumptions are satisfied, is likely to produce better performance.&lt;/p&gt;&lt;p&gt;This is something that's true of generative models in general: you have to make modeling assumptions about your features, and if those are right, then you've got a better fitting model. See pg. 7-8 of &lt;a href='https://see.stanford.edu/materials/aimlcs229/cs229-notes2.pdf'&gt;notes 2&lt;/a&gt;.&lt;br /&gt;&lt;/p&gt;&lt;p&gt;It turns out that if p(x|y) = 1  and p(x|y) = 0 are both in an exponential family distribution (the same one?), p(y|x) is logistic.&lt;/p&gt;&lt;p&gt;Notation note: the squiggle brackets around the y=1 i the maximum likelihood estimates are indicator notation, they indicate that it's essentially a counter, that increments once for each time that the variable is 1.  In other words, the value within the summation of the squiggly thing is 1 if the appropriate y is 1 for y=1, and so forth.  So it's really just a bunch of averages.&lt;/p&gt;&lt;p&gt;Prediction it's in the lecture at 23:00ish.  You predict the value of y (argmax with respect to y) that maximizes P(y|x), which, by bayes rule and some algebra, turns into argmax y p(x|y)p(y). &lt;/p&gt;&lt;p&gt;Essentially, you're building a model of p(x|y=1), a model of p(x|y=0), and fit a bernoilli to p(y) basically just by taking the average of y's incidences in the observation. &lt;/p&gt;&lt;p&gt;Much more simple and straightforward version: what he gives us is just a closed-form solution, like the matrix multiplication in regression.  We have the maximum likelihood function (page 6 of &lt;a href='https://see.stanford.edu/materials/aimlcs229/cs229-notes2.pdf'&gt;notes 2&lt;/a&gt;) and we seriously just plug our data into it.  Then we have [an estimate of] the probability distribution of y, and ditto for x|y=0 and x|y=1. Given that information, and some x, we can plug in an observed value for x into the distributions we got from our training, and hence have point estimates on all those distributions. Then from those point estimates, we apply bayes rule.  (Or at least I think this is how it goes.)&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;naive&amp;#95;bayes&quot;&gt;&lt;/a&gt;Naive bayes&lt;/h3&gt;&lt;p&gt;The conditional independence across the x's assumption is, well, false, like always. (That's the naive part.)  But it works surprisingly well for, e.g., classifying text documents.&lt;br /&gt;&lt;/p&gt;&lt;p&gt;The idea of this kind of text classification is a bag of words might have, like, 50,000 distinct words, far too many features to fit to a multinomial or something in your spam classifier. &lt;/p&gt;&lt;p&gt;But with the conditional independence assumption you can just assume the probability of all your x's given y is just the product of each individual conditional probability of xi|y.&lt;/p&gt;&lt;p&gt;Unsurprisingly, the maximum likelihood estimate for the word j conditional on being spam is just the proportion of e-mails that had that word and were spam within the e-mails that were spam... this is just basic probability. &lt;/p&gt;&lt;p&gt;And, again, the probability of y is just the proportion of spam e-mails in the dataset.&lt;/p&gt;&lt;p&gt;and then you compute p(y|x) with bayes rule &lt;/p&gt;&lt;p&gt;So I'm guessing that to actually predict, you compute the product of the p(x|y) for all x, and that's the joint probability of p(y|x) thanks to the conditional independence assumption, then bayes rule gives you your prediction right away.  This is almost comically easy.&lt;/p&gt;&lt;p&gt;Also, here's &lt;a href='https://www.youtube.com/watch?v=TpjPzKODuXo&amp;list=PL6397E4B26D00A269&amp;index=26'&gt;another explanation&lt;/a&gt; of how Naive Bayes works by more Stanford profs Dan Jurafsky &amp; Chris Manning (and &lt;a href='https://www.youtube.com/watch?v=0hxaqDbdIeE&amp;index=27&amp;list=PL6397E4B26D00A269'&gt;second part&lt;/a&gt;).&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;laplace&amp;#95;smoothing&quot;&gt;&lt;/a&gt;Laplace smoothing&lt;/h3&gt;&lt;p&gt;What happens when you try to classify something with a word that wasn't in your training set?  Oh boy, you're dividing by zero when you apply bayes rule. That's bad.  (The numerator is 0 too thanks to some products.  Bad.)&lt;/p&gt;&lt;p&gt;So what we just do is, instead of calculating the probability p(xi|y=1) with the raw proportion, we add 1 to the numerator and k, where k is the number of possible values for xi (i.e., 2, with all these dichotomous variables we're working with). (or is it possible values for y? should investigate.)  And we do that with our other maximum likelihood estimators too. Essentially we just add 1 to every count, including the counts in the denominator.  That keeps the probabilities of unseen events from being 0, which is nice, but keeps the good statistical properties.&lt;/p&gt;&lt;p&gt;(question: why don't we just drop words that don't appear in the training data from our predictions?  Answer, after chatting with a fellow Recurser: because it's not just that unseen features in the training set will generate zero posterior probabilities, but also that if a feature hasn't been seen in &lt;em&gt;just one&lt;/em&gt; of the classes, that will make the probability for that class go to zero.  So you'd have to drop more than just words that never appeared, you'd have to throw out all words that appeared only in one class, which would toss out a ton of useful information.)&lt;/p&gt;&lt;p&gt;So I take naive bayes to be, from start to finish:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;load documents and labels&lt;/li&gt;&lt;li&gt;create set of all words in documents&lt;/li&gt;&lt;li&gt;for each word, create feature as appears/does not appear number of times that word appears in the given document.  (In the Dan Jurafsky &amp; Chris Manning version, it's a bit more complex because they use counts rather than indicators.)&lt;/li&gt;&lt;li&gt;then for each word, &quot;train&quot; by creating vector of conditional probabilities for each class, i.e., probability of word x given class 1, probability of word x given class 2, etc.  This is calculated by simple proportion, i.e., number of documents in the class in which the word appears, divided by count of documents in the class. See page 10 of &lt;a href='https://see.stanford.edu/materials/aimlcs229/cs229-notes2.pdf'&gt;notes 2&lt;/a&gt; for the formal version.  This can probably be stored in some kind of hash. (The Dan Jurafsky &amp; Chris Manning version has slightly different calculations because they're using counts rather than binary features, but I think I like the Ng version better.)&lt;/li&gt;&lt;li&gt;Remember to do previous step with laplace smoothing. (add 1 to each numerator, and 2 to each denominator for binary feature)&lt;/li&gt;&lt;li&gt;then for a prediction, just take every word, then, for each class multiply out the conditional probabilities for each word given that class and the class, and divide by the overall probability of that data, as shown on the last formula on page 10 of the notes. Then predict the class where that product is highest. If an unknown word appears, it just gets the conditional probability 1/2 or whatever other laplace denominator you use for every class, thanks to smoothing.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Possible correction: should step 2 (dictionary creation) be based on all words in existing training set, or based on a preexisting dictionary s.t. we assign uninformative priors via laplace smoothing to words that don't appear in training set right from start?  This might just be a matter of choice/convenience for improving the model over time? &lt;/p&gt;
</description>
<enclosure>

</enclosure>
<pubDate>
Mon, 17 Jul 2017 00:00:00 -0400
</pubDate>
</item>
<item>
<guid>
http://paultopia.github.io/posts-output/haskell-debug-bgd/
</guid>
<link>
http://paultopia.github.io/posts-output/haskell-debug-bgd/
</link>
<title>
A Debugging Trek, and: (naive) Batch Gradient Descent in Haskell
</title>
<description>
&lt;p&gt;So I implemented &lt;a href='https://paultopia.github.io/posts-output/ng1/'&gt;batch gradient descent&lt;/a&gt; in Haskell, to simultaneously solidify my understanding of the algorithm and work on learning Haskell. &lt;/p&gt;&lt;p&gt;It got a bit bumpy. I've preserved my &lt;a href='https://github.com/paultopia/haskeml/blob/master/notes.md'&gt;realtime notes&lt;/a&gt; of the mess. But the short version is that after a certain number of iterations that was an increasing function the learning rate, the model would just terminate in weights of Infinity for all features. &lt;/p&gt;&lt;p&gt;So!  Debugging.&lt;br /&gt;&lt;/p&gt;&lt;p&gt;Step 1: get some more eyeballs. A kindly recurser pointed out that the argument orders to one of my functions was switched. This is the kind of thing that Haskell is supposed to avoid, but when everything is of type [Double] I guess one can hardly rely on the type checker to catch that it's the wrong one, can one?&lt;br /&gt;&lt;/p&gt;&lt;p&gt;Alas, that wasn't the bug. I was just multiplying two lists together elementwise, and since multiplication is commutative, well.&lt;/p&gt;&lt;p&gt;Step 2: implement in an easier language first.  With math-y code that produces wildly incorrect results, there are really two possibilities: either the code is buggy or the code is fine but my understanding of the math is wrong.  (Or both, I suppose.)  The second possibility seemed easier to eliminate first&amp;mdash;with correct math, one can get evidence supporting the proposition that the code is correct from getting correct results, but it doesn't really work the other way around unless there's some way of proving code correctness other than testing. So. &lt;/p&gt;&lt;p&gt;So I &lt;a href='https://github.com/paultopia/haskeml/blob/master/python-reference-bgd-implementation.ipynb'&gt;re-implemented the algorithm in python&lt;/a&gt;, complete with lots of slow and careful idiot-checking print statements. Somewhere in the middle, I realized that I hadn't scaled the features in the Haskell version (alas, that didn't turn out to be the bug either, but it did kindly turn my lists of &lt;code&gt;Infinity&lt;/code&gt; into lists of &lt;code&gt;NaN&lt;/code&gt;). The Python version produced reasonable results. So that's great, my math is good. Back to the Haskell.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Then I dug into the Haskell.  Not knowing how to insert the equivalent of &lt;code&gt;printf&lt;/code&gt; statements into this language&amp;mdash;do you need an IO type or something??&amp;ndash; I was at a loss for a while.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;It turns out that ghci &lt;a href='https://downloads.haskell.org/~ghc/7.4.1/docs/html/users_guide/ghci-debugger.html'&gt;has a debugger&lt;/a&gt;, which I played around with for a while, but it wasn't terribly enlightening&amp;mdash;it's a bit involved, and could use more study. &lt;/p&gt;&lt;p&gt;Then I discovered that there is a printf equivalent.  Because of course there is.  It's in the magic &lt;a href='https://hackage.haskell.org/package/base-4.9.1.0/docs/Debug-Trace.html'&gt;Debug.Trace&lt;/a&gt; library. And it's extra magical: you can just stick a call to &lt;code&gt;traceShow&lt;/code&gt; in front of whatever code you want to look at, and you'll get to see whatever values you pass it.&lt;/p&gt;&lt;p&gt;With that, it didn't take me long to find my bug.  I successively logged 20 iterations of all the interesting parameters to my gradient descent function, and soon discovered that on each iteration of the gradient, the error was monotonically increasing, rather than decreasing. Which obviously isn't right.&lt;br /&gt;&lt;/p&gt;&lt;p&gt;The obvious hypothesis there is that a sign got flipped somewhere.  And, lo and behold, after looking at the relevant part of the code, inside the gradient descent summation where I meant to be subtracting the label from the hypothesis, I actually was subtracting the hypothesis from the label. &lt;/p&gt;&lt;p&gt;Subtraction, alas, is not commutative. &lt;/p&gt;&lt;p&gt;Anyway, here's the fixed code!&lt;br /&gt;&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;haskell&quot;&gt;module Olsgradient where
import Data.List
default &amp;#40;Double&amp;#41;

addIntercept :: &amp;#91;&amp;#91;Double&amp;#93;&amp;#93; -&amp;gt; &amp;#91;&amp;#91;Double&amp;#93;&amp;#93;
addIntercept = map &amp;#40;\x -&amp;gt; 1.0:x&amp;#41;

predict :: &amp;#91;&amp;#91;Double&amp;#93;&amp;#93; -&amp;gt; &amp;#91;Double&amp;#93; -&amp;gt; &amp;#91;Double&amp;#93;
predict observations weights =
  let mult = map &amp;#40;\x -&amp;gt; zipWith &amp;#40;&amp;#42;&amp;#41; x weights&amp;#41; observations
  in map sum mult

subtractMaker :: Double -&amp;gt;  &amp;#91;Double&amp;#93; -&amp;gt; &amp;#91;Double&amp;#93; -&amp;gt; Double
subtractMaker learnRate costs featureList =
  let costFeatureMult = zipWith &amp;#40;&amp;#42;&amp;#41; costs featureList
  in learnRate &amp;#42; sum costFeatureMult

gradientStep :: Double -&amp;gt; &amp;#91;Double&amp;#93; -&amp;gt; &amp;#91;Double&amp;#93; -&amp;gt; &amp;#91;&amp;#91;Double&amp;#93;&amp;#93; -&amp;gt; &amp;#91;Double&amp;#93;
gradientStep learnRate labels weights observations =
  let preds = predict observations weights
      costs = zipWith &amp;#40;-&amp;#41; preds labels
      featureMatrix = transpose observations
      subtractors = map &amp;#40;subtractMaker learnRate costs&amp;#41; featureMatrix
  in zipWith &amp;#40;-&amp;#41; weights subtractors

innerTrainOLS :: &amp;#91;&amp;#91;Double&amp;#93;&amp;#93; -&amp;gt; &amp;#91;Double&amp;#93; -&amp;gt; &amp;#91;Double&amp;#93; -&amp;gt; Double -&amp;gt; Double -&amp;gt; Double -&amp;gt; Double -&amp;gt; &amp;#91;Double&amp;#93;
innerTrainOLS observations labels weights learnRate threshold maxIter numIter 
  | numIter &amp;gt; maxIter = weights
  | sse &amp;lt; threshold = weights
  | otherwise = innerTrainOLS observations labels newWeights learnRate threshold maxIter &amp;#40;numIter + 1&amp;#41;
  where
    preds = predict observations weights
    sse = sum $ map &amp;#40;&amp;#42;&amp;#42;2.0&amp;#41; &amp;#40;zipWith &amp;#40;-&amp;#41; labels preds&amp;#41;
    newWeights = gradientStep learnRate labels weights observations

trainOLS :: &amp;#91;&amp;#91;Double&amp;#93;&amp;#93; -&amp;gt; &amp;#91;Double&amp;#93; -&amp;gt; Double -&amp;gt; Double -&amp;gt; Double -&amp;gt; &amp;#91;Double&amp;#93;
trainOLS observations labels learnRate threshold maxIter =
  let obvs = addIntercept observations
      numFeats = length $ head obvs
      initweights = replicate numFeats 1
  in innerTrainOLS obvs labels initweights learnRate threshold maxIter 0

mean :: &amp;#91;Double&amp;#93; -&amp;gt; Double
mean lst = sum lst / fromIntegral &amp;#40;length lst&amp;#41;

standardDeviation :: &amp;#91;Double&amp;#93; -&amp;gt; Double
standardDeviation lst =
  let m = mean lst
      n = length lst
      squaredErrors = map &amp;#40;\x -&amp;gt; &amp;#40;x - m&amp;#41; &amp;#42;&amp;#42; 2.0&amp;#41; lst
  in sqrt &amp;#40;sum squaredErrors / fromIntegral n&amp;#41;

scale :: &amp;#91;Double&amp;#93; -&amp;gt; &amp;#91;Double&amp;#93;
scale lst =
  let m = mean lst
      stdev = standardDeviation lst
  in map &amp;#40;\x -&amp;gt; &amp;#40;x - m&amp;#41; / stdev&amp;#41; lst
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Note how smelly it is.  For example, &lt;code&gt;innerTrainOLS :: &amp;#91;&amp;#91;Double&amp;#93;&amp;#93; -&amp;gt; &amp;#91;Double&amp;#93; -&amp;gt; &amp;#91;Double&amp;#93; -&amp;gt; Double -&amp;gt; Double -&amp;gt; Double -&amp;gt; Double -&amp;gt; &amp;#91;Double&amp;#93;&lt;/code&gt; is like legit stink.  But it does the job for now, and cleanup can come later. :-) &lt;/p&gt;
</description>
<enclosure>

</enclosure>
<pubDate>
Mon, 17 Jul 2017 00:00:00 -0400
</pubDate>
</item>
<item>
<guid>
http://paultopia.github.io/posts-output/ng3/
</guid>
<link>
http://paultopia.github.io/posts-output/ng3/
</link>
<title>
Mathy Ng Lecture 4: Newton's Method, Exponential Family Distributions, GLMs
</title>
<description>
&lt;h2&gt;&lt;a name=&quot;ng&amp;#95;lecture&amp;#95;4:&amp;#95;newton's&amp;#95;method,&amp;#95;exponential&amp;#95;family&amp;#95;distributions,&amp;#95;glms.&quot;&gt;&lt;/a&gt;Ng Lecture 4: Newton's Method, Exponential Family Distributions, GLMs.&lt;/h2&gt;&lt;h3&gt;&lt;a name=&quot;newton's&amp;#95;method&quot;&gt;&lt;/a&gt;Newton's Method&lt;/h3&gt;&lt;p&gt;Motivation for Newton's method: suppose you have a nonlinear function of &lt;code&gt;$\theta$&lt;/code&gt; and you want to figure out at what value of &lt;code&gt;$\theta$&lt;/code&gt; it == 0.&lt;/p&gt;&lt;p&gt;One strategy is just to pick an arbitrary &lt;code&gt;$\theta&amp;#94;{&amp;#40;0&amp;#41;}$&lt;/code&gt;  calculate &lt;code&gt;$f&amp;#40;\theta&amp;#94;{&amp;#40;o&amp;#41;}&amp;#41;$&lt;/code&gt;  and then compute a derivative there in order to get a linear approximation to f, i.e., get a tangent line at that point.  Then extend the tangent line until it extends to the horizontal axis and call that &lt;code&gt;$\theta&amp;#94;{&amp;#40;1&amp;#41;}$&lt;/code&gt; (i.e., solve the linear approximation function &lt;code&gt;$f'&amp;#40;\theta&amp;#94;{&amp;#40;1&amp;#41;}&amp;#41; = 0$&lt;/code&gt; . That's one iteration. And then keep repeating that with a tangent line to &lt;code&gt;$\theta&amp;#94;{&amp;#40;1&amp;#41;}$&lt;/code&gt; and so forth.  This is Newton's method.&lt;/p&gt;&lt;p&gt;After a little algebra, this gives us an update rule for Newton's method:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;nohighlight&quot;&gt; $$\theta := \theta - \frac{f&amp;#40;\theta&amp;#41;}{f'&amp;#40;\theta&amp;#41;}$$ 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We can apply the same idea to maximizing the log-likelihood. If we have a likelihood function, we want to find the place where its derivative == 0. (Of course, that could also be a minimum. In the case of linear regression and such that shouldn't be a problem, because convex... right?) And we can apply the same update rule to that function ( where &quot;that function&quot; is the derivative of the likelihood function).  So, if &lt;code&gt;$\lambda$&lt;/code&gt; is the likelihood function, the update rule is:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;nohighlight&quot;&gt; $$\theta := \theta - \frac{\lambda'&amp;#40;\theta&amp;#41;}{\lambda''&amp;#40;\theta&amp;#41;}$$ 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In multiple dimensions, this turns into multiplying a matrix of first derivatives by the inverse of a matrix called the Hessian, which is a matrix of second derivatives.  See page 21 of &lt;a href='https://see.stanford.edu/materials/aimlcs229/cs229-notes1.pdf'&gt;lecture notes 1&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Usually this goes faster than gradient descent for small numbers of features, but if there are lots of features, be aware that the Hessian is a n+1/n+1 matrix (remembering that Ng uses n for number of features and m for number of rows), it can be computationally expensive.&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;generalized&amp;#95;linear&amp;#95;models&quot;&gt;&lt;/a&gt;Generalized Linear Models&lt;/h3&gt;&lt;p&gt;Some terminology. Bernoulli and Gaussian aren't single distributions but really lasses of distributions, depending on their parameters.  And both classes are in the family of &quot;exponential distributions.&quot;  So are lots of others&amp;mdash;Poisson, gamma, exponential, beta, Dirichlet are examples that he gives in the notes, but says there are also &quot;many more.&quot;&lt;/p&gt;&lt;p&gt;The point, leaving aside the derivations of how the Bernoilli and Gaussian are in the exponential family, is that you can construct a GLM for anything in the exponential family. So if you've got something where what you're trying to predict is well modeled by a Poisson, or a Dirichlet, or whatever, you're good. &lt;/p&gt;&lt;p&gt;Three assumptions of GLM: &lt;/p&gt;&lt;ol&gt;&lt;li&gt;Given inputs x and parameters &lt;code&gt;$\theta$&lt;/code&gt;  the response variable y is distributed in the exponential family with some natural parameter (see lecture notes 1 p. 22) &lt;code&gt;$\eta$&lt;/code&gt;&lt;/li&gt;&lt;li&gt;Given x, the goal is to output (as h(x)) the expected value of the sufficient statistic of y &lt;code&gt;$E&amp;#91;T&amp;#40;y&amp;#41;|x&amp;#93;$&lt;/code&gt;   Typically, &lt;code&gt;$T&amp;#40;y&amp;#41; = y$&lt;/code&gt; (see page 22 of lecture notes 1).&lt;/li&gt;&lt;li&gt;There's a linear relationship between the natural parameter and the inputs: &lt;code&gt;$\eta = \theta&amp;#94;Tx$&lt;/code&gt; (where the elements of &lt;code&gt;$\theta$&lt;/code&gt; just contain constants, not functions of x or something wild like that, I take it, or it needn't be linear...).&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;And judging from what happened at around minute 45, I take it that what you really just do is write the distribution as an exponential family, and then substitute &lt;code&gt;$\theta&amp;#94;Tx$&lt;/code&gt; for &lt;code&gt;$\eta$&lt;/code&gt;  And then what you get is the function for your hypothesis. See pp. 25-6 for examples of OLS and logistic. The reason we choose the sigmoid function for our hypothesis for the logistic is because we decided that the bernoulli distribution is a natural distribution to use to model these binary choices. &lt;/p&gt;&lt;p&gt;So: &lt;/p&gt;&lt;ol&gt;&lt;li&gt;Pick a distribution.&lt;/li&gt;&lt;li&gt;Formulate that distribution as an exponential family distribution.&lt;/li&gt;&lt;li&gt;Make use of assumption 3 above to swap out the eta.&lt;/li&gt;&lt;li&gt;Then you have your hypothesis.&lt;/li&gt;&lt;li&gt;Train by maximum likelihood.  How?  Take the log likelihood (reminder: that works because maximizing the likelihood can be done by maximizing a strictly increasing function of the likelihood) of the function giving the probability of response data given feature data paramaterized by theta, as before; see pg. 29-30 for an example re: softmax (Likelihood reminder: the product, over the training set, of probability of label given feature.). And then maximize it, using gradient or newton.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Where to actually find the likelihood function?  The heart of the idea goes back to pg. 18 of notes 1 in yesterday's material: the likelihood function starts by assuming that the hypothesis is correct, for some theta. That's what &quot;Let us assume that: &lt;code&gt;$P&amp;#40;y=1 | x;\theta&amp;#41; = h&amp;#95;\theta&amp;#40;x&amp;#41;$&lt;/code&gt; and &lt;code&gt;$P&amp;#40;y=0 | x;\theta&amp;#41; = 1 - h&amp;#95;\theta&amp;#40;x&amp;#41;$&lt;/code&gt;  says to us. So then in the later equations on pg. 18 we can substitute a function of the hypotheses (in the case of logit, a simple h and 1-h) for the probability of an individual outcome; the probability of all the outcomes at once is their product by standard probability theory.&lt;/p&gt;&lt;p&gt;Softmax, given at the end of the material today, is a generalization of logistic to multiple classes.  The hypothesis is a vector of probabilities for each class, based on the multinomial distribution.&lt;/p&gt;&lt;p&gt;An insight from the study group, discussing the previous lesson: &lt;/p&gt;&lt;p&gt;Why does the assumption that errors are normally distributed imply that the likelihood function on OLS is this gaussian thing?  Because if you hold x and &lt;code&gt;$\theta$&lt;/code&gt; constant, then the response has to be distributed the same way as the errors are. &lt;/p&gt;
</description>
<enclosure>

</enclosure>
<pubDate>
Fri, 07 Jul 2017 00:00:00 -0400
</pubDate>
</item>
<item>
<guid>
http://paultopia.github.io/posts-output/ng2/
</guid>
<link>
http://paultopia.github.io/posts-output/ng2/
</link>
<title>
Lecture 3 of Andrew Ng's mathier ML course
</title>
<description>
  &lt;h2&gt;&lt;a name=&quot;lecture&amp;#95;3&amp;#95;&amp;ndash;&amp;#95;locally&amp;#95;weighted&amp;#95;regression&quot;&gt;&lt;/a&gt;Lecture 3 &amp;ndash; locally weighted regression&lt;/h2&gt;&lt;p&gt;Nonparametric algorithms reduce &quot;the need to choose features very carefully&quot; (I guess that makes sense if you think of features as mathematical transformations on stuff observed rather than stuff observed in general... a nonparemetric algorithm surely can't avoid the fact that you left something off, though I guess it can help avoid the fact that you threw a bunch of extra stuff in...)&lt;/p&gt;&lt;p&gt;Formal definition of a nonparametric algorithm is an algorithm where the number of parameters grows with m.  Which also means it needs to hold onto the entire training set even after training. As a student said in questions, &quot;it's like you're not even really building a model at all.&quot; You just fit for every training example. (This seems really expensive!!)&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;locally&amp;#95;weighted&amp;#95;regression&amp;#95;(loess/lowss)&quot;&gt;&lt;/a&gt;Locally weighted regression (loess/lowss)&lt;/h3&gt;&lt;p&gt;Concept: consider a value for x, the vector of features, of a single observation. To make a prediction with OLS, we'd find the vector of weights (parameters) &lt;code&gt;$\theta$&lt;/code&gt; s.t. they minimize the cost function, then return &lt;code&gt;$\theta&amp;#94;tx$&lt;/code&gt; as prediction.&lt;/p&gt;&lt;p&gt;For loess, we'd take a region around x, and work on the subset of data around there. So, geometrically, rather than predicting y based a line fitted to the entire dataset, predicts y based a line fitted to a subset of the dataset around x.&lt;/p&gt;&lt;p&gt;formally, in loess we fit &lt;code&gt;$\theta$&lt;/code&gt; to minimize a weighted version of the same loss function we use in OLS, where the weights are chosen such that we give more weight to training examples closer to what we're trying to predict. &lt;/p&gt;&lt;p&gt;i.e., OLS minimizes: &lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;nohighlight&quot;&gt; $$\sum&amp;#95;i&amp;#40;y&amp;#94;{&amp;#40;i&amp;#41;}-\theta&amp;#94;Tx&amp;#94;{&amp;#40;i&amp;#41;}&amp;#41;&amp;#94;2$$ 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;while loess minimizes:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;nohighlight&quot;&gt; $$\sum&amp;#95;iw&amp;#94;{&amp;#40;i&amp;#41;}&amp;#40;y&amp;#94;{&amp;#40;i&amp;#41;}-\theta&amp;#94;Tx&amp;#94;{&amp;#40;i&amp;#41;}&amp;#41;&amp;#94;2$$ 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;the trick is in the definition of the weight function.  As I understand it it the fit is made at the time of prediction, so x without a subscript in the below is the value of the feature &lt;em&gt;for which you're trying to predict the output&lt;/em&gt; (and that's why you have to keep your training data around even after training, as Ng noted earlier. Do you even train at all in advance? Maybe there's some optimization trick that allows you to pre-train something? Kinda doubting it from the &quot;not even a model&quot; chat above.).  So with that preamble, the weight function is &lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;nohighlight&quot;&gt; $$w&amp;#94;{&amp;#40;i&amp;#41;}=e&amp;#94;{&amp;#40;-\frac{&amp;#40;x&amp;#94;{&amp;#40;i&amp;#41;}-x&amp;#41;&amp;#94;2}{2}&amp;#41;}$$ 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Actually, he said there are lots of possible weight functions, but the point is to have something that gets close to zero when &lt;code&gt;$x&amp;#94;{&amp;#40;i&amp;#41;}$&lt;/code&gt; is far from x and close to 1 when they're close together.  Which, obviously, this satisfies.&lt;/p&gt;&lt;p&gt;A more common form of the weight is&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;nohighlight&quot;&gt; $$w&amp;#94;{&amp;#40;i&amp;#41;}=e&amp;#94;{&amp;#40;-\frac{&amp;#40;x&amp;#94;{&amp;#40;i&amp;#41;}-x&amp;#41;&amp;#94;2}{2\tau&amp;#94;2}&amp;#41;}$$ 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;where tau is a &quot;bandwidth parameter&quot; that controls the rate at which the weighting function falls off with distance from x.&lt;/p&gt;&lt;p&gt;Another student question: this is indeed very costly, &quot;every time you make a prediction you need to fit theta to your entire training set again.&quot; However, &quot;turns out there are ways to make this much more efficient.&quot; He referred to &lt;a href='http://www.ri.cmu.edu/pub_files/pub1/moore_andrew_1991_1/moore_andrew_1991_1.pdf'&gt;Andrew Moore's kd-trees&lt;/a&gt; as this method.&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;probabilistic&amp;#95;interpretation&amp;#95;of&amp;#95;linear&amp;#95;regression&quot;&gt;&lt;/a&gt;Probabilistic interpretation of linear regression&lt;/h3&gt;&lt;p&gt;Why are we minimizing the sum of squared error as opposed to the absolute value or something? Assumptions that make this work. (Oh boy, are we going to do BLUE again?  Might skim past this.)&lt;/p&gt;&lt;p&gt;First we &quot;endow the least squares model with probabilistic semantics.&quot;&lt;/p&gt;&lt;p&gt;Yeah, this is the same stuff.  Assume y is a function of the model plus error, assume error is IID and distributed normally with mean zero, all the good social science stats stuff I already know. Then we do the standard probability and algebra and get the maximum likelihood estimator, which turns out to be the OLS cost function.  And that was like a whole class in grad school. The central limit theorem came up, as it does. All the good stuff. For his derivation, see pages 11-13 of &lt;a href='https://see.stanford.edu/materials/aimlcs229/cs229-notes1.pdf'&gt;lecture notes 1&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;There is one useful notation note though.  Semicolon indicates not a random variable but as something we're trying to estimate in the world, i.e. this: &lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;nohighlight&quot;&gt; $$P&amp;#40;y&amp;#94;{&amp;#40;i&amp;#41;}|x&amp;#94;{&amp;#40;i&amp;#41;};\theta&amp;#41;$$ 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;indicates &quot;the probability of &lt;code&gt;$y&amp;#94;{&amp;#40;i&amp;#41;}$&lt;/code&gt; conditioned on &lt;code&gt;$x&amp;#94;{&amp;#40;i&amp;#41;}$&lt;/code&gt;  as parameterized by &lt;code&gt;$\theta$&lt;/code&gt; &quot; while this:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;nohighlight&quot;&gt; $$P&amp;#40;y&amp;#94;{&amp;#40;i&amp;#41;}|x&amp;#94;{&amp;#40;i&amp;#41;},\theta&amp;#41;$$ 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;means &quot;the probability of &lt;code&gt;$y&amp;#94;{&amp;#40;i&amp;#41;}$&lt;/code&gt; conditioned on &lt;code&gt;$x&amp;#94;{&amp;#40;i&amp;#41;}$&lt;/code&gt; and &lt;code&gt;$\theta$&lt;/code&gt; &quot; which is wrong, because theta isn't a random variable, it's a property of the world we're trying to estimate (in frequentist terms).&lt;/p&gt;&lt;p&gt;The conditional probability (the correct one) = the likelihood function, only y gets an arrow (to indicate it's observed?). So maximum likelihood.&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;classification&quot;&gt;&lt;/a&gt;Classification&lt;/h3&gt;&lt;p&gt;Started off with standard stuff, instead of choosing a linear function, we choose a nonlinear function.  And for logistic regression, that's the sigmoid function, a.k.a. the logistic function: &lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;nohighlight&quot;&gt; $$h&amp;#95;\theta&amp;#40;x&amp;#41; = \frac{1}{1 + e&amp;#94;{-\theta&amp;#94;Tx}}$$ 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;One important point is that for logistic gradient descent we're actually ascending, that is, we're trying to maximize not minimize, so we add the gradient rather than subtract it.&lt;/p&gt;&lt;p&gt;Interestingly, it comes out to the same update rule with the sign swapped when the dust settles. It's not the same math because the function that generates the hypothesis is obviously different (the linear function vs the logistic function), but it has the same functional form.  Logistic gradient ascent update rule:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;nohighlight&quot;&gt; $$\theta&amp;#95;j : = \theta&amp;#95;j + \alpha &amp;#40;y&amp;#94;{&amp;#40;i&amp;#41;} - h&amp;#95;{\theta}&amp;#40;x&amp;#94;{&amp;#40;i&amp;#41;}&amp;#41;&amp;#41; \cdot x&amp;#95;j&amp;#94;{&amp;#40;i&amp;#41;}$$ 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Why does maximizing this work exactly?  It's just maximum likelihood again.  It turns out that for OLS, maximizing the likelihood function, after the math dust settles, is the same as minimizing the least squares cost function. (See notes pg. 13) But for logistic regression, when we &lt;em&gt;maximize&lt;/em&gt; the log likelihood of the parameters, the gradient ascent that we use to directly maximize the likelihood just simplifies to the same form. &lt;/p&gt;&lt;p&gt;(An explanation of why turned up elsewhere: logistic regression likelihood is concave. page 11 of &lt;a href='https://courses.cs.washington.edu/courses/cse547/16sp/slides/logistic-SGD.pdf'&gt;this&lt;/a&gt;)&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;digression&amp;#95;on&amp;#95;perceptrons&quot;&gt;&lt;/a&gt;digression on perceptrons&lt;/h3&gt;&lt;p&gt;a perceptron is just the same update rule but with this threshold function that maps positive values to 1 and negative values to 0 rather than logistic function's mapping of everything to the space from 0-1. &lt;/p&gt;&lt;p&gt;Hard to interpret perceptrons probabilistically though.&lt;/p&gt;
</description>
<enclosure>

</enclosure>
<pubDate>
Fri, 07 Jul 2017 00:00:00 -0400
</pubDate>
</item>
<item>
<guid>
http://paultopia.github.io/posts-output/ng1/
</guid>
<link>
http://paultopia.github.io/posts-output/ng1/
</link>
<title>
Lecture 2 of Andrew Ng's mathier ML course
</title>
<description>
 &lt;p&gt;One of the things I'm doing at &lt;a href='https://www.recurse.com/'&gt;RC&lt;/a&gt; is working through &lt;a href='https://see.stanford.edu/Course/CS229/54'&gt;the mathier version&lt;/a&gt; of Andrew Ng's famous machine learning course. Here are my notes from the first substantive lecture (lecture 2). &lt;/p&gt;&lt;p&gt;n.b. the math is all in code blocks because the markdown processor screws with underscores and carets otherwise, and mathjax can't handle that.  This is making me insane and I might actually write some kind of post-processor to jerk around the generated html files to fix this, but it'll have to do for now.&lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;lecture&amp;#95;2&quot;&gt;&lt;/a&gt;Lecture 2&lt;/h2&gt;&lt;p&gt;Linear regression, mostly stuff I've already seen a bunch of times, but with the derivations using weirder linear algebra than usual, and with more gradient descent and less closed-form solutions.&lt;/p&gt;&lt;p&gt;His notation: &lt;/p&gt;&lt;p&gt;m = number of training examples&lt;/p&gt;&lt;p&gt;x = features&lt;/p&gt;&lt;p&gt;y = output (labels/target)&lt;/p&gt;&lt;p&gt;(x, y) = training example&lt;/p&gt;&lt;p&gt;superscript i for indexing over examples.&lt;/p&gt;&lt;p&gt;h for model hypothesis &amp;mdash; it's the function mapping x-&gt;y &lt;/p&gt;&lt;p&gt;representing weights as $\theta$&lt;/p&gt;&lt;p&gt;n is the number of features&lt;/p&gt;&lt;p&gt;(Aaah, why not use n for the number of observations like scientists do?  Why can we not have consistent naming and notation in this world? Also, at some point when I was in grad school, we made a Stanford polisci t-shirt that had the slogan &quot;it's not the size of your n, it's how you use it.&quot; Where did that go? I miss that shirt.)&lt;/p&gt;&lt;p&gt;&lt;code&gt;$J&amp;#40;\theta&amp;#41;$&lt;/code&gt; is the sum of squared errors / 2.  (Apparently, from discussion afterward with mathier people, these get divided by 2 in order to make differentiation cleaner.)&lt;/p&gt;&lt;p&gt;Gradient descent algorithm:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;nohighlight&quot;&gt; $$\theta&amp;#95;i := \theta&amp;#95;i - \partial \frac{\partial}{\partial \theta} J&amp;#40;\theta&amp;#41;$$
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;that is, update the ith weight by subtracting the partial derivative of the cost (J(θ)) with respect to the ith weight (30:29 in video 2).&lt;/p&gt;&lt;p&gt;Calculus reminder: that &lt;a href='https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/partial-derivative-and-gradient-articles/a/introduction-to-partial-derivatives'&gt;partial derivative&lt;/a&gt; is essentially the magnitude of the change in the cost given an epsilon change in the weight at the given value of θ. &lt;/p&gt;&lt;p&gt;This &lt;a href='https://www.youtube.com/watch?v=i94OvYb6noo'&gt;lecture&lt;/a&gt; (suggested by a batch-mate) is also good on the gradients:&lt;/p&gt;&lt;p&gt;(Ng uses &lt;code&gt;:=&lt;/code&gt; to mean &quot;update the variable on the left by the algorithm on the right&quot;)&lt;/p&gt;&lt;p&gt;Ultimately, it's just taking a step in the direction of the (local) minimum error.&lt;/p&gt;&lt;p&gt;After doing the calculus, that turns into: &lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;nohighlight&quot;&gt;$$\theta&amp;#95;i : = \theta&amp;#95;i - \alpha &amp;#40;h&amp;#95;{\theta}&amp;#40;x&amp;#41; - y&amp;#41; \cdot x&amp;#95;i$$
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;where alpha is the learning rate (a model parameter). This is for one training example.&lt;/p&gt;&lt;p&gt;which is super convenient, since &lt;code&gt;$&amp;#40;h&amp;#95;{\theta}&amp;#40;x&amp;#41; - y&amp;#41;$&lt;/code&gt; is just the straightforward error at a given step.&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;batch&amp;#95;gradient&amp;#95;descent&quot;&gt;&lt;/a&gt;Batch gradient descent&lt;/h3&gt;&lt;p&gt;For m training examples, the algorithm just sums the error over the training examples, i.e.,&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;nohighlight&quot;&gt;$$\theta&amp;#95;i : = \theta&amp;#95;i - \alpha \sum&amp;#95;{j=1}&amp;#94;{m} &amp;#40;h&amp;#95;{\theta}&amp;#40;x&amp;#94;{&amp;#40;j&amp;#41;}&amp;#41; - y&amp;#94;{&amp;#40;j&amp;#41;}&amp;#41; \cdot x&amp;#95;i&amp;#94;{&amp;#40;j&amp;#41;}$$ 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;and then repeat until convergence&lt;/p&gt;&lt;p&gt;For OLS, there's only one global minimum, it's just a quadratic function that (therefore?) is &quot;bow-shaped&quot; (I've never understood these visual analogies on functions, but I take it that this is a good thing, and maybe means the same thing as convex??  Convexity is the property we discussed in our little group afterwards, so probably.  Note to self, really need to understand convexity and what it entails lots better.), and so no nasty local minima.&lt;/p&gt;&lt;p&gt;(Terminology reminder: gradient = derivative. &lt;a href='https://math.stackexchange.com/questions/1519367/difference-between-gradient-and-jacobian'&gt;Essentially&lt;/a&gt;.)&lt;/p&gt;&lt;p&gt;It turns out that this computation is the direction of steepest descent, for reasons that Ng doesn't feel like proving. &lt;/p&gt;&lt;p&gt;This is called &quot;batch gradient descent&quot; because at every step of gradient descent you look at the whole dataset, perform a sum over m training examples.&lt;/p&gt;&lt;p&gt;That's problematic if you have a ton of training examples.  So there's an alternative:&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Stochastic Gradient Descent&lt;/strong&gt; (a.k.a. &quot;incremental descent&quot;)&lt;/p&gt;&lt;p&gt;repeat until convergence: &lt;pre&gt;&lt;code&gt;for j = 1 to m: 
    perform an update using just the jth training example &amp;#40;for each i&amp;#41; 
 &lt;/code&gt;&lt;/pre&gt;&lt;/p&gt;&lt;p&gt;that update is just&lt;br /&gt;&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;nohighlight&quot;&gt; $$\theta&amp;#95;i : = \theta&amp;#95;i - \alpha &amp;#40;h&amp;#95;{\theta}&amp;#40;x&amp;#94;{&amp;#40;j&amp;#41;}&amp;#41; - y&amp;#94;{&amp;#40;j&amp;#41;}&amp;#41; \cdot x&amp;#95;i&amp;#94;{&amp;#40;j&amp;#41;}$$
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;in practice, this tends to go rather faster for large datasets. It doesn't actually converge exactly to the global minimum, but they tend to wander close to it. &lt;/p&gt;&lt;p&gt;Question I had: what's stochastic about this? It's not like it's actually randomly sampling the data or anything. In discussion afterward, someone said that it's called stochastic because it's based on the idea that the expectation of the update on a single observation is the same as the expectation on the update on the whole thing, which makes sense well enough to me.&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;closed&amp;#95;form&amp;#95;solution&amp;#95;of&amp;#95;theta&quot;&gt;&lt;/a&gt;Closed form solution of theta&lt;/h3&gt;&lt;p&gt;More new notation, for matrix derivatives. I mostly let this go by, because I feel like I've learned this derivation once already, courtesy of grad school, and I don't feel the need to do it again with different linear algebra. But reference: &lt;a href='https://see.stanford.edu/materials/aimlcs229/cs229-notes1.pdf'&gt;part 1 of his lecture notes&lt;/a&gt; on pg. 8.&lt;/p&gt;&lt;p&gt;A few points of interest: explanation of the stuff in the notes:&lt;/p&gt;&lt;p&gt;delta J, J is a function of vector parameters theta, recall. The derivative of J with respect to theta is itself a vector of partial derivatives, a n+1 dimensional vector. So then we can rewrite the batch gradient example as theta (not subscripted&amp;mdash;it's the whole thing, update the whole paramerer) minus that big gradient, i.e., &lt;code&gt;$\theta := \alpha \nabla&amp;#95;\theta J$&lt;/code&gt; &amp;ndash;and all of those quantities are N+1dimensional vectors. (except alpha, obvs)&lt;/p&gt;&lt;p&gt;Definition that feel like a bit of linear algebra I skipped: if A is a square matrix, the &lt;em&gt;trace&lt;/em&gt; of A is the sum of A's diagonal elements. &lt;code&gt;$tr A = \sum&amp;#95;{i=1}&amp;#94;n A&amp;#95;{ii}$&lt;/code&gt; Which sounds like skipped-over linear algebra to me.&lt;/p&gt;&lt;p&gt;Ultimately this leads to the classic closed form solution to OLS, which shows up on pg. 11 of part 1 of lecture notes. &lt;/p&gt;&lt;p&gt;Also might be worth noting (from video at 1:00) that the &quot;design matrix&quot; is a matrix that has the training examples input values on the rows.  In notes and on chalkboards, there's a very confusing notation with dashes and an unexplained superscript with a  T in it... but I take it that the first row is the vector of features for first training example, second row is for second draining example (from video at 1:01).&lt;/p&gt;&lt;p&gt;Then design matrix multiplied by theta vector is just the hypotheses for a given set of weights.  And the error is going to be elementwise subtracting the elements of the y vector (label vector, which gets an arrow over it in the notes like &lt;code&gt;$\overrightarrow{y}$&lt;/code&gt;).&lt;/p&gt;&lt;p&gt;Anyway, classic closed form: &lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;nohighlight&quot;&gt; $$\theta = &amp;#40;X&amp;#94;TX&amp;#41;&amp;#94;{-1}X&amp;#94;T\overrightarrow{y}$$
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This is our old friend OLS. Hello OLS. You're also &lt;a href='https://github.com/paultopia/browser-stats/blob/master/statspop/src/statspop/math/regression.cljs#L15'&gt;enjoyably easy to implement in clojurescript&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Note at the end of the lecture in response to a student question: usually, if &lt;code&gt;$X&amp;#94;TX$&lt;/code&gt; isn't invertible, it's because you've got dependent features in there, like repeating the same feature twice or something. (or linear combination, I take it? Standard OLS blow-up...)&lt;/p&gt;&lt;p&gt;that's it!&lt;/p&gt;&lt;p&gt;(note to self for future: to get mathml and highlight.js and this markdown parser to play nicely together, math has to be in code blocks, but those code blocks have to be either inline or they have to get the &lt;code&gt;nohighlight&lt;/code&gt; class; in the latter case there apparently needs to be whitespace after the class declaration on the code block or for some mysterious reason it'll get a bunch of other classes instead, god only knows why.)&lt;/p&gt;
</description>
<enclosure>

</enclosure>
<pubDate>
Fri, 07 Jul 2017 00:00:00 -0400
</pubDate>
</item>
<item>
<guid>
http://paultopia.github.io/posts-output/game-as-tree/
</guid>
<link>
http://paultopia.github.io/posts-output/game-as-tree/
</link>
<title>
Translating Game Theory Backward Induction into a Tree Algorithm
</title>
<description>
&lt;p&gt;I know a lot more about game theory than I do about graphs/trees/etc. (Political scientist, yo.) So here's an attempt at a translation of the idea of backwards induction into tree terms. &lt;/p&gt;&lt;p&gt;First, intuition/background: backwards induction is a method for finding subgame perfect equilibria of a sequential game in extensive form. (For simplicity, let's assume a perfect information game.) The short version is that, starting at the terminal node, you set the last player's choice for that node as the choice that yields the best they can achieve given the history of play leading up to that node. With that information, you now know the values for each choice of the second-to-last node for the second-to-last player, so set their choice to that. And so on, inductively. &lt;/p&gt;&lt;p&gt;This is pretty easily represented in code terms. An extensive form game is just a &lt;a href='https://stackoverflow.com/questions/7423401/whats-the-difference-between-the-data-structure-tree-and-graph'&gt;tree&lt;/a&gt;. So you can represent your extensive form game as a tree of depth n (I don't know if &quot;depth&quot; is a term of art for trees, but I mean that a lone node has depth 1, a parent with children that have no children themselves id depth 2, and so forth), such that the first choice is the root node, then its children are the paths from that decision, so forth.  So then you can just take the nodes at depth n-1 and replace them by the max of their children, and keep doing that until you reach the top node. Obviously, you also need to keep a bit of state somewhere that builds up the path through the tree, and there you go, you have your equilibrium. &lt;/p&gt;&lt;p&gt;The cool thing is that when you get backward induction, the idea generalizes to other kinds of problems. For example, there's a project Euler problem that asks you to find the maximum value path from top to bottom of a pyramid of numbers that maximizes the sum of the numbers in that path.  Something like this: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;    4
   5 9
  7 9 5
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;where the answer would be 22 (4-9-9).  Only, you know, much bigger.&lt;/p&gt;&lt;p&gt;When you realize that this is just a tree with the same kind of maximization problem, backwards induction is the obvious solution. Taking the n-1th row, each element can either terminate in the element to its below-left or its below-right; since you want to find the max, you can just update the elements in the n-1th row by the max of what it can terminate in. Then you can forget about the nth row and treat the n-1th row as the terminal row. Then apply the same procedure to update the n-2th row, and so on.&lt;/p&gt;&lt;p&gt;So, in the toy example above, the first round of updating looks like this: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;    4
  14 18
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;that is, 5 becomes &lt;code&gt;5 + max&amp;#40;7, 9&amp;#41;&lt;/code&gt;, 9 becomes &lt;code&gt;9 + max&amp;#40;9, 5&amp;#41;&lt;/code&gt; and so forth.&lt;/p&gt;&lt;p&gt;In python:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;python&quot;&gt;with open&amp;#40;&amp;quot;pyramid.txt&amp;quot;&amp;#41; as tf:
    pyramid&amp;#95;pre = tf.readlines&amp;#40;&amp;#41;

pyramid = &amp;#91;map &amp;#40;int, x.split&amp;#40;&amp;quot; &amp;quot;&amp;#41;&amp;#41; for x in pyramid&amp;#95;pre&amp;#93;

def update&amp;#95;values&amp;#40;pyramid&amp;#41;:
    lastrow = len&amp;#40;pyramid&amp;#41; - 2
    for x in range&amp;#40;lastrow, -1, -1&amp;#41;:
        row&amp;#95;length = x + 1
        for y in range&amp;#40;row&amp;#95;length&amp;#41;:
            pyramid&amp;#91;x&amp;#93;&amp;#91;y&amp;#93; = pyramid&amp;#91;x&amp;#93;&amp;#91;y&amp;#93; + max&amp;#40;pyramid&amp;#91;x + 1&amp;#93;&amp;#91;y&amp;#93;, pyramid&amp;#91;x + 1&amp;#93;&amp;#91;y + 1&amp;#93;&amp;#41;
    return pyramid&amp;#91;0&amp;#93;&amp;#91;0&amp;#93;

print&amp;#40;update&amp;#95;values&amp;#40;pyramid&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I assume there's a standard tree-traversal algorithm that CS people use for this kind of problem, curious whether it looks like the game theorist's backward induction or there's a better way.  But this way does the job!&lt;/p&gt;
</description>
<enclosure>

</enclosure>
<pubDate>
Thu, 06 Jul 2017 00:00:00 -0400
</pubDate>
</item>
<item>
<guid>
http://paultopia.github.io/posts-output/flexbox-iconbar/
</guid>
<link>
http://paultopia.github.io/posts-output/flexbox-iconbar/
</link>
<title>
A Flexbox Trick for Responsive Icon Screens
</title>
<description>
&lt;p&gt;Here's a trick I just cooked up (well, it's probably widely known by, like, everyone on earth who regularly does css stuff, but I just discovered it for me, so I'll take a tiny bit of credit.).&lt;br /&gt;&lt;/p&gt;&lt;p&gt;Suppose you want to start off your site with an icon screen, like an iPhone or something.  (I'm actually basing the design of my new website, in progress, on the old Palm Pilot home screen.  Though I just moved away from the green, so maybe not anymore.)&lt;/p&gt;&lt;p&gt;Some devices have fairly wide screens, others have narrow but relatively long screens. If you have, say, six icons, it would be nice to be able to lay that out in two rows of 3 icons each on wide screens, and three rows of two icons each on narrow screens (like smartphones).&lt;/p&gt;&lt;p&gt;With flexbox you can do that, by setting up two layers of flex, and switching the direction within the layers.&lt;/p&gt;&lt;p&gt;Here's how.  First, create an outer div, and then break up your icons (or whatever elements) into equally sized inner containers. Like this:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;html&quot;&gt;
&amp;lt;div class=&amp;quot;outercontainer&amp;quot;&amp;gt;

&amp;lt;div class=&amp;quot;innercontainer&amp;quot;&amp;gt;
&amp;lt;img src=&amp;quot;icon1&amp;quot;&amp;gt;
&amp;lt;img src=&amp;quot;icon2&amp;quot;&amp;gt;
&amp;lt;/div&amp;gt;

&amp;lt;div class=&amp;quot;innercontainer&amp;quot;&amp;gt;
&amp;lt;img src=&amp;quot;icon3&amp;quot;&amp;gt;
&amp;lt;img src=&amp;quot;icon4&amp;quot;&amp;gt;
&amp;lt;/div&amp;gt;

&amp;lt;div class=&amp;quot;innercontainer&amp;quot;&amp;gt;
&amp;lt;img src=&amp;quot;icon5&amp;quot;&amp;gt;
&amp;lt;img src=&amp;quot;icon6&amp;quot;&amp;gt;
&amp;lt;/div&amp;gt;


&amp;lt;/div&amp;gt;

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then with your CSS, you'll set a breakpoint for small screens and a breakpoint for bigger screens, and in them, you'll switch the directions of the flex on the outer and the inner containers, as follows:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;css&quot;&gt;
.outercontainer {
    display: flex;
    justify-content: space-around;
    align-items: stretch;
}

.bigsubcontainer {
    display: flex;
    justify-content: space-around;
    align-items: stretch;
}

/&amp;#42; wide screens &amp;#42;/

@media &amp;#40;min-width: 700px&amp;#41; {

    .outercontainer {
        flex-direction: row;
    }

    .bigsubcontainer {
        flex-direction: column;
    }
}

/&amp;#42; narrow screens &amp;#42;/

@media &amp;#40;max-width: 700px&amp;#41; {

    .outercontainer {
        flex-direction: column;
    }

    .innercontainer {
        flex-direction: row;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;How does this magic work?  Well, the wide screen media query says &quot;hey outer flexbox container, treat your children as columns.&quot; Since there are three children to the outer flexbox container, there are three columns.  Then it says &quot;hey inner flexbox container, treat your children as rows.&quot;  Since each inner flexbox container has two children, it means there will be two rows. And vice versa for the narrow-screen media query. &lt;/p&gt;&lt;p&gt;The result: &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;/img/little-flexbox.png&quot; alt=&quot;Little Screen&quot; /&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;/img/big-flexbox.png&quot; alt=&quot;Big Screen&quot; /&gt;&lt;/p&gt;&lt;p&gt;Complete control over the number of elements that appear in each row, with only a couple lines of code!&lt;/p&gt;
</description>
<enclosure>

</enclosure>
<pubDate>
Sat, 17 Jun 2017 00:00:00 -0400
</pubDate>
</item>
<item>
<guid>
http://paultopia.github.io/posts-output/mustache-latex/
</guid>
<link>
http://paultopia.github.io/posts-output/mustache-latex/
</link>
<title>
How to Make Mustache.js Templates Play Nice with LaTeX
</title>
<description>
&lt;p&gt;I'm trying to achieve the holy grail and have a LaTeX cv that gets automatically updated from JSON, like &lt;a href='https://jsonresume.org/'&gt;Jsonresume&lt;/a&gt;, only with my own custom fields appropriate for someone who does the wild variety of things I do. I'm terrible at LaTeX, but there are plenty of templates floating around, and there's a great new project, &lt;a href='https://latexresu.me/'&gt;Latexresu.me&lt;/a&gt;, that appeared on show HN recently&amp;mdash;it's awesome, try it&amp;mdash;and I just used it to shamelessly steal some stubs to build from.&lt;/p&gt;&lt;p&gt;This is part of an overall website overhaul for me: I'm building an entirely new personal website using &lt;a href='https://vuejs.org'&gt;Vue&lt;/a&gt; that will allow people to do things like generate bibibtex or ris entries for my publications, etc.&amp;mdash;basically all kinds of technological overkill for what most people use a static site for. All client-side rendering, even binary files shoved into the webpack bundle as data URIs, all that ridiculousness. &lt;/p&gt;&lt;p&gt;So, since I'm deep into javascript-land anyway, I decided to template the .tex file using &lt;a href='https://www.npmjs.com/package/mustache'&gt;Mustache.js&lt;/a&gt; and compile it with &lt;a href='https://www.npmjs.com/package/node-latex'&gt;Node-Latex&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;It turns out, however, that Mustache does HTML-escaping on every string passed into it. For example, the string &lt;code&gt;foo/bar&lt;/code&gt; in the JSON data that I'm trying to use to build my cv gets mangled into &lt;code&gt;foo&amp;amp;#x2F;bar&lt;/code&gt; in the template. And this is, alas, totally unacceptable because &lt;code&gt;&amp;amp;&lt;/code&gt; is a &lt;a href='https://tex.stackexchange.com/questions/34580/escape-character-in-latex'&gt;reserved character&lt;/a&gt; in LaTeX.&lt;/p&gt;&lt;p&gt;The Mustache docs aren't terribly helpful on the subject. They give two ways to unescape strings, both of which are very inconvenient here: &lt;/p&gt;&lt;ol&gt;&lt;li&gt;Use a &quot;triple Mustache&quot; &amp;mdash; i.e. &lt;code&gt;{{{foo}}}&lt;/code&gt;.  The problem is that if you're templating LaTeX, this isn't going to do a lot of good, because if you're in your right mind at all, you'll have created a custom delimiter, so as to not be forced to distingish between LaTeX curly brackets and Mustache curly brackets.  And there isn't a documented way to change what characters count as a triple mustache (though maybe you can?).&lt;/li&gt;&lt;li&gt;Add an ampersand before the string you want to unescape&amp;mdash; i.e. &lt;code&gt;{{&amp;amp;foo}}&lt;/code&gt;.  This plays nicely with custom delimiters, but has the inconvenient result of forcing you to manually unescape every single string you put in the template&amp;mdash;since if you're templating LaTeX, rather than HTML, chances are that you won't want to escape &lt;em&gt;anything&lt;/em&gt;.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Fortunately, there's an undocumented solution.  After digging through &lt;a href='https://github.com/janl/mustache.js/issues/244'&gt;some&lt;/a&gt; &lt;a href='https://github.com/janl/mustache.js/issues/307'&gt;issues&lt;/a&gt; with people complaining about this behavior, it turns out that someone kindly decided &lt;a href='https://github.com/janl/mustache.js/blob/master/mustache.js#L622'&gt;expose the function used to escape HTML to users&lt;/a&gt;, so that you can just override it in client code. &lt;/p&gt;&lt;p&gt;Since this isn't really documented anywhere, and since even the issues don't make clear how to use the fix that was eventually proposed and accepted (the proposed fix had user code modifying &lt;code&gt;Mustache.escapeHTML&lt;/code&gt;, but user code actually needs to modify &lt;code&gt;Mustache.escape&lt;/code&gt;), here's a quick example of how to sensibly use Mustache.js with LaTeX.&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;javascript&quot;&gt;const latex = require&amp;#40;'node-latex'&amp;#41;;
const fs = require&amp;#40;'fs'&amp;#41;;
const Mustache = require&amp;#40;'mustache'&amp;#41;;

// First, let's change the delimiter so that we can use &amp;lt;&amp;lt;foo&amp;gt;&amp;gt; instead of {{foo}} in LaTeX documents.

Mustache.tags = &amp;#91; '&amp;lt;&amp;lt;', '&amp;gt;&amp;gt;' &amp;#93;;

// Here's the fix! A simple function to override the escape function provided by Mustache.

Mustache.escape = text =&amp;gt; text;

// The greeting would blow up LaTeX rendering if escaped, but now that we've overridden the escape, it will work just fine.
const data = {greeting: &amp;quot;Hello/World&amp;quot;};

const template = &amp;quot;\\documentclass{article}\ \n \\begin{document} \n &amp;lt;&amp;lt;greeting&amp;gt;&amp;gt; \n \\end{document} &amp;quot;;
const input = Mustache.render&amp;#40;template, data&amp;#41;;
const output = fs.createWriteStream&amp;#40;'hello-tex.pdf'&amp;#41;;

latex&amp;#40;input&amp;#41;.pipe&amp;#40;output&amp;#41;;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That will just get rid of HTML encoding.  But you're not quite done yet, if you want to use LaTeX.  What if the text you want to put into the template itself has LaTeX reserved characters?&lt;/p&gt;&lt;p&gt;Here's a more robust fix.  Instead of &lt;code&gt;Mustache.escape = text =&amp;gt; text;&lt;/code&gt; in the above, you can set the escape function to something that escapes LaTeX reserved characters. I've defined a &lt;code&gt;latexEscaper&lt;/code&gt; below that can be dropped right in.:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;javascript&quot;&gt;var matches = new Map&amp;#40;&amp;#91;&amp;#91;&amp;quot;\\&amp;quot;, &amp;quot;textbackslash&amp;quot;&amp;#93;,
                       &amp;#91;&amp;quot;&amp;#126;&amp;quot;,&amp;quot;textasciitilde&amp;quot;&amp;#93;,
                       &amp;#91;&amp;quot;&amp;#94;&amp;quot;,&amp;quot;textasciicircum&amp;quot;&amp;#93;&amp;#93;&amp;#41;;

var messytext = &amp;quot;I shouldn't be escaped / \n I should be: $ \n and I should be a special LaTeX command: &amp;#94;&amp;quot;

function latexEscaper&amp;#40;text&amp;#41;{
		return text.replace&amp;#40;/&amp;#91;\\&amp;#126;\&amp;#94;%&amp;amp;$#&amp;#95;{}&amp;#93;/g, 
                    match =&amp;gt; &amp;quot;\\&amp;quot; +  &amp;#40;matches.get&amp;#40;match&amp;#41; || match&amp;#41;&amp;#41;;}
		console.log&amp;#40;latexEscaper&amp;#40;messytext&amp;#41;&amp;#41;;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And then your template should produce valid LaTeX, or at least as valid as LaTeX ever is...&lt;/p&gt;&lt;p&gt;Now, if you'll excuse me, I think I go need to do a PR to turn this from undocumented into documented...&lt;/p&gt;
</description>
<enclosure>

</enclosure>
<pubDate>
Sun, 11 Jun 2017 00:00:00 -0400
</pubDate>
</item>
<item>
<guid>
http://paultopia.github.io/posts-output/python-r-textmining/
</guid>
<link>
http://paultopia.github.io/posts-output/python-r-textmining/
</link>
<title>
Python and R Resources for text-mining
</title>
<description>
 &lt;p&gt;This is just a growing collection of useful Python and R packages and resources for text-mining. It's the flavor of ML I'm working on the most, so this is mostly just for my own hassle-avoidance.   &lt;/p&gt;&lt;p&gt;Work in progress.  &lt;/p&gt;&lt;h1&gt;&lt;a name=&quot;python&quot;&gt;&lt;/a&gt;Python&lt;/h1&gt; &lt;h2&gt;&lt;a name=&quot;libraries&quot;&gt;&lt;/a&gt;Libraries&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;a href='http://www.nltk.org'&gt;NLTK&lt;/a&gt; &amp;mdash; the 1000-pound gorilla here.&lt;/li&gt;&lt;li&gt;&lt;a href='https://radimrehurek.com/gensim/'&gt;Gensim&lt;/a&gt; &amp;mdash; very frequently used topic modeling library, also has word2vec wrapper that seems to get a lot of usage.&lt;/li&gt;&lt;li&gt;&lt;a href='http://www.christianpeccei.com/textmining/'&gt;Textmining&lt;/a&gt; &amp;ndash; a very small library that creates DTMs and stuff.  A nice alternative to wading through tons of NLTK documentation.&lt;/li&gt;&lt;li&gt;&lt;a href='https://spacy.io'&gt;spaCY&lt;/a&gt; &amp;mdash; NLTK alternative, I've not tried it.&lt;/li&gt;&lt;li&gt;&lt;a href='https://textblob.readthedocs.io/en/dev/'&gt;TextBlob&lt;/a&gt; &amp;mdash; not used it, but it looks to do a very significant subset of common text processing tasks with a relatively rational-looking API.&lt;/li&gt;&lt;li&gt;&lt;a href='https://www.crummy.com/software/BeautifulSoup/bs4/doc/'&gt;BeautifulSoup&lt;/a&gt; &amp;mdash; the standard python library for getting your texts out of web pages (agonizingly complicated API, but, then again, that's probably the DOM's fault). Incidentally, you should really be using &lt;a href='http://docs.python-requests.org/en/master/'&gt;requests&lt;/a&gt; to actually send http requests for scraping.&lt;/li&gt;&lt;li&gt;&lt;a href='https://scrapy.org'&gt;Scrapy&lt;/a&gt; &amp;mdash; another important Python webscraping tool, I've actually never used it.&lt;/li&gt;&lt;li&gt;&lt;a href='https://github.com/amueller/word_cloud'&gt;wordcloud&lt;/a&gt; &amp;mdash; word clouds are always fun.  Kinda useless, but fun.&lt;/li&gt;&lt;li&gt;&lt;a href='http://www.clips.ua.ac.be/pattern'&gt;Pattern&lt;/a&gt; &amp;mdash; a library that combines web-scraping with some standard NLP tools.&lt;/li&gt;&lt;li&gt;&lt;a href='https://stanfordnlp.github.io/CoreNLP/other-languages.html#python'&gt;CoreNLP Wrappers&lt;/a&gt; Python wrappers for Stanford Core NLP.&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;a name=&quot;publications,&amp;#95;tutorials,&amp;#95;etc.&quot;&gt;&lt;/a&gt;Publications, Tutorials, etc.&lt;/h2&gt;&lt;p&gt;(to be added)  &lt;/p&gt;&lt;h1&gt;&lt;a name=&quot;r&quot;&gt;&lt;/a&gt;R&lt;/h1&gt; &lt;h2&gt;&lt;a name=&quot;libraries&quot;&gt;&lt;/a&gt;Libraries&lt;/h2&gt;&lt;p&gt;&lt;a href='https://cran.r-project.org/web/packages/tm/index.html'&gt;TM&lt;/a&gt; &amp;mdash; The classic package, but I hate it like sin. On the other hand, its agonizingly horrible API is the source of my &lt;a href='https://stackoverflow.com/questions/24771165/r-project-no-applicable-method-for-meta-applied-to-an-object-of-class-charact/29529990#29529990'&gt;most-upvoted Stack Overflow answer&lt;/a&gt;, so, thanks?  This package and strings-as-factors together drove my abandonment of R for Python.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href='https://github.com/kbenoit/quanteda'&gt;Quanteda&lt;/a&gt; &amp;mdash; Ken Benoit's TM alternative.&lt;/li&gt;&lt;li&gt;&lt;a href='https://github.com/juliasilge/tidytext'&gt;tidytext&lt;/a&gt; &amp;mdash; I haven't used this yet, but given the authors (Robinson and Silge), it's probably amazing.&lt;/li&gt;&lt;li&gt;&lt;a href='https://github.com/ThomasK81/ToPan'&gt;ToPan&lt;/a&gt; &amp;mdash; a cool batteries included topic modeling Shiny app specifically designed for topic modeling in ancient languages.&lt;/li&gt;&lt;li&gt;&lt;a href='https://cran.r-project.org/web/packages/lda/index.html'&gt;LDA&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href='http://www.structuraltopicmodel.com'&gt;Structural Topic Model&lt;/a&gt; &amp;ndash; Molly Roberts, Brandon Stewart and Dustin Tingley package widely used among political scientists.&lt;/li&gt;&lt;li&gt;&lt;a href='ftp://cran.r-project.org/pub/R/web/packages/topicmodels/vignettes/topicmodels.pdf'&gt;Topicmodels&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href='https://cran.r-project.org/web/packages/wordcloud/'&gt;wordcloud&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href='https://github.com/bmschmidt/wordVectors'&gt;WordVectors&lt;/a&gt; &amp;mdash; word2vec implementation.&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;a name=&quot;publications,&amp;#95;tutorials,&amp;#95;etc.&quot;&gt;&lt;/a&gt;Publications, Tutorials, etc.&lt;/h2&gt; &lt;ul&gt;&lt;li&gt;&lt;a href='https://github.com/kbenoit/ITAUR'&gt;Introduction to Text Analysis Using R&lt;/a&gt; &amp;mdash; Benoit &lt;/li&gt;&lt;li&gt;&lt;a href='http://tidytextmining.com'&gt;Text Mining with R, A Tidy Approach&lt;/a&gt; &amp;mdash; Julia Silge and David Robinson, open web version of their book.&lt;/li&gt;&lt;li&gt;&lt;a href='https://eight2late.wordpress.com/2015/05/27/a-gentle-introduction-to-text-mining-using-r/'&gt;A gentle introduction to text mining using R&lt;/a&gt; &amp;mdash; Kailash Awati&lt;/li&gt;&lt;li&gt;&lt;a href='http://www.dh.uni-leipzig.de/wo/topic-modelling-of-historical-languages-in-r/'&gt;Topic Modeling of Historical Languages in R&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt; 
</description>
<enclosure>

</enclosure>
<pubDate>
Thu, 08 Jun 2017 00:00:00 -0400
</pubDate>
</item>
<item>
<guid>
http://paultopia.github.io/posts-output/react-in-reagent/
</guid>
<link>
http://paultopia.github.io/posts-output/react-in-reagent/
</link>
<title>
Use Someone Else's React Component in Reagent
</title>
<description>
&lt;p&gt;&lt;strong&gt;EDIT:&lt;/strong&gt; &lt;/p&gt;&lt;p&gt;I never finished this post, but actually managed to make a different strategy work. Post to be revised later, but example working code in &lt;a href='https://github.com/paultopia/datasheetexperiment'&gt;this repo&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;hr&gt;  &lt;/p&gt;&lt;p&gt;Today's quest: I have a bunch of &lt;a href='https://reagent-project.github.io/'&gt;reagent&lt;/a&gt; projects that involve displaying tabular data. Reagent, for those not in the cool kid club, is a clojurescript wrapper for React. I just learned, thanks to HN, about this awesome-looking new React library (do we call them libraries in react-land?  or just components?) to display a spreadsheet-like interface, &lt;a href='react-datasheet'&gt;https://github.com/nadbm/react-datasheet&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;The problem: I know jack-all about React, or indeed about Javascript beyond the basic semantics of the language.  I have zero investment in the React toolchain, or indeed the Javascript toolchain.  The only reason I use Reagent in CLJS is because I really like the deref-an-atom-to-update-UI model of state change. Not because I particularly want a virtual dom or anything like that. &lt;/p&gt;&lt;p&gt;And the Javascript toolchain is, frankly, nuts. Apparently it doesn't even come with a module system (maybe it does with the 2016 version, which sometimes gets called ES6 and sometimes get called ES2016, or maybe those are different things, who the hell knows? Or maybe there's also ES7, and something called Javascript Next, and what the fuck?  Stop it, Javascript, you're drunk.), so there are, like, &lt;a href='https://github.com/nadbm/react-datasheet'&gt;dozens of module systems&lt;/a&gt; and compilers and transpilers and apparently a package system built on Node that you still use even if you're not running your server on node and oh my god what? &lt;/p&gt;&lt;p&gt;Aside: I don't think it's a coincidence that the languages I like most, Clojure and Python, both have a strong BDFL-figure to keep things relatively sane. As much as people often disagree with their decisions, I take it that if people felt the need to produce dozens of totally different third-party solutions to a basic language feature like a module system, either Rich or Guido would quickly step in, bring the best one into the language, and the culture would quickly coalesce around people damn well using that. It's truly ridiculous that you can have &lt;code&gt;pip install foo&lt;/code&gt; and &lt;code&gt;import foo&lt;/code&gt; in Python, but that the latest version of Javascript apparently has a &lt;a href='http://exploringjs.com/es6/ch_modules.html'&gt;complex module loader API&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Ok, so anyway. I'm gonna try to do this thing. In roughly three steps: &lt;/p&gt;&lt;ol&gt;&lt;li&gt;Get the Javascript bits into my project in a form that Clojurescript might be able to use.&lt;/li&gt;&lt;li&gt;Get Clojurescript to actually see the Javascript bits.&lt;/li&gt;&lt;li&gt;Get the Reagent bits of the Clojurescript bits talking to the React bits of the Javascript bits.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;I first tried the tutorial &lt;a href='http://blob.tomerweller.com/reagent-import-react-components-from-npm'&gt;here&lt;/a&gt;, which just puts everything into a NPM thingie, compiles it with webpack, and then excludes reagent, but I got a classic javascript-compilation-hates-you error in the webpack bundle.js (&quot;Uncaught TypeError: r is not a function&quot;), and I don't even begin to know how to debug that.  So screw it, doing it some other way.  That first fail is &lt;a href='https://github.com/paultopia/reactinreagent/commit/a8edc242652fbcfdb6545d7447133991bd7ca732'&gt;this commit&lt;/a&gt;, for folks following along at home.&lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;first&amp;#95;hurdle:&amp;#95;getting&amp;#95;the&amp;#95;library/component&quot;&gt;&lt;/a&gt;First Hurdle: Getting the library/component&lt;/h2&gt;&lt;p&gt;The docs for React-Datasheet assume that you have some kind of compilation process, presumably the normal compilation process for React, so all they do is tell you to install it via NPM. Needless to say, I'm not using NPM. &lt;/p&gt;&lt;p&gt;So let's start a new clojurescript project&amp;mdash;no point in breaking an existing project by doing this.  It'll live &lt;a href='here'&gt;https://github.com/paultopia/reactinreagent&lt;/a&gt;, in case you want to follow along.  And then I guess the basic strategy will be to write myself an entry-point in Javascript that just provides the component (class?  apparently &lt;a href='https://reactjsnews.com/composing-components'&gt;there's no difference&lt;/a&gt; between react components and react classes?), and then I can call my own JS from CLJS, and include that JS directly in my project and hopefully not need externs or something...&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Create cljs project using my favorite template: &lt;code&gt;lein new reagent-frontend reactinreagent&lt;/code&gt;&lt;/li&gt;&lt;li&gt;Create a javascript project somewhere in the repo.  I don't want it to be on the classpath and compile a bunch of extra garbage in my clojurescript, so I'll just create a directory called &quot;reactstuff&quot; at the top level and put all my javascript in there. My hope is that after I sort out all the react stuff there'll just be a nice compiled/transpiled/javascript-magiced js file that I can dump into my cljs resources and treat like an external javascript library.&lt;/li&gt;&lt;/ol&gt;&lt;pre&gt;&lt;code&gt;mkdir reactstuff
cd reactstuff
npm install react-datasheet --save
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Not even gonna try to figure out what needs to happen to keep this stuff off github.  Don't care, no struggs.&lt;/p&gt;&lt;p&gt;well, that threw a truly astonishing number of warnings and errors: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;/Users/myuser
├── UNMET PEER DEPENDENCY react@&amp;#126;0.14.8 || &amp;#94;15.0.0
├── react-datasheet@1.2.2
└── UNMET PEER DEPENDENCY react-dom@&amp;#126;0.14.8 || &amp;#94;15.0.0

npm WARN enoent ENOENT: no such file or directory, open '/Users/pauliglot/package.json'
npm WARN react-datasheet@1.2.2 requires a peer of react@&amp;#126;0.14.8 || &amp;#94;15.0.0 but none was installed.
npm WARN react-datasheet@1.2.2 requires a peer of react-dom@&amp;#126;0.14.8 || &amp;#94;15.0.0 but none was installed.
npm WARN myuser No description
npm WARN myuser No repository field.
npm WARN myuser No README data
npm WARN myuser No license field.

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Ok, so I guess I need to install lots of other stuff to make this happen?  I suppose installing all the react crap into this other directory won't pollute my clojurescript project, and hopefully it'll all come out right at the other end.  Let's pray.  (But now I definitely need to add this to the .gitignore). Let's see what happens.&lt;br /&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;npm install react --save

npm install react --save
npm WARN saveError ENOENT: no such file or directory, open '/Users/myuser/package.json'
/Users/myuser
├─┬ react@15.4.2
│ ├─┬ fbjs@0.8.12
│ │ ├── core-js@1.2.7
│ │ ├─┬ isomorphic-fetch@2.2.1
│ │ │ ├─┬ node-fetch@1.6.3
│ │ │ │ ├─┬ encoding@0.1.12
│ │ │ │ │ └── iconv-lite@0.4.15
│ │ │ │ └── is-stream@1.1.0
│ │ │ └── whatwg-fetch@2.0.3
│ │ ├─┬ promise@7.1.1
│ │ │ └── asap@2.0.5
│ │ ├── setimmediate@1.0.5
│ │ └── ua-parser-js@0.7.12
│ ├─┬ loose-envify@1.3.1
│ │ └── js-tokens@3.0.1
│ └── object-assign@4.1.1
└── UNMET PEER DEPENDENCY react-dom@&amp;#126;0.14.8 || &amp;#94;15.0.0

npm WARN enoent ENOENT: no such file or directory, open '/Users/myuser/package.json'
npm WARN react-datasheet@1.2.2 requires a peer of react-dom@&amp;#126;0.14.8 || &amp;#94;15.0.0 but none was installed.
npm WARN myuser No description
npm WARN myuser No repository field.
npm WARN myuser No README data
npm WARN myuser No license field.

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Ok, so that ain't working.  Apparently I do need, like, an entire fucking react toolchain to use this component.  Let's see what the &lt;a href='https://facebook.github.io/react/docs/installation.html'&gt;react docs&lt;/a&gt; have to say about getting one, huh? &lt;/p&gt;&lt;p&gt;Ok, apparently I need to:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;npm init
npm install --save react react-dom
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;oh god, npm init is some silly walkthrough that asks you a bunch of questions to create a package.json.  save me?  I'm just taking all the defaults. &lt;/p&gt;&lt;p&gt;But ok!  Now it'll let me install the things, with only one warning: &lt;code&gt;npm WARN reactstuff@1.0.0 No repository field.&lt;/code&gt; &amp;mdash; and I'm perfectly happy with this warning, since I don't feel the need for NPM to know where my repo is.&lt;/p&gt;&lt;p&gt;So, next thing, I guess the default for npm.init was to create an entry point at index.js, so I'll do that. &lt;/p&gt;&lt;p&gt;Hmm.  I'm not actually sure where index.js goes in order to get this stuff to all compile. I guess I need to use webpack?  But how do I get webpack and the npm stuff to play together?  Here's &lt;a href='https://scotch.io/tutorials/setup-a-react-environment-using-webpack-and-babel'&gt;a really fucking long tutorial for that&lt;/a&gt;, jesus.&lt;/p&gt;&lt;p&gt;No.  This is a horrifying mess.  I'm not going to set up an entire javascript build system for this.  (forget callback hell, how about dependency and build system hell?)  Instead, I'm going to empty the directory and start again, this time using facebook's lazyperson tool, &lt;a href='https://github.com/facebookincubator/create-react-app'&gt;create-react-app&lt;/a&gt;. &lt;/p&gt;&lt;pre&gt;&lt;code&gt;cd ..
rm -rf reactstuff 
mkdir reactstuff
cd reactstuff 
npm install -g create-react-app
create-react-app godhelpme
cd godhelpme
npm install react-datasheet --save
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Ok, so first thing I'm gonna do is try to get it going with pure javascript, with a placeholder file. &lt;/p&gt;&lt;p&gt;http://stackoverflow.com/questions/35489797/using-react-components-in-reagent#35734001&lt;/p&gt;
</description>
<enclosure>

</enclosure>
<pubDate>
Wed, 05 Apr 2017 00:00:00 -0400
</pubDate>
</item>
<item>
<guid>
http://paultopia.github.io/posts-output/backup-to-git/
</guid>
<link>
http://paultopia.github.io/posts-output/backup-to-git/
</link>
<title>
Backup Dropbox, iCloud, etc. to git
</title>
<description>
 &lt;p&gt;According to &lt;a href='http://stackoverflow.com/questions/1960799/using-git-and-dropbox-together-effectively'&gt;the Wisdom of the Internet&lt;/a&gt;, you shouldn't put git repos into Dropbox (at least not without doing too-fancy things like turning Dropbox itself into a git remote, which, no), because everything changes everything else in funny complex ways and things blow up.   &lt;/p&gt;&lt;p&gt;But if you're me, sometimes you store, like writing and such, a bunch of stuff in Dropbox (or in iCloud, where I imagine similar issues arise, or in Google Drive, or in Box, or even in bloody Microsoft's OneDrive monstrosity), and want to keep doing so because of nice things like automatic multiple-device syncronization. &lt;/p&gt;&lt;p&gt;But at the same time, you want version control. And you don't want to rely on Dropbox's opaque versioning system that you have to pay for and where the terms and the UI change all the time. You want GIT, damnit. &lt;/p&gt;&lt;p&gt;Why not just automatically copy all the files from the Dropbox/iCloud/whev folder to your git repo?  I wrote a quick python script to do so. You can get it &lt;a href='https://gist.github.com/paultopia/9b91a9ca00ed489d0d820e76d201dcca'&gt;from this gist&lt;/a&gt;.  Just stick it in a cron job or launchd or whatever.  I think I will have mine run every hour when the computer is on.&lt;/p&gt;&lt;p&gt;Now to figure out launchd on mac. &lt;a href='http://alvinalexander.com/mac-os-x/mac-osx-startup-crontab-launchd-jobs'&gt;Here's a tutorial&lt;/a&gt; some kind person wrote, let's see how this works...&lt;/p&gt;&lt;p&gt;(I suppose this would be more useful with a separate config file and the ability to pass multiple source directories, maybe even multiple target directories, but that's more work, and this is all I need, so, oh hey open source. :-) ...maybe later).&lt;/p&gt;&lt;p&gt;&lt;em&gt;Edit&lt;/em&gt;: figured out launchctl. That tutorial above is pretty good and has more details, but here are the basics. &lt;/p&gt;&lt;p&gt;First &lt;code&gt;cd $HOME/Library/LaunchAgents&lt;/code&gt;&lt;/p&gt;&lt;p&gt;Then create a plist file in funny apple format. Let's say your filename for the plist is &lt;code&gt;com.yourname.yourcommand.plist&lt;/code&gt;. And let's say your version of that python script is located at &lt;code&gt;/Users/yourname/github/yourfile/backup-to-git&lt;/code&gt;. And say you want it to run every hour.  Then this is your plist:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&amp;gt;
&amp;lt;!DOCTYPE plist PUBLIC &amp;quot;-//Apple//DTD PLIST 1.0//EN&amp;quot; &amp;quot;http://www.apple.com/DTDs/PropertyList-1.0.dtd&amp;quot;&amp;gt;
&amp;lt;plist version=&amp;quot;1.0&amp;quot;&amp;gt;
&amp;lt;dict&amp;gt;
  &amp;lt;key&amp;gt;Label&amp;lt;/key&amp;gt;
  &amp;lt;string&amp;gt;com.yourname.yourcommand&amp;lt;/string&amp;gt;
  &amp;lt;key&amp;gt;ProgramArguments&amp;lt;/key&amp;gt;
  &amp;lt;array&amp;gt;
    &amp;lt;string&amp;gt;/Users/yourname/github/yourfile/backup-to-git&amp;lt;/string&amp;gt;
  &amp;lt;/array&amp;gt;
  &amp;lt;key&amp;gt;StartInterval&amp;lt;/key&amp;gt;
  &amp;lt;integer&amp;gt;3600&amp;lt;/integer&amp;gt;
  &amp;lt;key&amp;gt;RunAtLoad&amp;lt;/key&amp;gt;
  &amp;lt;true/&amp;gt;
&amp;lt;/dict&amp;gt;
&amp;lt;/plist&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Note that the StartInterval value is the number of seconds between runs. &lt;/p&gt;&lt;p&gt;Then to get it going without reboot, run &lt;code&gt;launchctl load com.yourname.yourcommand.plist&lt;/code&gt; (and replace load with unload to stop it).&lt;br /&gt;&lt;/p&gt;&lt;p&gt;Supposedly this will continue working after reboot too. I have faith.&lt;/p&gt;
</description>
<enclosure>

</enclosure>
<pubDate>
Thu, 12 Jan 2017 00:00:00 -0500
</pubDate>
</item>
<item>
<guid>
http://paultopia.github.io/posts-output/anti-homebrew/
</guid>
<link>
http://paultopia.github.io/posts-output/anti-homebrew/
</link>
<title>
Starting to distrust Homebrew...
</title>
<description>
  &lt;p&gt;Is it just me, or has Homebrew been getting super-bossy recently about how you run your machine?&lt;br /&gt;  &lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;round&amp;#95;1:&amp;#95;update&amp;#95;xcode&amp;#95;you&amp;#95;must,&amp;#95;padawan...&quot;&gt;&lt;/a&gt;Round 1: Update XCode you must, padawan...&lt;/h2&gt;&lt;p&gt;The problems started with &lt;a href='https://github.com/Homebrew/brew/issues/1131'&gt;this issue I filed&lt;/a&gt;. The story behind that issue is this: I upgraded my machine to Sierra, and brew immediately started throwing a fatal error. It wouldn't allow any use of brew at all unless one's XCode is updated to at least the latest version.   &lt;/p&gt;&lt;p&gt;Now, that's a problem, for several reasons. First, XCode is a massive, multi-gigabyte, failure-prone download that can take days to actually get if you live, as I do, in the rural Midwest with a corrupt internet service oligopoly. I'm convinced that installation the first time around actually crashed my SSD.  &lt;/p&gt;&lt;p&gt;Second, it turns out, after discussion in that thread, that XCode &lt;em&gt;isn't actually a dependency&lt;/em&gt; for the vast majority of Homebrew packages. So this forced multi-gigabyte constantly breaking download is for a tiny handful of packages. &lt;/p&gt;&lt;p&gt;This forced upgrade only applies if you actually have XCode on your system. So the maintainers of actually decided that their users are to have exactly two choices: have no XCode at all, or have the latest version.  And they made that decision based on a dependency that only applies to a small percentage of their packages (which, of course, aren't disclosed in any place I can find). &lt;/p&gt;&lt;p&gt;Ok, so that was really annoying.  But, ultimately, Homebrew is just a bunch of Ruby scripts. And while I've never written a line of Ruby in my life, it's pretty easy to read, and I do know Python, which is close enough.  So I went digging. &lt;/p&gt;&lt;p&gt;I found the file where this behavior is specified. And with a one-line edit to convince Homebrew into thinking that the current installed version of XCode is the installed version (all described in that issue linked at the top), all was well again. For a while.&lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;round&amp;#95;2:&amp;#95;update&amp;#95;homebrew&amp;#95;you&amp;#95;must,&amp;#95;young&amp;#95;sith...&quot;&gt;&lt;/a&gt;Round 2: Update Homebrew you must, young Sith...&lt;/h2&gt;&lt;p&gt;Fast forward a few weeks. I did install XCode 8, which surprisingly worked. And I went to upgrade a package. Oops, homebrew now wants XCode 8.1.  And I don't have time to download more endless gigs in order to upgrade a like 5mb package. So I head on over to /usr/local/Homebrew/Library/Homebrew/os/mac/xcode.rb, fire up vim, and edit the script again in order to convince brew that XCode 8 is the latest version.  Then I re-run my command. &lt;/p&gt;&lt;p&gt;&lt;em&gt;!&lt;sup&gt;%$!!&lt;/sup&gt;&lt;sup&gt;$&amp;%&lt;/sup&gt; WTF? It's still throwing an XCode version error?&lt;/em&gt;  Yep, now it turns out that Homebrew auto-updates itself &lt;em&gt;every time you use it,&lt;/em&gt; as the first task, and then the auto-updating overwrites the changes I made to the XCode version file. &lt;/p&gt;&lt;p&gt;&quot;Ok, fine, this is an easy fix,&quot; I think.  &quot;I'll just set xcode.rb to be not writable.&quot; &lt;/p&gt;&lt;p&gt;&lt;em&gt;!&lt;sup&gt;%$!!&lt;/sup&gt;&lt;sup&gt;$&amp;%&lt;/sup&gt; WTF? It's still throwing an XCode version error?!!?&lt;/em&gt;  Go back, check xcode.rb, and discover the write bit has been set again. Brew ever-so-helpfully elevated its own permissions in order to boss me around. &lt;/p&gt;&lt;p&gt;&quot;Ok, a little bit harder of a fix,&quot; I think. &quot;I'll just change the owner too.  Try and change files owned by root, I dare you.&quot; &lt;/p&gt;&lt;p&gt;&lt;em&gt;GARGHHG!!!  STILL THROWING THE XCODE ERROR!&lt;/em&gt; And the ownership has been changed back. (I always thought &lt;a href='https://github.com/Homebrew/brew/blob/master/docs/FAQ.md#why-does-homebrew-say-sudo-is-bad-'&gt;part of the goddamn point of Homebrew was that it didn't need root privs to run it&lt;/a&gt;? And indeed, &lt;a href='https://github.com/Homebrew/brew/pull/1452'&gt;it supposedly can't even be run as root&lt;/a&gt;. But yet it seems to magically help itself to quite privileged behavior when it wants to force update itself without the user's consent.)&lt;/p&gt;&lt;p&gt;This seems &lt;em&gt;really&lt;/em&gt; problematic. Users don't get to choose to use an older version of the tool anymore? And don't get to restrict its behavior at all? This strikes me as a major security problem.&lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;round&amp;#95;3:&amp;#95;package&amp;#95;management,&amp;#95;except&amp;#95;when&amp;#95;it&amp;#95;doesn't.&quot;&gt;&lt;/a&gt;Round 3: package management, except when it doesn't.&lt;/h2&gt;&lt;p&gt;Fast forward a few more weeks. So today, I decided to try ProjectLibre. It has a Homebrew cask, so let's live dangerously.  First, I decided to look in on my currently installed casks with &lt;code&gt;brew cask list&lt;/code&gt;.  Here's what I get:   &lt;/p&gt;&lt;blockquote&gt;&lt;p&gt; Warning: The default Caskroom location has moved to /usr/local/Caskroom. &lt;/p&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;p&gt;Please migrate your Casks to the new location and delete /opt/homebrew-cask/Caskroom, or if you would like to keep your Caskroom at /opt/homebrew-cask/Caskroom, add the following to your HOMEBREW&lt;i&gt;CASK&lt;/i&gt;OPTS: &lt;/p&gt;&lt;p&gt;  &amp;ndash;caskroom=/opt/homebrew-cask/Caskroom &lt;/p&gt;&lt;p&gt;For more details on each of those options, see https://github.com/caskroom/homebrew-cask/issues/21913. beaker                                                       java                                                         xquartz &lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;Ok, what's this?  First of all, I don't even remember installing Java via brew, but maybe I did. It would have made sense, given how &lt;a href='http://opensource.stackexchange.com/a/1422'&gt;terrifying&lt;/a&gt; Oracle &lt;a href='http://www.theregister.co.uk/2016/12/16/oracle_targets_java_users_non_compliance'&gt;is being&lt;/a&gt; about Java, and the damn near impossibility even for a &lt;a href='http://paul-gowder.com/'&gt;&lt;em&gt;actual lawyer&lt;/em&gt;&lt;/a&gt; of figuring out from the &lt;a href='http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html'&gt;java download page&lt;/a&gt; which version of what I'm downloading and what contracts I'm agreeing to by doing so.&lt;br /&gt;&lt;/p&gt;&lt;p&gt;Looking at &lt;a href='https://github.com/caskroom/homebrew-cask/issues/21913'&gt;the noted github issue&lt;/a&gt;, there is, no explanation of this change. But there is new information: apparently migrating your casks to the new location, as suggested by the warning, isn't so easy as all that. If you installed your packages &lt;em&gt;after&lt;/em&gt; a commit that was apparently merged on May 31, 2016, then you're ok, you can just move the directory the casks are located in.  But if you installed anything before that, it's symlinked, and you have to manually uninstall and reinstall.&lt;/p&gt;&lt;p&gt;So apparently it wants me to delete the entire (200mb-ish) JDK and re-install it because the maintainers decided to change the location where packages were installed (&lt;em&gt;multiple times, recently&lt;/em&gt;, if you count the symlink change) and aren't willing to provide an automated migration solution, or set some option in an environment variable that will probably get deprecated (or just flat-out dropped) in the next version? Which, remember, you can't choose not to use, because now it force auto-updates.   &lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;adding&amp;#95;privacy&amp;#95;violations&amp;#95;to&amp;#95;security&amp;#95;violations.&quot;&gt;&lt;/a&gt;Adding privacy violations to security violations.&lt;/h2&gt;&lt;p&gt;Also, Homebrew &lt;a href='https://chr4.org/blog/2016/04/26/homebrew-betrayed-us-all-to-google/'&gt;evidently tracks its users with google analytics&lt;/a&gt; as of April or thereabouts. And, this &lt;a href='https://www.reddit.com/r/programming/comments/4gj664/homebrew_enabled_tracking_with_google_analytics/'&gt;opt-out behavior isn't disclosed to users&lt;/a&gt;, and I only found out about it by poking through a Hacker News thread. (There's some suggestion that maybe it got disclosed eventually, in some update, but I don't remember seeing the disclosure...)&lt;/p&gt;&lt;p&gt;Valeri Karpov has some &lt;a href='http://thecodebarbarian.com/i-dont-want-to-hire-you-if-you-cant-reverse-a-binary-tree'&gt;strong words about Homebrew&lt;/a&gt;, and I confess, I'm starting to feel the same way. Maybe it's time to try to figure out how to migrate to Nix...&lt;/p&gt;
</description>
<enclosure>

</enclosure>
<pubDate>
Wed, 28 Dec 2016 00:00:00 -0500
</pubDate>
</item>
<item>
<guid>
http://paultopia.github.io/posts-output/destructuring/
</guid>
<link>
http://paultopia.github.io/posts-output/destructuring/
</link>
<title>
Clojure basics: destructuring
</title>
<description>
 &lt;p&gt;I think destructuring is one of the harder things for total beginners to handle in Clojure, because the syntax is just really terse. When you get used to it, it makes the code more readable, but at the beginning, it makes the code lots less readable.   &lt;/p&gt;&lt;p&gt;There are some good destructuring tutorials out there (listed at the end), but none with live code execution (and the ability for readers to play around and tweak stuff) via the magic of &lt;a href='https://github.com/viebel/klipse'&gt;klipse&lt;/a&gt;.  So here goes! &lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;the&amp;#95;basic&amp;#95;idea&quot;&gt;&lt;/a&gt;The Basic Idea&lt;/h2&gt;&lt;p&gt;Destructuring is a way to concisely create local bindings from complex data structures. Here's an example.  Suppose you have a map, and you want to do something with it. &lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;def a-triangle {:base 5 :height 10}&amp;#41;
&amp;#40;defn area &amp;#91;triangle&amp;#93;
&amp;#40;let &amp;#91;b &amp;#40;:base triangle&amp;#41; h &amp;#40;:height triangle&amp;#41;&amp;#93;
&amp;#40;&amp;#42; b h 0.5&amp;#41;&amp;#41;&amp;#41;
&amp;#40;area a-triangle&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;But that's a lot of typing. Destructuring lets us do it smaller:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;defn des1-area &amp;#91;triangle&amp;#93;
&amp;#40;let &amp;#91;{b :base h :height} triangle&amp;#93;
&amp;#40;&amp;#42; b h 0.5&amp;#41;&amp;#41;&amp;#41;
&amp;#40;des1-area a-triangle&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The let assignment there is our first example of destructuring. It says &quot;pull the values at &lt;code&gt;:base&lt;/code&gt; and &lt;code&gt;:height&lt;/code&gt; from the map &lt;code&gt;triangle&lt;/code&gt;, then assign them to the local symbols &lt;code&gt;b&lt;/code&gt; and &lt;code&gt;h&lt;/code&gt;.&quot;&lt;/p&gt;&lt;p&gt;But this is still too much typing.  We don't even need a let binding at all, because we can destructure right in a function definition. &lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;defn des2-area &amp;#91;{b :base h :height}&amp;#93;
&amp;#40;&amp;#42; b h 0.5&amp;#41;&amp;#41;
&amp;#40;des2-area a-triangle&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That's more like it! Note how this second example of destructuring is just like the first, except that you don't need to pass the local name of the map to it, because the function destructures it before it even gets a local binding. &lt;/p&gt;&lt;p&gt;If you just want to use the same names as in the underlying map, the &lt;code&gt;:keys&lt;/code&gt; option allows you to do so:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;defn des3-area &amp;#91;{:keys &amp;#91;base height&amp;#93;}&amp;#93;
&amp;#40;&amp;#42; base height 0.5&amp;#41;&amp;#41;
&amp;#40;des3-area a-triangle&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;There, the destructuring statement should be read as &quot;take the map that I'm going to pass into this function, and then give me the keys that are listed in the vector, and locally bind their values to the symbol-ized forms of their keys.&quot;&lt;/p&gt;&lt;p&gt;Sadly, the &lt;code&gt;:keys&lt;/code&gt; option doesn't appear to work with string keys. &lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;def string-triangle {&amp;quot;base&amp;quot; 5 &amp;quot;height&amp;quot; 10}&amp;#41;
&amp;#40;des3-area string-triangle&amp;#41;  ; :-&amp;#40;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;However, slightly more longwinded destructuring does:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;defn des4-area &amp;#91;{b &amp;quot;base&amp;quot; h &amp;quot;height&amp;quot;}&amp;#93;
&amp;#40;&amp;#42; b h 0.5&amp;#41;&amp;#41;
&amp;#40;des4-area string-triangle&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And there's a happy surprise: &lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;defn des5-area &amp;#91;{:strs &amp;#91;base height&amp;#93;}&amp;#93;
&amp;#40;&amp;#42; base height 0.5&amp;#41;&amp;#41;
&amp;#40;des5-area string-triangle&amp;#41;
 &lt;/code&gt;&lt;/pre&gt;&lt;/p&gt;&lt;p&gt;That's right: &lt;code&gt;:strs&lt;/code&gt;:strings::&lt;code&gt;:keys&lt;/code&gt;::keywords.&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;vectors&amp;#95;(and&amp;#95;other&amp;#95;sequential&amp;#95;data&amp;#95;structures)&amp;#95;too&quot;&gt;&lt;/a&gt;Vectors (and other sequential data structures) too&lt;/h3&gt;&lt;p&gt;Suppose you want to add the first two numbers from a vector of arbitrary size. Here's a simple non-destructurey way. &lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;defn add-first-2 &amp;#91;v&amp;#93;
&amp;#40;+ &amp;#40;first v&amp;#41; &amp;#40;second v&amp;#41;&amp;#41;&amp;#41;
&amp;#40;add-first-2 &amp;#91;1 2 3 4&amp;#93;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With destructuring, you can just take pluck out variables in order from the vector. So our function becomes:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;defn add-first-2d &amp;#91;&amp;#91;a b&amp;#93;&amp;#93;
&amp;#40;+ a b&amp;#41;&amp;#41;
&amp;#40;add-first-2d &amp;#91;1 2 3 4&amp;#93;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So what that destructuring form says is &quot;take the sequential data structure you're passing into this function, pluck out the first two elements, and locally bind them the to the symbols a and b&quot;&lt;/p&gt;&lt;p&gt;Suppose you want the first and the third?  Well, the convention is that you throw away an unused value with an underscore, so:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;defn add-first-and-third &amp;#91;&amp;#91;a &amp;#95; b&amp;#93;&amp;#93;
&amp;#40;+ a b&amp;#41;&amp;#41;
&amp;#40;add-first-and-third &amp;#91;1 2 3 4&amp;#93;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;By the way, I meant it when I said &quot;any sequence&quot;&amp;mdash;this includes strings, anything that can behave sequentially.&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;let &amp;#91;&amp;#91;fst &amp;#95; thrd&amp;#93; &amp;quot;bar&amp;quot;&amp;#93; &amp;#40;str fst thrd&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You can even combine destructuring with the variable arguments &lt;code&gt;&amp;amp;&lt;/code&gt; trick to collect an indeterminate number of arguments into a list and then immediately destructure them. Though &lt;a href='https://stuartsierra.com/2015/06/01/clojure-donts-optional-arguments-with-varargs'&gt;Stuart Sierra says this is a bad idea&lt;/a&gt;.&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;defn add-first-and-third-uncollected &amp;#91;&amp;amp; &amp;#91;a &amp;#95; b&amp;#93;&amp;#93;
&amp;#40;+ a b&amp;#41;&amp;#41;
&amp;#40;add-first-and-third-uncollected 1 2 3 4&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Note how this works even though the numbers aren't collected into a vector.  Incidentally, you can also use the fancy ampersand &lt;em&gt;within&lt;/em&gt; a destructuring statement to collect the tail of a sequence.&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;let &amp;#91;&amp;#91;v1 v2 &amp;amp; the-rest&amp;#93; &amp;#40;range 10&amp;#41;&amp;#93;
&amp;#91;v1 v2 &amp;#40;apply + the-rest&amp;#41;&amp;#93;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;While we're at it, let's look at nested data structures. First, we'll use the previous technique to make a vector with sequences in them. And, actually, let's learn a new technique in the process: you can also use &lt;code&gt;:as&lt;/code&gt; in any destructuring operation to bind the entire destructured data structure to a name.  So:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;def nested &amp;#40;let &amp;#91;&amp;#91;v1 v2 &amp;amp; the-rest :as everything&amp;#93; &amp;#40;range 10&amp;#41;&amp;#93;
  &amp;#91;v1 v2 the-rest everything&amp;#93;&amp;#41;&amp;#41;
nested
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now let's grab... say... the 1 from the first two numbers, nothing from the first sequence and the 2 from the second sequence. &lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;let &amp;#91;&amp;#91;&amp;#95; theone &amp;#95; &amp;#91;&amp;#95; &amp;#95; thetwo&amp;#93;&amp;#93; nested&amp;#93; &amp;#40;str theone thetwo&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;That's a little obscure-looking, here's a clearer one, fetching the items at the same positions: &lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;def nested2 &amp;#91;:a :b &amp;#91;:c :d&amp;#93; &amp;#91;:e :f :g&amp;#93;&amp;#93;&amp;#41;
&amp;#40;let &amp;#91;&amp;#91;&amp;#95; theone &amp;#95; &amp;#91;&amp;#95; &amp;#95; thetwo&amp;#93;&amp;#93; nested2&amp;#93; &amp;#40;str theone thetwo&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So what you can see is that the inner vector in the let statement essentially said &quot;let's start destructuring!&quot;  And then from the first four values of the vector that we destructured (&lt;code&gt;:a:&lt;/code&gt; &lt;code&gt;:b&lt;/code&gt; and &lt;code&gt;&amp;#91;:c :d&amp;#93;&lt;/code&gt;) we took only the second&amp;mdash;so we threw out the first nested vector as a discard value. Then, continuing through the vector, we got to the second nested vector. Since we wanted to fetch something out of that, we put another inner vector in to say &quot;let's destructure this vector now.&quot; And then we grabbed the third item in there.&lt;/p&gt;&lt;p&gt;You can also go a little crazy with the nesting and get maps inside vectors, and so on and so on.  Here's something a little ridiculous...&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;def ridiculous &amp;#91;&amp;quot;foo&amp;quot; {:bar &amp;quot;baz&amp;quot; :bat &amp;#91;1 2 3&amp;#93;}&amp;#93;&amp;#41;
&amp;#40;let &amp;#91;&amp;#91;&amp;#95; {&amp;#91;&amp;#95; mynum &amp;#95;&amp;#93; :bat}&amp;#93; ridiculous&amp;#93; &amp;#40;str mynum&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;See what I did there?  I took the second item in the vector, which was a map, grabbed the thing attached to &lt;code&gt;:bat&lt;/code&gt;, which was a vector, and then grabbed the second item in it.&lt;/p&gt;&lt;p&gt;There are more fancy destructuring features, such as the :or keyword to supply default bindings in map destructuring, but this is enough for now. Go read the further reading for all of that. &lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;comparison:&amp;#95;python&amp;#95;tuple&amp;#95;unpacking&quot;&gt;&lt;/a&gt;Comparison: Python Tuple Unpacking&lt;/h2&gt;&lt;p&gt;For those coming to Clojure from Python, it's interesting to compare destructuring to one of my favorite syntactic features of the latter.&lt;br /&gt;&lt;/p&gt;&lt;p&gt;A classic programming interview-type problem is how to swap the values of two variables without using a third variable. Most solutions involve &lt;a href='http://www.geeksforgeeks.org/swap-two-numbers-without-using-temporary-variable/'&gt;silliness with arithmetic&lt;/a&gt;, but in python it's as simple as: &lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;python&quot;&gt;a = 0
b = 1
a, b = b, a
print&amp;#40;&amp;quot;a = &amp;quot; + str&amp;#40;a&amp;#41;&amp;#41;
print&amp;#40;&amp;quot;b = &amp;quot; + str&amp;#40;b&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The closest equivalent I can come up with to this in Clojure puts the variables in a vector to be destructured, viz: &lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;def v &amp;#91;0 1&amp;#93;&amp;#41;
&amp;#40;def v &amp;#40;let &amp;#91;&amp;#91;a b&amp;#93; v&amp;#93; &amp;#91;b a&amp;#93;&amp;#41;&amp;#41;
v
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;or as a map, which can do the swapping right in the destructuring statement:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;def ab {:a 0 :b 1}&amp;#41;
&amp;#40;def ab &amp;#40;let &amp;#91;{a :b b :a} ab&amp;#93; {:a a :b b}&amp;#41;&amp;#41;
ab
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Though I'm not sure if either technically respects the &quot;no temp variables&quot; rule since they do create temporary bindings in the let statements.  But both versions have the same general form of &quot;unpack the first two variables, swap them without storing either one in a third.&quot;  And there's probably a more elegant way to do it. (Something to try at home: write a macro to do this to two variables on their own.)&lt;/p&gt;&lt;p&gt;But anyway, the python idea works the same.  The trick is that the &lt;a href='https://www.tutorialspoint.com/python/python_tuples.htm'&gt;comma creates a tuple&lt;/a&gt;, and then the &lt;a href='http://stackoverflow.com/a/14836456/4386239'&gt;assignment unpacks that tuple from left to right&lt;/a&gt;. So the left side of the assignment statement reaches in, and assigns a and b to the elements of the tuple on the right side, which you just created with the values in b and a. Though I think some of this stuff got screwed with in Python 3.&lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;further&amp;#95;reading&quot;&gt;&lt;/a&gt;Further reading&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;a href='http://clojure.org/guides/destructuring'&gt;Official Clojure guide&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href='http://clojure.org/reference/special_forms#binding-forms'&gt;A more abbreviated official Clojure explanation&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href='http://blog.jayfields.com/2010/07/clojure-destructuring.html'&gt;Jay Fields tutorial&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href='https://gist.github.com/john2x/e1dca953548bfdfb9844'&gt;John Louis Del Rosario tutorial&lt;/a&gt; and &lt;a href='http://www.john2x.com/blog/clojure-destructuring.html'&gt;blog post&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href='http://blog.brunobonacci.com/2014/11/16/clojure-complete-guide-to-destructuring/'&gt;Bruno Bonacci tutorial&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href='https://clojurebridge.github.io/community-docs/docs/clojure/destructuring/'&gt;ClojureBridge destructuring examples&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href='http://www.braveclojure.com/do-things/#Defining_Functions'&gt;Clojure for the Brave and True on defining functions&lt;/a&gt; (scroll down a bit for destructuring section)&lt;/li&gt;&lt;li&gt;&lt;a href='https://www.laliluna.de/articles/2013/010/29/clojure-destructuring.html'&gt;Sebastian Hennebrueder on destructuring&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
</description>
<enclosure>

</enclosure>
<pubDate>
Sat, 17 Dec 2016 00:00:00 -0500
</pubDate>
</item>
<item>
<guid>
http://paultopia.github.io/posts-output/basic-transducers/
</guid>
<link>
http://paultopia.github.io/posts-output/basic-transducers/
</link>
<title>
Transducers for total beginners
</title>
<description>
 &lt;p&gt;&quot;Transducer&quot; has to be the most intimidating name in all Clojure-land. For everyday use, however, they're really simple. (I don't get the truly fancy stuff, like writing one's own transducers, or getting them to hold state.)  &lt;/p&gt;&lt;p&gt;The simple &quot;for beginners&quot; (recommended experience level: you know how to use map and reduce and function composition and the threading macro) flavor of transducers is: like function composition, but with some more fancy. &lt;/p&gt;&lt;p&gt;This blog post is an attempted translation of the basic parts of the &lt;a href='http://clojure.org/reference/transducers'&gt;Clojure documentation page on transducers&lt;/a&gt; into more comprehensible terms that don't require you to be as smart as Rich Hickey to understand.&lt;/p&gt;&lt;p&gt;So one way to think of transducers is just as a different way of doing ordinary function composition, but where you don't have to explicitly call &quot;partial&quot; to do partial application for those sequence functions that support the special one-less-arity-makes-a-transducer powers, and also they go in a different order.&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;def transducer-math
  &amp;#40;comp
   &amp;#40;map #&amp;#40;+ 5 %&amp;#41;&amp;#41;
   &amp;#40;map #&amp;#40;/ % 3&amp;#41;&amp;#41;&amp;#41;&amp;#41;

&amp;#40;def composed-math
  &amp;#40;comp
   &amp;#40;partial map #&amp;#40;+ 5 %&amp;#41;&amp;#41;
   &amp;#40;partial map #&amp;#40;/ % 3&amp;#41;&amp;#41;&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Compare the two: &lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;into &amp;#91;&amp;#93; &amp;#40;composed-math &amp;#91;1 2 3&amp;#93;&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;into &amp;#91;&amp;#93; transducer-math &amp;#91;1 2 3&amp;#93;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Why are these different?  Because ordinary function composition runs backwards, like nesting, so it applies the division before the addition.  Transducer composition runs forward, the &quot;natural order,&quot; like the arrow threading macro &lt;code&gt;-&amp;gt;&lt;/code&gt; does, so it applies the addition before the division.&lt;/p&gt;&lt;p&gt;&lt;code&gt;transduce&lt;/code&gt; is like &lt;code&gt;reduce&lt;/code&gt;, with a bit of magic under the hood. The docs have stuff I don't even begin to understand in there, but what it seems to amount to is that it applies the transducer to the collection before reducing, i.e., you can replace &lt;code&gt;reduce&lt;/code&gt; with &lt;code&gt;transduce transducer&lt;/code&gt; and it will otherwise work. &lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;def xf 
  &amp;#40;comp 
   &amp;#40;filter odd?&amp;#41;
   &amp;#40;filter #&amp;#40;&amp;gt; 5 %&amp;#41;&amp;#41;&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;transduce xf + &amp;#40;range 10&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;reduce + &amp;#40;range 10&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;transduce xf conj &amp;#91;&amp;#93; &amp;#40;range 10&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;reduce conj &amp;#91;&amp;#93; &amp;#40;range 10&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;code&gt;eduction&lt;/code&gt; seems to basically just mean &quot;create a lazy sequence from applying the transducer to the collection&quot; &lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;take 2 &amp;#40;eduction xf &amp;#40;range 10&amp;#41;&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;However, &lt;code&gt;sequence&lt;/code&gt; does the same thing, so I have to confess to a bit of confusion as to what the differences are.&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;take 2 &amp;#40;sequence xf &amp;#40;range 10&amp;#41;&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Other advantages of transducers: you can apply them to core.async channels, so everything that comes in gets transformed. They're also potentially more efficient than ordinary nested calls and such, because they don't create intermediate sequences for all the steps (not even lazy ones).&lt;/p&gt;&lt;p&gt;For future reference, here's the list of the built-in higher-order sequence functions that make transducers when called with one less arity, straight from the docs:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;map&lt;/li&gt;&lt;li&gt;cat&lt;/li&gt;&lt;li&gt;mapcat&lt;/li&gt;&lt;li&gt;filter&lt;/li&gt;&lt;li&gt;remove&lt;/li&gt;&lt;li&gt;take&lt;/li&gt;&lt;li&gt;take-while&lt;/li&gt;&lt;li&gt;take-nth&lt;/li&gt;&lt;li&gt;drop&lt;/li&gt;&lt;li&gt;drop-while&lt;/li&gt;&lt;li&gt;replace&lt;/li&gt;&lt;li&gt;partition-by&lt;/li&gt;&lt;li&gt;partition-all&lt;/li&gt;&lt;li&gt;keep&lt;/li&gt;&lt;li&gt;keep-indexed&lt;/li&gt;&lt;li&gt;map-indexed&lt;/li&gt;&lt;li&gt;distinct&lt;/li&gt;&lt;li&gt;interpose&lt;/li&gt;&lt;li&gt;dedupe&lt;/li&gt;&lt;li&gt;random-sample&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Christophe Grand has also written &lt;a href='https://github.com/cgrand/xforms'&gt;tranducerific support for more core functions&lt;/a&gt;. Right now they seem a little hard to understand (especially x/reduce!!) but reading the code is interesting...&lt;/p&gt;&lt;p&gt;Also, &lt;a href='http://stackoverflow.com/questions/26317325/can-someone-explain-clojure-transducers-to-me-in-simple-terms'&gt;this is a nice SO&lt;/a&gt;.&lt;/p&gt;
</description>
<enclosure>

</enclosure>
<pubDate>
Mon, 05 Dec 2016 00:00:00 -0500
</pubDate>
</item>
<item>
<guid>
http://paultopia.github.io/posts-output/cljs-macro-data/
</guid>
<link>
http://paultopia.github.io/posts-output/cljs-macro-data/
</link>
<title>
Using macros to get data into Clojurescript front-end pages
</title>
<description>
 &lt;p&gt;Suppose you want to construct pure front-end static pages that will be as fast as possible.  Optimum speed at least arguably involves minimizing server round trips.  Ideally, everything should be one round trip, which should fetch all code and data for the entire site (so long as it isn't huge). This minimizes network latency, permits aggressive caching strtegies, the use of services like cloudflare to optimize the stink out of everything, etc. &lt;/p&gt;&lt;p&gt;But that comes at a cost. If everything is bundled up together, that means instead of, say, having your SPA application go fetch some markdown from the server with an AJAX request and render it to the user (network round trip! oh noes!), you get to mix the code and the data. But that's just ugly, and hard to maintain. For example, this is what some of the code from &lt;a href='http://gowder.io'&gt;gowder.io&lt;/a&gt;, which is just a personal static site built with Reagent, looks like: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;#40;defn research-page &amp;#91;&amp;#93;
  &amp;#91;shell &amp;quot;Researcher&amp;quot;
   &amp;#91;:div
    &amp;#91;:p &amp;quot;I'm currently an academic researcher, and in that capacity, since 2012, I've published one book, &amp;quot;
     &amp;#91;:a {:href &amp;quot;http://rulelaw.net&amp;quot;} &amp;quot;The Rule of Law in the Real World&amp;quot;&amp;#93;
     &amp;quot;, and over a dozen articles in constitutional law, political and legal philosophy, critical race theory, classical Athenian law and political theory, and distributive justice. I've also given about 40 scholarly presentations in the last 4 years. For details, see &amp;quot;
     &amp;#91;:a {:href &amp;quot;http://paul-gowder.com&amp;quot;} &amp;quot;my academic website&amp;quot;&amp;#93; &amp;quot;, where you can also download copies of many articles. Other than the book, I'm perhaps proudest of &amp;quot;
     &amp;#91;:a {:href &amp;quot;https://zenodo.org/record/57249&amp;quot;} &amp;quot;an article&amp;quot;&amp;#93;
     &amp;quot; on urban racial segregation, cognitive bias, and ascriptive injuries.&amp;quot;&amp;#93;
    &amp;#91;:p &amp;quot;Currently, I'm working on more quantitative and computational projects, including some experiments with machine-learning predictions of judicial outcomes and with human-computer facilitated empirical data collection.&amp;quot;&amp;#93;
    &amp;#91;:p &amp;quot;I have a Ph.D. in political science from &amp;quot;
     &amp;#91;:a {:href &amp;quot;https://politicalscience.stanford.edu&amp;quot;} &amp;quot;Stanford&amp;quot;&amp;#93;
     &amp;quot; and a law degree from &amp;quot;
     &amp;#91;:a {:href &amp;quot;http://hls.harvard.edu&amp;quot;} &amp;quot;Harvard.&amp;quot;&amp;#93;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;What a bloody mess.  Any time I have to change the content, I have to be careful to make sure I don't accidentally unmatch some braces or mis-nest some tags or something equally stupid. In addition to being likely to introduce errors into the code, this is also likely to introduce errors into the content, since it isn't readily readable, and it gets formatted with indentation and such for code rather than for text. &lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;when&amp;#95;do&amp;#95;code&amp;#95;and&amp;#95;content&amp;#95;come&amp;#95;together?&quot;&gt;&lt;/a&gt;When do Code and Content Come Together?&lt;/h2&gt;&lt;p&gt;This demonstrates two strategies for bringing code and content together, which are imperfect because of their timing. Summarizing the above: &lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;em&gt;Code and content come together at runtime&lt;/em&gt;: this means that the code has to go fetch the content from somewhere. And that means network latency and stuff.&lt;/li&gt;&lt;li&gt;&lt;em&gt;Code and content come together at write time&lt;/em&gt;: this means that the code and content have to be written together, like in the same file. And that's difficult to write and maintain.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;But there is a alternative. &lt;/p&gt;&lt;p&gt;Clojurescript is a lisp!  It has macros!  This means that we can take content, write it in a separate place from the code, and then bring the two together &lt;em&gt;at compile time&lt;/em&gt;. &lt;/p&gt;&lt;p&gt;Here's a trivial demo, which is available in full runnable form &lt;a href='https://github.com/paultopia/jsonmacrodemo'&gt;on Github&lt;/a&gt;. We take &lt;a href='https://reagent-project.github.io/'&gt;Reagent&lt;/a&gt;, &lt;a href='https://github.com/dakrone/cheshire'&gt;Cheshire&lt;/a&gt;, &lt;a href='https://github.com/davidsantiago/hickory'&gt;Hickory&lt;/a&gt; and &lt;a href='https://github.com/yogthos/Selmer'&gt;Selmer&lt;/a&gt;, and run them together as follows: &lt;/p&gt;&lt;p&gt;First, in a macro running on the JVM, we take a JSON of content, parse it with Cheshire, and then pass it to Selmer to turn it into HTML. It should be pretty easy to do something similar with Markdown content, if you're into that. Then we parse that with Hickory into Hiccup data structures.&lt;/p&gt;&lt;p&gt;Then we call that macro from CLJS, and at compile-time, it kindly fetches the data and inserts it into our code, ready to be used by Reagent. &lt;/p&gt;&lt;p&gt;So we have a minimal template.html:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;p&amp;gt;This text comes from a Selmer template! Hello {{name}}!&amp;lt;/p&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And we have a minimal name.json: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;{&amp;quot;name&amp;quot;: &amp;quot;World!&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And then we have a macro.clj:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;#40;ns jsonmacrodemo.macro
  &amp;#40;:require &amp;#91;cheshire.core :refer &amp;#91;parse-string&amp;#93;&amp;#93;
            &amp;#91;selmer.parser :refer &amp;#91;render-file render&amp;#93;&amp;#93;
            &amp;#91;hickory.core :refer &amp;#91;parse-fragment as-hiccup&amp;#93;&amp;#93;&amp;#41;&amp;#41;

&amp;#40;defn get-data &amp;#91;jsonfile&amp;#93;
  &amp;#40;parse-string &amp;#40;slurp jsonfile&amp;#41; true&amp;#41;&amp;#41;

&amp;#40;defmacro from-template &amp;#91;template jsonfile&amp;#93;
  &amp;#40;first &amp;#40;map as-hiccup &amp;#40;parse-fragment &amp;#40;render &amp;#40;slurp template&amp;#41; &amp;#40;get-data jsonfile&amp;#41;&amp;#41;&amp;#41;&amp;#41;&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And finally, we have some the Clojurescript that consumes it, core.cljs: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;#40;ns jsonmacrodemo.core
  &amp;#40;:require &amp;#91;reagent.core :as reagent&amp;#93;&amp;#41;
  &amp;#40;:require-macros &amp;#91;jsonmacrodemo.macro :as m&amp;#93;&amp;#41;&amp;#41;

&amp;#40;defn home-page &amp;#91;&amp;#93;
  &amp;#91;:div
   &amp;#40;m/from-template &amp;quot;template.html&amp;quot; &amp;quot;name.json&amp;quot;&amp;#41;&amp;#93;&amp;#41;

&amp;#40;reagent/render &amp;#91;home-page&amp;#93; &amp;#40;.getElementById js/document &amp;quot;app&amp;quot;&amp;#41;&amp;#41;

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Code and content are completely separated at write time, but get compiled together before they ever see a web browser. Best of both worlds.&lt;/p&gt;
</description>
<enclosure>

</enclosure>
<pubDate>
Sun, 04 Dec 2016 00:00:00 -0500
</pubDate>
</item>
<item>
<guid>
http://paultopia.github.io/posts-output/devcards-testing/
</guid>
<link>
http://paultopia.github.io/posts-output/devcards-testing/
</link>
<title>
Devcards for Testing Clojurescript Projects: A Beginner Introduction
</title>
<description>
 &lt;p&gt;Devcards is an amazing library that basically lets you create a separate test build of a Clojurescript project.  &lt;a href='http://rigsomelight.com/devcards/#!/devdemos.testing'&gt;The documentation&lt;/a&gt; is pretty clear, but if you're a relative Clojurescript beginner like me, you'll need a little bit more hand-holding. So here's my mini-walkthrough for getting Devcards integrated into a CLJS project, targeted at people who know the basics. (Recommended background knowledge: can set up a small Clojurescript project, perhaps with help of a lein template, and get it to compile. It will also help to &lt;a href='http://blog.jayfields.com/2010/08/clojuretest-introduction.html'&gt;know how testing works&lt;/a&gt; on JVM Clojure-side with clojure.test.).   &lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;why?&quot;&gt;&lt;/a&gt;Why?&lt;/h2&gt; &lt;p&gt;Clojurescript testing is hard. Or, at least, it seems hard. Honestly, I haven't gotten to the point of figuring out how to make it work yet. Unlike JVM Clojure where you can just use clojure.test and set up some deftests and then just run them with lein test, Clojurescript testing requires setting up some browser environment (or, I guess, Node or something?) to run it in.  Most non-Devcards techniques &lt;a href='https://github.com/bensu/doo#setting-up-environments'&gt;seem to require you&lt;/a&gt; to do extreme yak-shavey things like set up Phantom.js.  &lt;/p&gt;&lt;p&gt;By contrast, Devcards just lets you set up &quot;cards,&quot; that only show up in special builds, and that demonstrate their functionality on a convenient little webpage. So then when you want to do unit testing on your Clojurescript app, you just compile the Devcards build, open up the special Devcards webpage, and then look to make sure everything is working as expected. Your test run is opening a webpage. (And if you have Figwheel going, then you get live test reloading on that webpage.) &lt;/p&gt;&lt;p&gt;You can have an ordinary test, which displays on the web much like it displays when running lein test (i.e., you can see what passed and what failed), and you can also use a &quot;card,&quot; which is just a snippet of code that gets executed and displayed, and is useful for &quot;testing&quot; stuff that requires direct visual examination. (For example, I'm working on a browser extension that uses &lt;a href='https://gionkunz.github.io/chartist-js/'&gt;Chartist.js&lt;/a&gt; to display data vis, and I'm just &lt;a href='https://github.com/paultopia/browser-stats/commit/b6936f8466aba7b0c1695139bbd5c4fe6773ee2f'&gt;defining cards in a test namespace&lt;/a&gt; to allow me to eyeball test charts and make sure they look like I expect.)&lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;setup&quot;&gt;&lt;/a&gt;Setup&lt;/h2&gt;&lt;p&gt;Of course you're going to want to require Devcards in your Leiningen dependencies (or do whatever it is that the Boot folks do). More importantly, you're also going to want to set up a separate build in your project.clj.  Here's what the builds section of my project.clj looks like (this is based off the awesome &lt;a href='https://github.com/reagent-project/reagent-frontend-template'&gt;reagent frontend template&lt;/a&gt;, which I basically use for everything, and then add devcards on my own. Hmm... maybe there's a PR or a fork in here...)&lt;/p&gt;&lt;pre&gt;&lt;code&gt;:cljsbuild {:builds {:app
                       {:source-paths &amp;#91;&amp;quot;src&amp;quot; &amp;quot;env/dev/cljs&amp;quot;&amp;#93;
                        :compiler
                        {:main &amp;quot;statspop.dev&amp;quot;
                         :output-to &amp;quot;public/js/app.js&amp;quot;
                         :output-dir &amp;quot;public/js/out&amp;quot;
                         :asset-path   &amp;quot;js/out&amp;quot;
                         :source-map true
                         :optimizations :none
                         :pretty-print  true}}
                       :devcards
                       {:source-paths &amp;#91;&amp;quot;src&amp;quot; &amp;quot;env/dev/cljs&amp;quot; &amp;quot;test&amp;quot;&amp;#93;
                        :figwheel
                        {:devcards true}
                        :compiler
                        { :main       &amp;quot;statspop.dev&amp;quot;
                         :asset-path &amp;quot;js/devcards&amp;#95;out&amp;quot;
                         :output-to  &amp;quot;public/js/devcards.js&amp;quot;
                         :output-dir &amp;quot;public/js/devcards&amp;#95;out&amp;quot;
                         :optimizations :none
                         :source-map-timestamp true }}
                       :release
                       {:source-paths &amp;#91;&amp;quot;src&amp;quot; &amp;quot;env/prod/cljs&amp;quot;&amp;#93;
                        :compiler
                        {:output-to &amp;quot;public/js/app.js&amp;quot;
                         :output-dir &amp;quot;public/js/release&amp;quot;
                         :asset-path   &amp;quot;js/out&amp;quot;
                         :optimizations :advanced
                         :pretty-print false}}}}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Note the devcards build in the middle.  That's where the action happens. &lt;/p&gt;&lt;ul&gt;&lt;li&gt;First, note that it has &quot;test&quot; as a source path, in addition to the other paths. That's where I've defined the cards.&lt;/li&gt;&lt;li&gt;Second, note that it has a Figwheel option in the map with &lt;code&gt;{:devcards true}&lt;/code&gt;.  You can use Devcards without Figwheel, but why are you building Clojurescript projects without Figwheel? (Also, Devcards and Figwheel were written by the same &lt;a href='http://rigsomelight.com/'&gt;awesome person&lt;/a&gt;, so they're really good at working together.)&lt;/li&gt;&lt;li&gt;Third, note that it compiles to a totally different Javascript file. It goes to devcards.js rather than app.js. The implication here is that you put your devcards on a totally different html page too. So in the statspop project above, I have index.html in the target &quot;public&quot; directory, which contains the ordinary app (and will actually go away for prod, since this is to be a Chrome extension), but I also have cards.html, which, in relevant part, is just:&lt;/li&gt;&lt;/ul&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;html&amp;gt;
    &amp;lt;head&amp;gt;
	&amp;lt;link rel=&amp;quot;stylesheet&amp;quot; href=&amp;quot;css/chartist.min.css&amp;quot;&amp;gt;
	&amp;lt;script src=&amp;quot;js/jstat.min.js&amp;quot; type=&amp;quot;text/javascript&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
	 &amp;lt;script src=&amp;quot;js/chartist.min.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
    &amp;lt;/head&amp;gt;
    &amp;lt;body&amp;gt;
        &amp;lt;script src=&amp;quot;js/devcards.js&amp;quot; type=&amp;quot;text/javascript&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
    &amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Note how that html just calls the Javascript and CSS libraries I'll be using (this may change, depending on how you set up external dependencies, using CLJSJS etc.), and then calls the devcards script defined in the project.clj.&lt;/p&gt;&lt;p&gt;Unlike normal CLJS libraries, you don't specify a HTML element in your cards page to render the Devcards into. So it doesn't have anything like a &lt;code&gt;&amp;lt;div id=&amp;quot;app&amp;quot;&amp;gt;&lt;/code&gt; that you'd normally use with Reagent or something. Indeed, you don't need to add any code to render it at all.  Just construct the cards, and require the namespaces the cards are in from something that actually gets loaded (or something that gets loaded by something that gets loaded, etc.), and Devcards library code will handle the rendering for you.&lt;/p&gt;&lt;p&gt;That namespace point is important and easy to miss. While you don't have to explicitly render Devcards, you do have to have the namespace a card is defined in somewhere in the dependency tree of your main namespace (&lt;a href='https://github.com/clojure/clojurescript/wiki/Compiler-Options#main'&gt;main namespace mainly used for no-optimization compilation&lt;/a&gt;). So my dependency tree looks something like this: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;statspop.dev  &amp;#40;the main namespace specified in project.clj&amp;#41;
|
 -- requires statspop.core
 |
  ---- requires all the application code namespaces
 -- requires statspop.core-test
 |
  ---- requires all the individual test namespaces &amp;#40;where Devcards cards and tests are defined&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Speaking of rendering, the Devcards docs suggest setting up your main app rendering with a conditional, so that it only renders if the node it aims at appears. E.g., from the core.cljs one of my projects:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;#40;defn mount-root &amp;#91;&amp;#93;
  &amp;#40;when-let &amp;#91;app &amp;#40;.getElementById js/document &amp;quot;app&amp;quot;&amp;#41;&amp;#93;
    &amp;#40;r/render &amp;#91;home-page&amp;#93; app&amp;#41;&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The idea there is that the application code (as opposed to the testing code) won't get run if the application page isn't loaded. This seems like a sensible precaution in view of the risk of side-effects, state pollution, etc.&lt;/p&gt;&lt;p&gt;That's about it for setup. &lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;using&amp;#95;devcards.&quot;&gt;&lt;/a&gt;Using devcards.&lt;/h2&gt;&lt;p&gt;I just copypasta-boilerplate import everything I might ever need into every test namespace, e.g., &lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;#40;ns statspop.download-test
  &amp;#40;:require &amp;#91;statspop.download :as d&amp;#93; ; the functionality I want to test
            &amp;#91;cljs.test :as t :refer-macros &amp;#91;is testing&amp;#93;&amp;#93;
            &amp;#91;devcards.core :as dc :refer-macros &amp;#91;defcard deftest defcard-rg&amp;#93;&amp;#93;
            &amp;#91;reagent.core :as r&amp;#93;
            &amp;#91;cljs.test :as t :refer-macros &amp;#91;is testing&amp;#93;&amp;#93;&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;After all, this is a dev build, it doesn't need to be light. &lt;/p&gt;&lt;p&gt;Then usage is super simple.  To define an ordinary test, you just do it exactly as you would with JVM clojure.test. Devcards deftest just shadows the cljs.test symbol and emits both tests for devcards and ordinary cljs tests if you also want to do the test runner thing with Phantom.js and the like for some reason. For example, I've rolled my own quick-and-dirty CSV converter rather than bring in a whole library for one function, so that needs a test: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;#40;deftest nested-vectors-to-csv-string
  &amp;#40;is &amp;#40;=
       &amp;#40;d/format-vec-as-csv &amp;#91;&amp;#91;&amp;quot;foo&amp;quot; &amp;quot;bar&amp;quot;&amp;#93; &amp;#91;1 2&amp;#93; &amp;#91;&amp;quot;baz&amp;quot; 3&amp;#93;&amp;#93;&amp;#41;
       &amp;quot;foo,bar\n1,2\nbaz,3&amp;quot;&amp;#41;&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To define a card, you use the defcard macro. This is mostly useful for ui/io/other state-y and side-effect-y-type things where automated testing won't work, you really just need to look and see that the input and output are what they should be.  There's also a defcard-rg macro that is just like defcard, but will take and render Reagent components for you; I tend to use that for all cards just to keep consistency with everything else I'm doing (since I'm aggressively reagent-for-everything). So this bit of code tests the creation of a downloadable csv file based on a Reagent component in my application code: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;&amp;#40;defcard-rg download-csv
  &amp;quot;download a csv file named data.csv containing the contents of the csv test above&amp;quot;
  &amp;#91;:div
   &amp;#91;:p
    &amp;#91;d/downloader &amp;#91;&amp;#91;&amp;quot;foo&amp;quot; &amp;quot;bar&amp;quot;&amp;#93; &amp;#91;1 2&amp;#93; &amp;#91;&amp;quot;baz&amp;quot; 3&amp;#93;&amp;#93; :csv&amp;#93;&amp;#93;&amp;#93;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Note how they have docstrings and cool stuff like that too.&lt;br /&gt;&lt;/p&gt;&lt;p&gt;That's it!  (Obviously, there are advanced functions, but this is the basic stuff.)  Now you can build your devcards build (e.g. &lt;code&gt;lein figwheel devcards&lt;/code&gt; &amp;mdash;although Figwheel is much nicer wrapped in rlwrap or &lt;a href='https://paultopia.github.io/posts-output/figwheel-emacs/'&gt;used from Emacs&lt;/a&gt;), go to your cards.html or whatever page, and you'll get a lovely menu of namespaces; click on a namespace to open it and you'll see all your tests + all your cards on the page. With the examples above, I can check that my csv string conversion test passes, and I can also try out the csv downloader functionality and make sure the csv that gets downloaded looks like it should. &lt;/p&gt;&lt;p&gt;Sweet, you've got a test system. &lt;/p&gt;
</description>
<enclosure>

</enclosure>
<pubDate>
Sat, 03 Dec 2016 00:00:00 -0500
</pubDate>
</item>
<item>
<guid>
http://paultopia.github.io/posts-output/figwheel-emacs/
</guid>
<link>
http://paultopia.github.io/posts-output/figwheel-emacs/
</link>
<title>
Figwheel + Spacemacs
</title>
<description>
 &lt;p&gt;I've been trying to figure out how to get Figwheel and Spacemacs to play nicely together for a while.  It turns out it's much easier than it looks (required knowledge level: reasonable comfort with front-end Clojurescript and leiningen, prior use of Figwheel, successful installation of Spacemacs and use of Clojure mode).&lt;/p&gt;&lt;p&gt;Relevant documentation: &lt;a href='https://github.com/syl20bnr/spacemacs/tree/master/layers/%2Blang/clojure'&gt;Using the Clojure layer in Spacemacs&lt;/a&gt;, &lt;a href='https://github.com/bhauman/lein-figwheel/wiki/Using-the-Figwheel-REPL-within-NRepl'&gt;using Figwheel in nREPL&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;That later document gives a process for integrating Figwheel into Emacs that doesn't seem to work with my Spacemacs stuff. But most of what it says to do isn't actually necessary, and I've extracted from it a method that doesn't actually require any special configuration in your .spacemacs, other than having Clojure mode activated.  Here's the entirety of my clojure configuration from my .spacemacs, none of which is necessary to get figwheel going: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;  &amp;#40;spacemacs/toggle-evil-cleverparens-on&amp;#41;
  &amp;#40;add-hook 'clojure-mode-hook #'evil-cleverparens-mode&amp;#41;
  &amp;#40;setq cider-show-error-buffer nil&amp;#41;
  &amp;#40;with-eval-after-load 'clojure-mode
    &amp;#40;dolist &amp;#40;c &amp;#40;string-to-list &amp;quot;:&amp;#95;-?!#&amp;#42;&amp;quot;&amp;#41;&amp;#41;
      &amp;#40;modify-syntax-entry c &amp;quot;w&amp;quot; clojure-mode-syntax-table &amp;#41;&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So how do we do it?&lt;br /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Step 1&lt;/strong&gt;: make sure the right stuff is in your project.clj (I have no ideas for boot users).  First, you need all the appropriate configuration for Figwheel. I usually start CLJS projects with the excellent &lt;a href='https://github.com/reagent-project/reagent-frontend-template'&gt;reagent frontend template&lt;/a&gt;, which handles most of that stuff for you. But in case you need something better, here are some of the basics that I have in my project.cljs: &lt;/p&gt;&lt;p&gt;&lt;em&gt;Figwheel in plugins&lt;/em&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;  :plugins &amp;#91;&amp;#91;lein-cljsbuild &amp;quot;1.1.4&amp;quot;&amp;#93;
            &amp;#91;lein-figwheel &amp;quot;0.5.8&amp;quot;&amp;#93;&amp;#93;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;em&gt;Figwheel settings giving nrepl middleware, ports (might not be needed?), etc.&lt;/em&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;  :figwheel {:http-server-root &amp;quot;public&amp;quot;
             :nrepl-port 7002
             :nrepl-middleware &amp;#91;&amp;quot;cemerick.piggieback/wrap-cljs-repl&amp;quot;&amp;#93;}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;em&gt;CLJS builds giving source paths, e.g.:&lt;/em&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;  :cljsbuild {:builds {:app
                       {:source-paths &amp;#91;&amp;quot;src&amp;quot; &amp;quot;env/dev/cljs&amp;quot;&amp;#93;  ; needed
                        :compiler
                        {:main &amp;quot;blahblahblah.dev&amp;quot; ; blah blah etc.}}

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;em&gt;repl-options summoning up piggieback&lt;/em&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;  :repl-options {:nrepl-middleware &amp;#91;cemerick.piggieback/wrap-cljs-repl&amp;#93;}

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;em&gt;and a dev profile calling in piggieback and figwheel-sidecar&lt;/em&gt;&lt;/p&gt;&lt;pre&gt;&lt;code&gt;  :profiles {:dev {:dependencies &amp;#91;&amp;#91;figwheel-sidecar &amp;quot;0.5.4-5&amp;quot;&amp;#93;
                                  &amp;#91;org.clojure/tools.nrepl &amp;quot;0.2.12&amp;quot;&amp;#93;
                                  &amp;#91;com.cemerick/piggieback &amp;quot;0.2.2-SNAPSHOT&amp;quot;&amp;#93;&amp;#93;}}&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Not all this stuff may be required (and my process is a little cargo-cultey), but at least the piggieback, sidecar, and source paths elements are required per the figwheel docs. If you work from the reagent frontend template, the only thing you need to add is the :repl-options section in the defproject. &lt;/p&gt;&lt;p&gt;&lt;strong&gt;Step 2&lt;/strong&gt;: then you're actually done!  Now you can activate figwheel from within emacs.  And you don't need to mess around with jacking-in clojurescript separate from clojure or anything silly like that.  Instead, you need only: &lt;/p&gt;&lt;ol&gt;&lt;li&gt;Open a cljs source file from your project.&lt;/li&gt;&lt;li&gt;Start a normal clojure repl with &lt;code&gt;SPC m s i&lt;/code&gt;&lt;/li&gt;&lt;li&gt;Open up the CIDER REPL buffer (if it isn't up already, just use &lt;code&gt;SPC w -&lt;/code&gt; to get a new window, then &lt;code&gt;SPC b b&lt;/code&gt; to get a menu of buffers).  Now you have a cider repl, a CLJ/JVM one rather than a CLJS/JS one.&lt;/li&gt;&lt;li&gt;In the cider repl, call the following three functions in order:&lt;/li&gt;&lt;/ol&gt;&lt;pre&gt;&lt;code&gt;&amp;#40;use 'figwheel-sidecar.repl-api&amp;#41;

&amp;#40;start-figwheel!&amp;#41;

&amp;#40;cljs-repl&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And now you have a Figwheel REPL in the buffer.  You can send stuff to the browser just like you can with Figwheel in the terminal, AND you can use the normal spacemacs/cider key bindings to send stuff to the fancy figwheel repl through emacs. &lt;/p&gt;&lt;p&gt;Even more awesome, you can then quit out of the cljs repl with &lt;code&gt;:cljs/quit&lt;/code&gt;, at which point you'll have a clj repl again, and you can send CLJ/JVM code to that as normal.  BUT: figwheel will still be autobuilding!  So you can edit your cljs code and it'll shoot right back to the browser.  Then, when you want a figwheel repl again, you can go with &lt;code&gt;&amp;#40;cljs-repl&amp;#41;&lt;/code&gt; and it'll be right back.&lt;/p&gt;&lt;p&gt;When you kill cider (with &lt;code&gt;SPC m s q&lt;/code&gt;) it's polite enough to also take out the figwheel autobuild. &lt;/p&gt;&lt;p&gt;Magic. &lt;/p&gt;
</description>
<enclosure>

</enclosure>
<pubDate>
Fri, 02 Dec 2016 00:00:00 -0500
</pubDate>
</item>
<item>
<guid>
http://paultopia.github.io/posts-output/helloworld/
</guid>
<link>
http://paultopia.github.io/posts-output/helloworld/
</link>
<title>
Cryogen + Github pages + Klipse
</title>
<description>
&lt;p&gt;Hello world, and all that jazz.  I've decided to start a tech blog. &lt;/p&gt;&lt;p&gt;The first challenge: getting it up. Static site generators seem to be fashionable these days, and I'm a big fan of Clojure, so naturally I went with &lt;a href='http://cryogenweb.org/'&gt;Cryogen&lt;/a&gt;, which is a dead simple static site generator where you literally fire up a lein template and then edit a bunch of markdown files and simple &lt;a href='https://github.com/yogthos/Selmer'&gt;Selmer&lt;/a&gt; templates plus a single config edn. And &lt;a href='https://pages.github.com/'&gt;Github Pages&lt;/a&gt; is both free and convenient name recognition for code-oriented things, so that's the obvious choice for a host.&lt;/p&gt;&lt;p&gt;The main alternative I considered was &lt;a href='https://jaspervdj.be/hakyll/'&gt;Hakyll&lt;/a&gt;, mainly because I've been meaning to try to do a Haskell project. But taking one look at the code in the &quot;create compilation rules in a Haskell EDSL&quot; snippet on the front page, and, nopesauce. As much as I'm starting to like Haskell (more later), I still immediately get turned off by the weird &lt;a href='https://twitter.com/PaulGowder/status/783886798350987264'&gt;special character-heavy syntax choices&lt;/a&gt;. So when I saw &lt;code&gt;&amp;gt;&amp;gt;=&lt;/code&gt; and &lt;code&gt;.||.&lt;/code&gt; that was it for me. (Maybe when I finally write my personal course management system.)&lt;/p&gt;&lt;p&gt;So challenge #1 is getting it on github. The official Cryogen docs aren't terribly clear on this point, but github personal/organizational pages appear to want to have the static content at the root of the repo, and Cryogen outputs the content it produces to /resources/public. You can fix this by setting the repo at resources/public rather than in the root directory of the Cryogen project, but then the markdown files, Selmer templates, etc. aren't under version control, and that's obviously a problem.&lt;/p&gt;&lt;p&gt;Fortunately, a couple nice chaps named &lt;a href='http://tangrammer.github.io/posts/02-12-2014-cryogen-and-github.html'&gt;Juan Ruz&lt;/a&gt; and Mayank Jain cooked up &lt;a href='http://firesofmay.com/posts/2015-08-26-setup-cryogen.html'&gt;a solution&lt;/a&gt;. The heart of the fix is to create one repo at the root of the Cryogen project, call it &quot;my blog&quot; or something, and then create a second repo, &lt;em&gt;inside the first one&lt;/em&gt;, with the standard yourname.github.io naming, starting at /resources/public. &lt;/p&gt;&lt;p&gt;To be honest, this seems super-shady to me. The official way to nest repositories in one another in git is to use a &lt;a href='https://git-scm.com/docs/git-submodule'&gt;submodule&lt;/a&gt;, but just try to read the documentation for that, I dare you. So what happens if you actually nest repos like this without using submodules?  Does everything horribly break?  Well, not so far... &lt;/p&gt;&lt;p&gt;The folks who devised this recommend putting /resources/public in the .gitignore of the original repo, presumably as a safety measure to prevent all kinds of weird conflicts from happening. And it seems ok... I haven't horribly blown up anything so far. (Heaven help me if I try to do anything even remotely fancy with branches, or checking out old commits, or something.)&lt;/p&gt;&lt;p&gt;The second challenge is getting Klipse running. For those who don't know, &lt;a href='https://github.com/viebel/klipse'&gt;Klipse&lt;/a&gt; is an amazing embedded clojurescript evaluation environment, basically a modular repl in a page: you can replace code snippets with actual executable code, and even do things like fetch libraries. It is awesomesauce. It also has interpreters for (officially) Javascript, Ruby, and PHP in addition to clojurescript; unofficially it also has Python among others. &lt;/p&gt;&lt;p&gt;After some hassle, integrating Klipse with Cryogen actually turned out to be dead simple. In Cryogen, all the Selmer templates are stored in subdirectories of your themes, so all I did was &lt;a href='https://github.com/paultopia/experimental-cryogen/blob/master/resources/templates/themes/nucleus/html/base.html'&gt;edit base.html&lt;/a&gt; there to add references to the Klipse javascript source.  Viz: &lt;/p&gt;&lt;pre&gt;&lt;code&gt;{% if post.executable %}
{% style &amp;quot;css/codemirror.css&amp;quot; %}
&amp;lt;script&amp;gt;
 window.klipse&amp;#95;settings = {
     selector: '.clojure',
     selector&amp;#95;eval&amp;#95;python&amp;#95;client: '.python'
 };
&amp;lt;/script&amp;gt;
{% script &amp;quot;js/klipse&amp;#95;plugin.js&amp;quot; %}
{% script &amp;quot;js/skulpt.min.js&amp;quot; %}
{% script &amp;quot;js/skulpt-stdlib.js&amp;quot; %}
{% endif %}

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;A few points to note there: &lt;/p&gt;&lt;ul&gt;&lt;li&gt;The selectors are classes that can be added to a fenced code block in the markdown file just by putting the name of a class directly after the opening symbol, i.e., &lt;code&gt;&amp;#126;&amp;#126;&amp;#126;clojure&lt;/code&gt;&lt;/li&gt;&lt;li&gt;post.executable is a variable that I set at the top of the markdown files. So what the template does is chooses whether or not to include the Klipse stuff depending on whether I've said, in a given post, that there's executable code in it. The rationale here is that all this extra javascript is really heavy, and I don't want people to have to load it if they're just visiting the site to look at a page that doesn't use it.  I'll probably modify this down the road to take a different variable for each language, and then only load the interpretation environment appropriate to that language.&lt;/li&gt;&lt;li&gt;Because Python is still an unofficial part of Klipse, this selector isn't actually documented yet, but it's in there and I'll prove it:&lt;/li&gt;&lt;/ul&gt;&lt;pre&gt;&lt;code class=&quot;python&quot;&gt;print &amp;quot;, &amp;quot;.join&amp;#40;map&amp;#40;lambda x: &amp;quot;Hello &amp;quot; + x, &amp;#91;&amp;quot;my baby&amp;quot;, &amp;quot;my honey&amp;quot;, &amp;quot;my ragtop World!&amp;quot;&amp;#93;&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;See?&lt;/p&gt;&lt;ul&gt;&lt;li&gt;I'm locally serving the Klipse javascript rather than using the one provided by the (awesome) maintainer of the plugin because the provided version doesn't support https. However, it turns out there's &lt;a href='https://github.com/viebel/klipse#https'&gt;a workaround&lt;/a&gt;, and I'll probably switch to that, because the maintainer told me that he's pushing out frequent releases, and I want to keep up to date.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Other matters of note: &lt;/p&gt;&lt;ul&gt;&lt;li&gt;Depending on what languages you want to use, you might need a special build of the highlight.js javascript that comes with cryogen. &lt;a href='https://highlightjs.org/download/'&gt;Get it here&lt;/a&gt;.&lt;/li&gt;&lt;li&gt;All this mucking around with multiple repos and such really demands &lt;a href='https://github.com/paultopia/experimental-cryogen/blob/master/deploy'&gt;a build script&lt;/a&gt;.  Mostly derived from Jain's.&lt;/li&gt;&lt;li&gt;Note how you can compile Cryogen with &lt;code&gt;lein run&lt;/code&gt;. This isn't actually in the documentation anywhere, which just recommends compiling with &lt;code&gt;lein ring server&lt;/code&gt; and actually running a whole webserver (plus auto recompile). But this seems annoying and wasteful to me when you can just add a compilation step to the build script.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Now let's have a fizzbuzz.&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;take 100 &amp;#40;map #&amp;#40;cond &amp;#40;= &amp;#40;mod % 15&amp;#41; 0&amp;#41; &amp;quot;fizzbuzz&amp;quot; &amp;#40;= &amp;#40;mod % 3&amp;#41; 0&amp;#41; &amp;quot;fizz&amp;quot; &amp;#40;= &amp;#40;mod % 5&amp;#41; 0&amp;#41; &amp;quot;buzz&amp;quot; :else %&amp;#41; &amp;#40;range 1 101&amp;#41;&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;bye.&lt;/p&gt;
</description>
<enclosure>

</enclosure>
<pubDate>
Mon, 17 Oct 2016 00:00:00 -0400
</pubDate>
</item>
<item>
<guid>
http://paultopia.github.io/posts-output/second/
</guid>
<link>
http://paultopia.github.io/posts-output/second/
</link>
<title>
Experimenting
</title>
<description>
&lt;p&gt;This is just a post to experiment with klipse and making it work with cryogen markdown passing. &lt;/p&gt;&lt;p&gt;the following is done with markdown fenced block: &lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;&amp;#40;take 10 &amp;#40;map inc &amp;#40;range&amp;#41;&amp;#41;&amp;#41;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;the following is done with raw html code tags:&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;clojure&quot;&gt; ((comp (partial apply +) (partial map (partial * 3))) [1 2 3]) &lt;/code&gt;&lt;/p&gt;&lt;p&gt;Doing some haskell to see default highlight.js behavior:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;plength :: &amp;#91;a&amp;#93; -&amp;gt; Int
plength &amp;#91;&amp;#93; = 0
plength &amp;#40;x:xs&amp;#41; = 1 + plength xs
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Some python with markdown fenced block:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;python&quot;&gt;for x in range&amp;#40;20&amp;#41;:
    print x
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;With raw code tag:&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;python&quot;&gt;print [x.upper() for x in [&quot;foo&quot;, &quot;bar&quot;]] &lt;/code&gt;&lt;/p&gt;&lt;p&gt;(need to minimize loading of plugins by having a tag for each language)&lt;/p&gt;
</description>
<enclosure>

</enclosure>
<pubDate>
Sun, 16 Oct 2016 00:00:00 -0400
</pubDate>
</item>
<item>
<guid>
http://paultopia.github.io/posts-output/2016-01-07-docs/
</guid>
<link>
http://paultopia.github.io/posts-output/2016-01-07-docs/
</link>
<title>
Quick Start Guide
</title>
<description>
&lt;p&gt;This intro only documents a subset of Cryogen's features. For additional documentation please see the &lt;a href='http://cryogenweb.org'&gt;cryogen site&lt;/a&gt;.&lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;features&quot;&gt;&lt;/a&gt;Features&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;Blog posts and pages with Markdown (default) or AsciiDoc&lt;/li&gt;&lt;li&gt;Tags&lt;/li&gt;&lt;li&gt;Table of contents generation&lt;/li&gt;&lt;li&gt;Plain HTML page templates&lt;/li&gt;&lt;li&gt;Code syntax highlighting&lt;/li&gt;&lt;li&gt;Disqus support&lt;/li&gt;&lt;li&gt;Sitemap generation&lt;/li&gt;&lt;li&gt;RSS feed generation&lt;/li&gt;&lt;li&gt;Sass/SCSS compilation&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;a name=&quot;prerequisites&quot;&gt;&lt;/a&gt;Prerequisites&lt;/h2&gt;&lt;p&gt;You will need &lt;a href='https://github.com/technomancy/leiningen'&gt;Leiningen&lt;/a&gt; 2.5.0 or above installed.&lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;usage&quot;&gt;&lt;/a&gt;Usage&lt;/h2&gt;&lt;h3&gt;&lt;a name=&quot;creating&amp;#95;a&amp;#95;new&amp;#95;site&quot;&gt;&lt;/a&gt;Creating a New Site&lt;/h3&gt;&lt;p&gt;A new site can be created using the Cryogen template as follows:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;lein new cryogen my-blog
&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;&lt;a name=&quot;running&amp;#95;the&amp;#95;server&quot;&gt;&lt;/a&gt;Running the Server&lt;/h3&gt;&lt;p&gt;The web server can be started from the &lt;code&gt;my-blog&lt;/code&gt; directory using the &lt;code&gt;lein-ring&lt;/code&gt; plugin:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;lein ring server
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The server will watch for changes in the &lt;code&gt;resources/templates&lt;/code&gt; folder and recompile the content automatically.&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;site&amp;#95;configuration&quot;&gt;&lt;/a&gt;Site Configuration&lt;/h3&gt;&lt;p&gt;The site configuration file is found at &lt;code&gt;templates/config.edn&lt;/code&gt;, this file looks as follows:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;clojure&quot;&gt;{:site-title         &amp;quot;My Awesome Blog&amp;quot;
 :author             &amp;quot;Bob Bobbert&amp;quot;
 :description        &amp;quot;This blog is awesome&amp;quot;
 :site-url           &amp;quot;http://blogawesome.com/&amp;quot;
 :post-root          &amp;quot;posts&amp;quot;
 :page-root          &amp;quot;pages&amp;quot;
 :post-root-uri      &amp;quot;posts-output&amp;quot;
 :page-root-uri      &amp;quot;pages-output&amp;quot;
 :tag-root-uri       &amp;quot;tags-output&amp;quot;
 :blog-prefix        &amp;quot;/blog&amp;quot;
 :rss-name           &amp;quot;feed.xml&amp;quot;
 :rss-filters        &amp;#91;&amp;quot;cryogen&amp;quot;&amp;#93;
 :recent-posts       3
 :post-date-format   &amp;quot;yyyy-MM-dd&amp;quot;
 :sass-src           nil
 :sass-dest          nil
 :theme              &amp;quot;blue&amp;quot;
 :resources          &amp;#91;&amp;quot;img&amp;quot;&amp;#93;
 :keep-files         &amp;#91;&amp;quot;.git&amp;quot;&amp;#93;
 :disqus?            false
 :disqus-shortname   &amp;quot;&amp;quot;
 :ignored-files      &amp;#91;#&amp;quot;\.#.&amp;#42;&amp;quot; #&amp;quot;.&amp;#42;\.swp$&amp;quot;&amp;#93;
 :posts-per-page     5
 :blocks-per-preview 2
 :previews?          false
 :clean-urls?        true}

&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;For information about each key please see the &lt;a href='http://cryogenweb.org/docs/configuration.html'&gt;&quot;Configuration&quot;&lt;/a&gt; portion of the Cryogen documentation site.&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;switching&amp;#95;between&amp;#95;markdown&amp;#95;and&amp;#95;asciidoc&quot;&gt;&lt;/a&gt;Switching between Markdown and AsciiDoc&lt;/h3&gt;&lt;p&gt;Cryogen comes with Markdown support as default. If you want to use AsciiDoc instead, open the &lt;code&gt;project.clj&lt;/code&gt; in your created blog (e.g. &lt;code&gt;my-blog&lt;/code&gt;), and change the line in &lt;code&gt;:dependencies&lt;/code&gt; that says &lt;code&gt;cryogen-markdown&lt;/code&gt; to &lt;code&gt;cryogen-asciidoc&lt;/code&gt;. Instead of looking for files ending in &lt;code&gt;.md&lt;/code&gt; in the &lt;code&gt;resources/templates/md&lt;/code&gt; directory, the compiler will now look for files ending in &lt;code&gt;.asc&lt;/code&gt; in the &lt;code&gt;resources/templates/asc&lt;/code&gt; directory.&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;selecting&amp;#95;a&amp;#95;theme&quot;&gt;&lt;/a&gt;Selecting a Theme&lt;/h3&gt;&lt;p&gt;The Cryogen template comes with two themes in the &lt;code&gt;resources/templates/themes&lt;/code&gt; folder. To change your blog's theme, change the value of the &lt;code&gt;:theme&lt;/code&gt; key in &lt;code&gt;config.edn&lt;/code&gt;.&lt;/p&gt;&lt;h3&gt;&lt;a name=&quot;customizing&amp;#95;layouts&quot;&gt;&lt;/a&gt;Customizing Layouts&lt;/h3&gt;&lt;p&gt;Cryogen uses &lt;a href='https://github.com/yogthos/Selmer'&gt;Selmer&lt;/a&gt; templating engine for layouts. Please refer to its documentation to see the supported tags and filters for the layouts.&lt;/p&gt;&lt;p&gt;The layouts are contained in the &lt;code&gt;resources/templates/themes/{theme}/html&lt;/code&gt; folder of the project. By default, the &lt;code&gt;base.html&lt;/code&gt; layout is used to provide the general layout for the site. This is where you would add static resources such as CSS and JavaScript assets as well as define headers and footers for your site.&lt;/p&gt;&lt;p&gt;Each page layout should have a name that matches the &lt;code&gt;:layout&lt;/code&gt; key in the page metadata and end with &lt;code&gt;.html&lt;/code&gt;. Page layouts extend the base layout and should only contain the content relevant to the page inside the &lt;code&gt;content&lt;/code&gt; block. For example, the &lt;code&gt;tag&lt;/code&gt; layout is located in &lt;code&gt;tag.html&lt;/code&gt; and looks as follows:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;xml&quot;&gt;{% extends &amp;quot;templates/html/layouts/base.html&amp;quot; %}
{% block content %}
&amp;lt;div id=&amp;quot;posts-by-tag&amp;quot;&amp;gt;
    &amp;lt;h2&amp;gt;Posts tagged {{name}}&amp;lt;/h2&amp;gt;
    &amp;lt;ul&amp;gt;
    {% for post in posts %}
        &amp;lt;li&amp;gt;
            &amp;lt;a href=&amp;quot;{{post.uri}}&amp;quot;&amp;gt;{{post.title}}&amp;lt;/a&amp;gt;
        &amp;lt;/li&amp;gt;
    {% endfor %}
    &amp;lt;/ul&amp;gt;
&amp;lt;/div&amp;gt;
{% endblock %}
&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;&lt;a name=&quot;code&amp;#95;syntax&amp;#95;highlighting&quot;&gt;&lt;/a&gt;Code Syntax Highlighting&lt;/h3&gt;&lt;p&gt;Cryogen uses &lt;a href='https://highlightjs.org/'&gt;Highlight.js&lt;/a&gt; for code syntax highlighting. You can add more languages by replacing &lt;code&gt;templates/js/highlight.pack.js&lt;/code&gt; with a customized package from &lt;a href='https://highlightjs.org/download/'&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;The &lt;code&gt; initHighlightingOnLoad&lt;/code&gt; function is called in &lt;code&gt;{theme}/html/base.html&lt;/code&gt;.&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;xml&quot;&gt;&amp;lt;script&amp;gt;hljs.initHighlightingOnLoad&amp;#40;&amp;#41;;&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;h2&gt;&lt;a name=&quot;deploying&amp;#95;your&amp;#95;site&quot;&gt;&lt;/a&gt;Deploying Your Site&lt;/h2&gt;&lt;p&gt;The generated static content will be found under the &lt;code&gt;resources/public&lt;/code&gt; folder. Simply copy the content to a static folder for a server such as Nginx or Apache and your site is now ready for service.&lt;/p&gt;&lt;p&gt;A sample Nginx configuration that's placed in &lt;code&gt;/etc/nginx/sites-available/default&lt;/code&gt; can be seen below:&lt;/p&gt;&lt;pre&gt;&lt;code class=&quot;javascript&quot;&gt;server {
  listen 80 default&amp;#95;server;
  listen &amp;#91;::&amp;#93;:80 default&amp;#95;server ipv6only=on;
  server&amp;#95;name localhost &amp;lt;yoursite.com&amp;gt; &amp;lt;www.yoursite.com&amp;gt;;

  access&amp;#95;log  /var/log/blog&amp;#95;access.log;
  error&amp;#95;log   /var/log/blog&amp;#95;error.log;

  location / {
    alias       /var/blog/;
    error&amp;#95;page  404 = /404.html;
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Simply set &lt;code&gt;yoursite.com&lt;/code&gt; to the domain of your site in the above configuration and ensure the static content is available at &lt;code&gt;/var/blog/&lt;/code&gt;. Finally, place your custom error page in the &lt;code&gt;/var/blog/404.html&lt;/code&gt; file.&lt;/p&gt;&lt;p&gt;More information on deployment can be found &lt;a href='http://cryogenweb.org/docs/deploying-to-github-pages.html'&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;h2&gt;&lt;a name=&quot;some&amp;#95;sites&amp;#95;made&amp;#95;with&amp;#95;cryogen&quot;&gt;&lt;/a&gt;Some Sites Made With Cryogen&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;a href='http://carmenla.me/blog/index.html'&gt;Creator's blog&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href='http://cryogenweb.org'&gt;Cryogen Documentation Site&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href='http://yogthos.net/'&gt;Yogthos' blog&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href='http://www.clojure.tn'&gt;Clojure :in Tunisia&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href='http://dl1ely.github.io'&gt;dl1ely.github.io&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href='http://jonase.github.io/nil-recur'&gt;nil/recur&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href='http://tangrammer.github.io/'&gt;on the clojure move&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href='http://blog.jethrokuan.com/'&gt;cognizance&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href='http://www.agynamix.de'&gt;AGYNAMIX Site &amp; Blog&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href='http://eresident.me'&gt;e-Resident Me&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href='http://www.chadstovern.com'&gt;Chad Stovern's blog&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href='https://greative.jp/'&gt;Greative&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;
</description>
<enclosure>

</enclosure>
<pubDate>
Thu, 07 Jan 2016 00:00:00 -0500
</pubDate>
</item>
<item>
<guid>
http://paultopia.github.io/posts-output/2014-11-04-second-post/
</guid>
<link>
http://paultopia.github.io/posts-output/2014-11-04-second-post/
</link>
<title>
Yet Another Post
</title>
<description>
&lt;h3&gt;&lt;a name=&quot;this&amp;#95;post&amp;#95;so&amp;#95;fetch&quot;&gt;&lt;/a&gt;This Post So Fetch&lt;/h3&gt;&lt;p&gt;some more stuff happened&lt;/p&gt;
</description>
<enclosure>

</enclosure>
<pubDate>
Tue, 04 Nov 2014 00:00:00 -0500
</pubDate>
</item>
<item>
<guid>
http://paultopia.github.io/posts-output/2014-03-10-first-post/
</guid>
<link>
http://paultopia.github.io/posts-output/2014-03-10-first-post/
</link>
<title>
A Post
</title>
<description>
&lt;h3&gt;&lt;a name=&quot;this&amp;#95;post&amp;#95;not&amp;#95;fetch&amp;#95;enough&quot;&gt;&lt;/a&gt;This Post Not Fetch Enough&lt;/h3&gt;&lt;p&gt;some stuff happened&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;and a quote appeared &lt;/p&gt;&lt;/blockquote&gt;
</description>
<enclosure>

</enclosure>
<pubDate>
Mon, 10 Mar 2014 00:00:00 -0400
</pubDate>
</item>
</channel>
</rss>
